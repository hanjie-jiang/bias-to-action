{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Machine Learning Notes <p>Curated notes on probability, foundations, and neural networks.</p> <p> ML Fundamentals ML Fundamentals <ul> <li>Overview</li> <li>Feature Engineering</li> <li>Model Evaluation</li> <li>Regularization</li> <li>Classical Algorithms</li> <li>Unsupervised Learning</li> </ul> Probability &amp; Markov Probability &amp; Markov <ul> <li>Overview</li> <li>Bayes' Rule</li> <li>Naive Bayes</li> <li>Joint &amp; Marginal</li> </ul> Engineering &amp; Data Structure Engineering &amp; Data Structure <ul> <li>Overview</li> <li>Python Sets</li> <li>Python Dictionaries</li> <li>Problem Solving</li> <li>Resources</li> </ul> Language Model Language Models <ul> <li>N-gram Language Modeling</li> </ul> </p> Engineering &amp; Data Structure <p>Sets, dictionaries, problem solving patterns, and interview preparation.</p> Information Theory <p>Entropy, cross-entropy and KL divergence.</p> Neural Networks <p>Backpropagation, activations, training tips.</p> Linear Algebra <p>Vectors, matrices, SVD and more.</p>"},{"location":"Foundational%20knowledge%20plan/","title":"Foundational knowledge plan","text":""},{"location":"Foundational%20knowledge%20plan/#week-0-overview-of-ml-fundamentals","title":"Week 0: Overview of ML Fundamentals","text":"<p>The ML fundamentals section introduces model evaluation, classical algorithms and more, which becomes the building blocks of the topics in the weeks following. </p>"},{"location":"Foundational%20knowledge%20plan/#week-1-2-probability-foundations-markov-assumption","title":"Week 1-2: Probability Foundations + Markov Assumption","text":"<ul> <li>Probability_and_Markov_Overview</li> <li>Topics:<ul> <li>conditional_probability_and_bayes_rule</li> <li>naive_bayes_and_gaussian_naive_bayes</li> <li>joint_and_marginal_distributions</li> <li>Markov Assumption: what it is and why it matters in NLP</li> </ul> </li> <li>Resources:<ul> <li>StatQuest: Conditional Probability (YouTube)</li> <li>StatQuest: Bayes' Rule</li> <li>3Blue1Brown: Bayes theorem, the geometry of changing beliefs</li> <li>StatQuest: Naive Bayes</li> <li>StatQuest: Gaussian Naive Bayes</li> <li>Khan Academy - Probability &amp; Statistics</li> <li>Speech and Language Processing by Jurafsky &amp; Martin Ch. 3 (Markov models)</li> </ul> </li> </ul>"},{"location":"Foundational%20knowledge%20plan/#week-3-n-gram-models-language-modeling","title":"Week 3: N-gram Models &amp; Language Modeling","text":"<ul> <li>Ngram_Language_Modeling</li> <li>Topics:<ul> <li>What is an n-gram?</li> <li>How n-gram language models work</li> <li>Perplexity and limitations of n-gram models</li> </ul> </li> <li>Activities:<ul> <li>Implement a bigram/trigram model on a toy corpus</li> </ul> </li> <li>Resources:<ul> <li>The Illustrated Transformer - start with n-gram part</li> <li>Happy-LLM intro chapter</li> <li>Optional: n-gram language model notebook</li> </ul> </li> </ul>"},{"location":"Foundational%20knowledge%20plan/#week-4-intro-to-information-theory","title":"Week 4: Intro to Information Theory","text":"<ul> <li> <p>Information_Theory</p> </li> <li> <p>Topics:</p> <ul> <li>Entropy, Cross-Entropy, KL Divergence</li> <li>Why they matter in language modeling</li> </ul> </li> <li>Activities:<ul> <li>Manually compute entropy of a simple probability distribution</li> <li>Implement cross-entropy loss</li> </ul> </li> <li>Resources:<ul> <li>3Blue1Brown \u00e2\u20ac\u201c But what is entropy?</li> <li>Stanford CS224n Lecture 1</li> </ul> </li> </ul>"},{"location":"Foundational%20knowledge%20plan/#week-5-6-linear-algebra-for-ml","title":"Week 5-6: Linear Algebra for ML","text":"<ul> <li>Linear_Algebra_for_ML</li> <li>Topics:<ul> <li>Vectors, Matrices, Matrix Multiplication</li> <li>Dot product, norms, projections </li> <li>Eigenvalues &amp; Singular Value Decomposition (SVD)  </li> </ul> </li> <li>Activities:<ul> <li>Practice via small matrix coding problems (NumPy or PyTorch)</li> </ul> </li> <li>Resources:<ul> <li>3Blue1Brown: Essence of Linear Algebra </li> <li>Stanford CS229 Linear Algebra Review</li> </ul> </li> </ul>"},{"location":"Foundational%20knowledge%20plan/#week-7-calculus-gradient-descent","title":"Week 7: Calculus + Gradient Descent","text":"<ul> <li>Calculus_and_Gradient_Descent</li> <li>Topics:<ul> <li>Partial Derivatives    </li> <li>Chain Rule    </li> <li>Gradients and optimization intuition    </li> </ul> </li> <li>Activities:<ul> <li>Derive gradients of simple functions    </li> <li>Visualize gradient descent in 2D    </li> </ul> </li> <li>Resources:<ul> <li>Khan Academy Calculus (focus on multivariable sections)    </li> <li>Gradient Descent Visualization (YouTube) </li> </ul> </li> </ul>"},{"location":"Foundational%20knowledge%20plan/#week-8-9-neural-networks-backpropagation","title":"Week 8-9: Neural Networks &amp; Backpropagation","text":"<ul> <li>Neural_Networks_and_Deep_Learning_Overview</li> <li>Topics:<ul> <li>Introduction to Perceptron Algorithm</li> <li>Structure of a feedforward neural network</li> <li>Activation functions (ReLU, softmax)</li> <li>Backpropagation algorithm</li> </ul> </li> <li>Activities:<ul> <li>Implement a simple NN from scratch (e.g., on MNIST or XOR)</li> <li>Derive gradient of softmax + cross-entropy</li> </ul> </li> <li>Resources:<ul> <li>Michael Nielsen\u00e2\u20ac\u2122s NN book: http://neuralnetworksanddeeplearning.com/</li> <li>CS231n lecture on backprop</li> </ul> </li> </ul>"},{"location":"Foundational%20knowledge%20plan/#week-10-integration-and-project","title":"Week 10: Integration and Project","text":"<ul> <li>Integration_and_Project</li> <li>Goal:<ul> <li>Build a mini-project combining n-gram + neural net ideas</li> <li>Example: Predict the next word using both n-gram and a small MLP</li> </ul> </li> <li>Outcome:<ul> <li>Review all learned concepts</li> <li>Prepare to transition to Happy-LLM\u00e2\u20ac\u2122s transformer section</li> </ul> </li> </ul>"},{"location":"Information_Theory/","title":"Information_Theory","text":""},{"location":"Information_Theory/#title-introduction-to-information-theory","title":"title: Introduction to Information Theory","text":""},{"location":"Information_Theory/#introduction","title":"Introduction","text":"<p>Information theory quantifies uncertainty and information content. Concepts such as entropy and cross-entropy are deeply entwined with language modeling and loss functions used to train neural networks.</p>"},{"location":"Information_Theory/#knowledge-points","title":"Knowledge Points","text":"<ul> <li>Entropy</li> <li>Cross-Entropy</li> <li>Kullback-Leibler (KL) Divergence</li> <li>Why information theory matters for language modeling</li> <li>Manual entropy calculation exercise</li> <li>Implementing cross-entropy loss</li> </ul>"},{"location":"Integration_and_Project/","title":"Integration_and_Project","text":""},{"location":"Integration_and_Project/#title-integration-mini-project","title":"title: Integration &amp; Mini-Project","text":""},{"location":"Integration_and_Project/#introduction","title":"Introduction","text":"<p>The capstone week integrates probabilistic and neural methods. You will build a hybrid language predictor that combines an n-gram baseline with a small neural network, reinforcing all concepts learned so far.</p>"},{"location":"Integration_and_Project/#knowledge-points","title":"Knowledge Points","text":"<ul> <li>Designing a hybrid n-gram + neural model</li> <li>Predicting the next word with combined methods</li> <li>Review of all learned concepts</li> <li>Transition plan to transformer architectures</li> </ul>"},{"location":"calculus_and_linear_algebra/Calculus_and_Gradient_Descent/","title":"Week7_Calculus_and_Gradient_Descent","text":""},{"location":"calculus_and_linear_algebra/Calculus_and_Gradient_Descent/#title-calculus-gradient-descent","title":"title: Calculus &amp; Gradient Descent","text":""},{"location":"calculus_and_linear_algebra/Calculus_and_Gradient_Descent/#introduction","title":"Introduction","text":"<p>Calculus provides the machinery to compute derivatives, which are essential for optimizing neural networks. Understanding gradients and how gradient descent navigates a loss landscape is critical for debugging and improving models.</p>"},{"location":"calculus_and_linear_algebra/Calculus_and_Gradient_Descent/#knowledge-points","title":"Knowledge Points","text":"<ul> <li>Partial derivatives</li> <li>Chain rule</li> <li>Gradients as slopes in high dimensions</li> <li>Gradient descent algorithm &amp; intuition</li> <li>Visualization of gradient descent in 2D</li> </ul>"},{"location":"calculus_and_linear_algebra/Linear_Algebra_for_ML/","title":"Linear_Algebra_for_ML","text":""},{"location":"calculus_and_linear_algebra/Linear_Algebra_for_ML/#title-linear-algebra-for-machine-learning","title":"title: Linear Algebra for Machine Learning","text":""},{"location":"calculus_and_linear_algebra/Linear_Algebra_for_ML/#introduction","title":"Introduction","text":"<p>Linear algebra is the backbone of all modern machine-learning frameworks. Vectors and matrices represent data and parameters, while operations such as matrix multiplication power everything from linear regression to transformers.</p>"},{"location":"calculus_and_linear_algebra/Linear_Algebra_for_ML/#knowledge-points","title":"Knowledge Points","text":"<ul> <li>Vectors &amp; vector operations</li> <li>Matrices &amp; matrix multiplication</li> <li>Dot product, norms, and projections</li> <li>Eigenvalues &amp; eigenvectors</li> <li>Singular Value Decomposition (SVD)</li> <li>Practical coding exercises with NumPy/PyTorch</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/","title":"Fixed Size Window","text":"<p>Fixed size sliding window maintains a constant window size while traversing through data. This technique is particularly effective for problems involving subarrays or substrings of a specific length.</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#core-concept","title":"Core Concept","text":"<p>In fixed size window problems: 1. Window size remains constant throughout the traversal 2. Add one element from the right 3. Remove one element from the left 4. Process current window state</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#basic-template","title":"Basic Template","text":"<pre><code>def fixed_window_template(arr, k):\n    \"\"\"Template for fixed size window problems.\"\"\"\n    if len(arr) &lt; k:\n        return []\n\n    # Initialize first window\n    window_sum = 0\n    for i in range(k):\n        window_sum += arr[i]\n\n    result = [process_window(window_sum)]\n\n    # Slide the window\n    for i in range(k, len(arr)):\n        # Remove leftmost element, add rightmost element\n        window_sum = window_sum - arr[i - k] + arr[i]\n        result.append(process_window(window_sum))\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#common-problem-types","title":"Common Problem Types","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#1-maximumminimum-in-window","title":"1. Maximum/Minimum in Window","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#maximum-sum-subarray-of-size-k","title":"Maximum Sum Subarray of Size K","text":"<pre><code>def max_sum_subarray(arr, k):\n    \"\"\"Find maximum sum of subarray of size k.\"\"\"\n    if len(arr) &lt; k:\n        return 0\n\n    # Calculate sum of first window\n    window_sum = sum(arr[:k])\n    max_sum = window_sum\n\n    # Slide window and update maximum\n    for i in range(k, len(arr)):\n        window_sum = window_sum - arr[i - k] + arr[i]\n        max_sum = max(max_sum, window_sum)\n\n    return max_sum\n\n# Example: arr = [2, 1, 5, 1, 3, 2], k = 3\n# Windows: [2,1,5]=8, [1,5,1]=7, [5,1,3]=9, [1,3,2]=6\n# Result: 9\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#average-of-subarrays-of-size-k","title":"Average of Subarrays of Size K","text":"<pre><code>def find_averages(arr, k):\n    \"\"\"Find average of each subarray of size k.\"\"\"\n    if len(arr) &lt; k:\n        return []\n\n    result = []\n    window_sum = sum(arr[:k])\n    result.append(window_sum / k)\n\n    for i in range(k, len(arr)):\n        window_sum = window_sum - arr[i - k] + arr[i]\n        result.append(window_sum / k)\n\n    return result\n\n# Time: O(n), Space: O(1) excluding result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#2-pattern-matching","title":"2. Pattern Matching","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#find-all-anagrams-in-string","title":"Find All Anagrams in String","text":"<pre><code>def find_anagrams(s, p):\n    \"\"\"Find all start indices of anagrams of p in s.\"\"\"\n    if len(p) &gt; len(s):\n        return []\n\n    from collections import Counter\n\n    p_count = Counter(p)\n    window_count = Counter()\n    result = []\n\n    for i in range(len(s)):\n        # Add current character\n        window_count[s[i]] += 1\n\n        # Remove character outside window\n        if i &gt;= len(p):\n            left_char = s[i - len(p)]\n            window_count[left_char] -= 1\n            if window_count[left_char] == 0:\n                del window_count[left_char]\n\n        # Check if current window is anagram\n        if i &gt;= len(p) - 1 and window_count == p_count:\n            result.append(i - len(p) + 1)\n\n    return result\n\n# Example: s = \"abab\", p = \"ab\"\n# Result: [0, 2] (anagrams at indices 0 and 2)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#permutation-in-string","title":"Permutation in String","text":"<pre><code>def check_inclusion(s1, s2):\n    \"\"\"Check if s2 contains permutation of s1.\"\"\"\n    if len(s1) &gt; len(s2):\n        return False\n\n    from collections import Counter\n\n    s1_count = Counter(s1)\n    window_count = Counter()\n\n    for i in range(len(s2)):\n        # Add current character\n        window_count[s2[i]] += 1\n\n        # Remove character outside window\n        if i &gt;= len(s1):\n            left_char = s2[i - len(s1)]\n            window_count[left_char] -= 1\n            if window_count[left_char] == 0:\n                del window_count[left_char]\n\n        # Check if current window is permutation\n        if i &gt;= len(s1) - 1 and window_count == s1_count:\n            return True\n\n    return False\n\n# Time: O(n), Space: O(k) where k is size of character set\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#3-sliding-window-maximumminimum","title":"3. Sliding Window Maximum/Minimum","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#sliding-window-maximum","title":"Sliding Window Maximum","text":"<pre><code>def sliding_window_maximum(nums, k):\n    \"\"\"Find maximum in each sliding window of size k.\"\"\"\n    from collections import deque\n\n    if not nums or k == 0:\n        return []\n\n    dq = deque()  # Store indices\n    result = []\n\n    for i in range(len(nums)):\n        # Remove elements outside current window\n        while dq and dq[0] &lt;= i - k:\n            dq.popleft()\n\n        # Remove smaller elements (they can't be maximum)\n        while dq and nums[dq[-1]] &lt; nums[i]:\n            dq.pop()\n\n        dq.append(i)\n\n        # Add maximum of current window to result\n        if i &gt;= k - 1:\n            result.append(nums[dq[0]])\n\n    return result\n\n# Example: nums = [1,3,-1,-3,5,3,6,7], k = 3\n# Result: [3,3,5,5,6,7]\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#first-negative-in-window","title":"First Negative in Window","text":"<pre><code>def first_negative_in_window(arr, k):\n    \"\"\"Find first negative number in each window of size k.\"\"\"\n    from collections import deque\n\n    negatives = deque()  # Store indices of negative numbers\n    result = []\n\n    for i in range(len(arr)):\n        # Add current element if negative\n        if arr[i] &lt; 0:\n            negatives.append(i)\n\n        # Remove elements outside current window\n        while negatives and negatives[0] &lt;= i - k:\n            negatives.popleft()\n\n        # Add result for current window\n        if i &gt;= k - 1:\n            if negatives:\n                result.append(arr[negatives[0]])\n            else:\n                result.append(0)  # No negative number\n\n    return result\n\n# Time: O(n), Space: O(k)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#advanced-fixed-window-problems","title":"Advanced Fixed Window Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#1-string-problems","title":"1. String Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#maximum-number-of-vowels-in-substring","title":"Maximum Number of Vowels in Substring","text":"<pre><code>def max_vowels(s, k):\n    \"\"\"Find maximum number of vowels in any substring of length k.\"\"\"\n    vowels = set('aeiou')\n\n    # Count vowels in first window\n    vowel_count = sum(1 for char in s[:k] if char in vowels)\n    max_vowels = vowel_count\n\n    # Slide window\n    for i in range(k, len(s)):\n        # Remove leftmost character\n        if s[i - k] in vowels:\n            vowel_count -= 1\n\n        # Add rightmost character\n        if s[i] in vowels:\n            vowel_count += 1\n\n        max_vowels = max(max_vowels, vowel_count)\n\n    return max_vowels\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#get-equal-substrings-within-budget","title":"Get Equal Substrings Within Budget","text":"<pre><code>def equal_substring(s, t, max_cost):\n    \"\"\"Find length of longest substring where cost &lt;= max_cost.\"\"\"\n    def get_cost(c1, c2):\n        return abs(ord(c1) - ord(c2))\n\n    left = 0\n    current_cost = 0\n    max_length = 0\n\n    for right in range(len(s)):\n        # Add cost of current character\n        current_cost += get_cost(s[right], t[right])\n\n        # Shrink window if cost exceeds budget\n        while current_cost &gt; max_cost:\n            current_cost -= get_cost(s[left], t[left])\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#2-array-problems","title":"2. Array Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#maximum-points-from-cards","title":"Maximum Points from Cards","text":"<pre><code>def max_score(card_points, k):\n    \"\"\"Maximum score from taking k cards from either end.\"\"\"\n    n = len(card_points)\n\n    # Take all k cards from left initially\n    current_sum = sum(card_points[:k])\n    max_sum = current_sum\n\n    # Try taking i cards from right, k-i from left\n    for i in range(1, k + 1):\n        # Remove one from left, add one from right\n        current_sum = current_sum - card_points[k - i] + card_points[n - i]\n        max_sum = max(max_sum, current_sum)\n\n    return max_sum\n\n# Time: O(k), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#defuse-the-bomb","title":"Defuse the Bomb","text":"<pre><code>def decrypt(code, k):\n    \"\"\"Decrypt circular array based on k.\"\"\"\n    n = len(code)\n    result = [0] * n\n\n    if k == 0:\n        return result\n\n    # Determine window direction\n    start = 1 if k &gt; 0 else n + k\n    end = k if k &gt; 0 else n - 1\n\n    # Calculate sum for first window\n    window_sum = sum(code[i % n] for i in range(start, start + abs(k)))\n\n    for i in range(n):\n        result[i] = window_sum\n\n        # Slide window\n        window_sum -= code[start % n]\n        window_sum += code[(start + abs(k)) % n]\n        start += 1\n\n    return result\n\n# Time: O(n), Space: O(1) excluding result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#implementation-tips","title":"Implementation Tips","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#1-boundary-handling","title":"1. Boundary Handling","text":"<pre><code>def safe_fixed_window(arr, k):\n    # Always check if array is large enough\n    if not arr or k &lt;= 0 or k &gt; len(arr):\n        return []\n\n    # Handle edge case of k = 1\n    if k == 1:\n        return arr[:]\n\n    # Regular sliding window logic\n    # ...\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#2-efficient-updates","title":"2. Efficient Updates","text":"<pre><code># Good: O(1) per window\nwindow_sum = window_sum - arr[i - k] + arr[i]\n\n# Bad: O(k) per window\nwindow_sum = sum(arr[i - k + 1:i + 1])\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#3-using-data-structures","title":"3. Using Data Structures","text":"<pre><code>from collections import deque, Counter\n\n# For min/max tracking\ndq = deque()\n\n# For frequency counting\ncounter = Counter()\n\n# For set operations\nchar_set = set()\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#common-mistakes","title":"Common Mistakes","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#1-index-errors","title":"1. Index Errors","text":"<pre><code># Wrong: May go out of bounds\nfor i in range(len(arr)):\n    if i &gt;= k:\n        # Process window arr[i-k+1:i+1]\n\n# Correct: Proper bounds checking\nfor i in range(k - 1, len(arr)):\n    # Process window arr[i-k+1:i+1]\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#2-not-handling-edge-cases","title":"2. Not Handling Edge Cases","text":"<pre><code>def robust_sliding_window(arr, k):\n    if not arr or k &lt;= 0:\n        return []\n\n    if k &gt; len(arr):\n        return []  # or return [sum(arr)] depending on problem\n\n    # Main logic here\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#3-inefficient-window-recalculation","title":"3. Inefficient Window Recalculation","text":"<pre><code># Inefficient: O(n*k)\nfor i in range(len(arr) - k + 1):\n    window_sum = sum(arr[i:i+k])  # Recalculates every time\n\n# Efficient: O(n)\nwindow_sum = sum(arr[:k])\nfor i in range(k, len(arr)):\n    window_sum = window_sum - arr[i-k] + arr[i]\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#practice-problems","title":"Practice Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#easy","title":"Easy","text":"<ol> <li>Maximum Average Subarray I (LeetCode 643)</li> <li>Find All Anagrams in a String (LeetCode 438)</li> <li>Defuse the Bomb (LeetCode 1652)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#medium","title":"Medium","text":"<ol> <li>Sliding Window Maximum (LeetCode 239)</li> <li>Maximum Number of Vowels (LeetCode 1456)</li> <li>Get Equal Substrings Within Budget (LeetCode 1208)</li> <li>Maximum Points You Can Obtain from Cards (LeetCode 1423)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#hard","title":"Hard","text":"<ol> <li>Minimum Window Substring (LeetCode 76)</li> <li>Sliding Window Median (LeetCode 480)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Fixed_Size_Window/#next-topics","title":"Next Topics","text":"<ul> <li>Variable_Size_Window - Learn about dynamic window sizing</li> <li>Sliding_Window_Problems - Practice problems using sliding window</li> <li>Two_Pointers_Overview - Related technique for array traversal</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/","title":"Sliding Window Overview","text":"<p>The Sliding Window technique is a powerful algorithmic pattern used to solve problems involving subarrays or substrings. It optimizes brute force solutions from O(n\u00b2) or O(n\u00b3) to O(n) by maintaining a \"window\" that slides through the data.</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#what-is-sliding-window","title":"What is Sliding Window?","text":"<p>Sliding Window maintains a subset (window) of elements and efficiently updates this window as it moves through the data structure. Instead of recalculating everything for each position, it adds new elements and removes old ones.</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#types-of-sliding-windows","title":"Types of Sliding Windows","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#1-fixed-size-window","title":"1. Fixed Size Window","text":"<p>The window size remains constant throughout the traversal.</p> <pre><code>def max_sum_subarray(arr, k):\n    \"\"\"Find maximum sum of subarray of size k.\"\"\"\n    if len(arr) &lt; k:\n        return None\n\n    # Calculate sum of first window\n    window_sum = sum(arr[:k])\n    max_sum = window_sum\n\n    # Slide the window\n    for i in range(k, len(arr)):\n        # Remove leftmost element, add rightmost element\n        window_sum = window_sum - arr[i - k] + arr[i]\n        max_sum = max(max_sum, window_sum)\n\n    return max_sum\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#2-variable-size-window","title":"2. Variable Size Window","text":"<p>The window size changes based on certain conditions.</p> <pre><code>def longest_substring_without_repeating(s):\n    \"\"\"Find length of longest substring without repeating characters.\"\"\"\n    char_set = set()\n    left = 0\n    max_length = 0\n\n    for right in range(len(s)):\n        # Shrink window until no duplicates\n        while s[right] in char_set:\n            char_set.remove(s[left])\n            left += 1\n\n        # Add current character and update max\n        char_set.add(s[right])\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#when-to-use-sliding-window","title":"When to Use Sliding Window","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#perfect-for","title":"\u2705 Perfect for:","text":"<ul> <li>Subarray/substring problems: Finding max, min, or specific properties</li> <li>Contiguous sequences: Problems requiring consecutive elements</li> <li>Optimization problems: Converting O(n\u00b2) to O(n)</li> <li>String pattern matching: When pattern has specific constraints</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#not-suitable-for","title":"\u274c Not suitable for:","text":"<ul> <li>Non-contiguous sequences: When elements don't need to be adjacent</li> <li>Global optimization: When you need to consider all possible combinations</li> <li>Complex dependencies: When current window depends on distant elements</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#fixed-size-window-patterns","title":"Fixed Size Window Patterns","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#1-maximumminimum-in-window","title":"1. Maximum/Minimum in Window","text":"<pre><code>def max_in_sliding_window(arr, k):\n    \"\"\"Find maximum element in each sliding window of size k.\"\"\"\n    from collections import deque\n\n    result = []\n    dq = deque()  # Store indices\n\n    for i in range(len(arr)):\n        # Remove elements outside current window\n        while dq and dq[0] &lt;= i - k:\n            dq.popleft()\n\n        # Remove smaller elements (they can't be maximum)\n        while dq and arr[dq[-1]] &lt; arr[i]:\n            dq.pop()\n\n        dq.append(i)\n\n        # Add to result if window is complete\n        if i &gt;= k - 1:\n            result.append(arr[dq[0]])\n\n    return result\n\ndef average_of_subarrays(arr, k):\n    \"\"\"Find average of each subarray of size k.\"\"\"\n    result = []\n    window_sum = sum(arr[:k])\n    result.append(window_sum / k)\n\n    for i in range(k, len(arr)):\n        window_sum = window_sum - arr[i - k] + arr[i]\n        result.append(window_sum / k)\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#2-pattern-matching","title":"2. Pattern Matching","text":"<pre><code>def find_anagrams(s, p):\n    \"\"\"Find all anagrams of p in s.\"\"\"\n    if len(p) &gt; len(s):\n        return []\n\n    from collections import Counter\n\n    p_count = Counter(p)\n    window_count = Counter()\n    result = []\n\n    for i in range(len(s)):\n        # Add current character to window\n        window_count[s[i]] += 1\n\n        # Remove character outside window\n        if i &gt;= len(p):\n            left_char = s[i - len(p)]\n            window_count[left_char] -= 1\n            if window_count[left_char] == 0:\n                del window_count[left_char]\n\n        # Check if current window is anagram\n        if window_count == p_count:\n            result.append(i - len(p) + 1)\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#variable-size-window-patterns","title":"Variable Size Window Patterns","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#1-longest-substring-problems","title":"1. Longest Substring Problems","text":"<pre><code>def longest_substring_k_distinct(s, k):\n    \"\"\"Longest substring with at most k distinct characters.\"\"\"\n    if k == 0:\n        return 0\n\n    char_count = {}\n    left = 0\n    max_length = 0\n\n    for right in range(len(s)):\n        # Add current character\n        char_count[s[right]] = char_count.get(s[right], 0) + 1\n\n        # Shrink window if too many distinct characters\n        while len(char_count) &gt; k:\n            char_count[s[left]] -= 1\n            if char_count[s[left]] == 0:\n                del char_count[s[left]]\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\ndef longest_ones_with_k_flips(arr, k):\n    \"\"\"Longest subarray of 1s after flipping at most k zeros.\"\"\"\n    left = 0\n    zero_count = 0\n    max_length = 0\n\n    for right in range(len(arr)):\n        if arr[right] == 0:\n            zero_count += 1\n\n        # Shrink window if too many zeros\n        while zero_count &gt; k:\n            if arr[left] == 0:\n                zero_count -= 1\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#2-minimum-window-problems","title":"2. Minimum Window Problems","text":"<pre><code>def min_window_substring(s, t):\n    \"\"\"Minimum window substring containing all characters of t.\"\"\"\n    if not s or not t:\n        return \"\"\n\n    from collections import Counter\n\n    t_count = Counter(t)\n    required = len(t_count)\n    formed = 0\n    window_count = {}\n\n    left = 0\n    min_len = float('inf')\n    min_left = 0\n\n    for right in range(len(s)):\n        char = s[right]\n        window_count[char] = window_count.get(char, 0) + 1\n\n        if char in t_count and window_count[char] == t_count[char]:\n            formed += 1\n\n        # Try to shrink window\n        while formed == required and left &lt;= right:\n            char = s[left]\n\n            # Update minimum window\n            if right - left + 1 &lt; min_len:\n                min_len = right - left + 1\n                min_left = left\n\n            window_count[char] -= 1\n            if char in t_count and window_count[char] &lt; t_count[char]:\n                formed -= 1\n\n            left += 1\n\n    return \"\" if min_len == float('inf') else s[min_left:min_left + min_len]\n\ndef min_subarray_sum(arr, target):\n    \"\"\"Minimum length subarray with sum &gt;= target.\"\"\"\n    left = 0\n    min_length = float('inf')\n    current_sum = 0\n\n    for right in range(len(arr)):\n        current_sum += arr[right]\n\n        # Shrink window while sum &gt;= target\n        while current_sum &gt;= target:\n            min_length = min(min_length, right - left + 1)\n            current_sum -= arr[left]\n            left += 1\n\n    return min_length if min_length != float('inf') else 0\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#time-and-space-complexity","title":"Time and Space Complexity","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#time-complexity","title":"Time Complexity","text":"<ul> <li>Fixed window: O(n) - each element visited once</li> <li>Variable window: O(n) - each element added and removed at most once</li> <li>With hash maps: O(n) - hash operations are O(1) average</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#space-complexity","title":"Space Complexity","text":"<ul> <li>Basic sliding window: O(1) - only store window boundaries</li> <li>With data structures: O(k) where k is window size or distinct elements</li> <li>Result storage: O(n) if storing all results</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#common-implementation-patterns","title":"Common Implementation Patterns","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#1-two-pointer-template","title":"1. Two Pointer Template","text":"<pre><code>def sliding_window_template(arr):\n    left = 0\n    # Initialize window state\n\n    for right in range(len(arr)):\n        # Add arr[right] to window\n\n        # Shrink window if necessary\n        while condition_to_shrink:\n            # Remove arr[left] from window\n            left += 1\n\n        # Update result with current window\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#2-fixed-window-template","title":"2. Fixed Window Template","text":"<pre><code>def fixed_window_template(arr, k):\n    # Initialize first window\n    for i in range(k):\n        # Add arr[i] to window\n\n    # Process first window\n    result = [process_window()]\n\n    # Slide window\n    for i in range(k, len(arr)):\n        # Remove arr[i-k], add arr[i]\n        result.append(process_window())\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#optimization-techniques","title":"Optimization Techniques","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#1-using-deque-for-minmax","title":"1. Using Deque for Min/Max","text":"<pre><code>from collections import deque\n\ndef sliding_window_maximum(arr, k):\n    \"\"\"Efficient maximum in sliding window using deque.\"\"\"\n    dq = deque()\n    result = []\n\n    for i in range(len(arr)):\n        # Remove elements outside window\n        while dq and dq[0] &lt;= i - k:\n            dq.popleft()\n\n        # Maintain decreasing order\n        while dq and arr[dq[-1]] &lt; arr[i]:\n            dq.pop()\n\n        dq.append(i)\n\n        if i &gt;= k - 1:\n            result.append(arr[dq[0]])\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#2-counter-for-character-frequency","title":"2. Counter for Character Frequency","text":"<pre><code>from collections import Counter\n\ndef sliding_window_with_counter(s, pattern):\n    \"\"\"Use Counter for efficient character frequency tracking.\"\"\"\n    pattern_count = Counter(pattern)\n    window_count = Counter()\n    matches = 0\n\n    for char in s:\n        # Add character\n        window_count[char] += 1\n        if window_count[char] == pattern_count[char]:\n            matches += 1\n\n        # Remove excess characters\n        # ... shrinking logic\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#common-mistakes","title":"Common Mistakes","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#1-incorrect-window-bounds","title":"1. Incorrect Window Bounds","text":"<pre><code># Wrong: Off-by-one error\nfor right in range(len(arr)):\n    if right &gt;= k - 1:  # Should be right &gt;= k - 1\n        # Process window arr[right-k+1:right+1]\n\n# Correct: Proper indexing\nwindow_start = right - k + 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#2-not-handling-edge-cases","title":"2. Not Handling Edge Cases","text":"<pre><code>def robust_sliding_window(arr, k):\n    if not arr or k &lt;= 0 or k &gt; len(arr):\n        return []\n    # ... implementation\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#3-inefficient-window-updates","title":"3. Inefficient Window Updates","text":"<pre><code># Wrong: Recalculating entire window\ndef inefficient_max_sum(arr, k):\n    max_sum = 0\n    for i in range(len(arr) - k + 1):\n        current_sum = sum(arr[i:i+k])  # O(k) for each position\n        max_sum = max(max_sum, current_sum)\n    return max_sum\n\n# Correct: Update incrementally\ndef efficient_max_sum(arr, k):\n    window_sum = sum(arr[:k])\n    max_sum = window_sum\n\n    for i in range(k, len(arr)):\n        window_sum = window_sum - arr[i-k] + arr[i]  # O(1) update\n        max_sum = max(max_sum, window_sum)\n\n    return max_sum\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#practice-problems","title":"Practice Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#easy","title":"Easy","text":"<ol> <li>Maximum Sum Subarray of Size K</li> <li>Average of Subarrays of Size K</li> <li>Find All Anagrams in a String</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#medium","title":"Medium","text":"<ol> <li>Longest Substring Without Repeating Characters</li> <li>Minimum Window Substring</li> <li>Longest Substring with At Most K Distinct Characters</li> <li>Max Consecutive Ones III</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#hard","title":"Hard","text":"<ol> <li>Sliding Window Maximum</li> <li>Minimum Window Subsequence</li> <li>Longest Substring with At Most Two Distinct Characters</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Overview/#next-topics","title":"Next Topics","text":"<ul> <li>Fixed_Size_Window - Deep dive into fixed window problems</li> <li>Variable_Size_Window - Advanced variable window techniques</li> <li>Two_Pointers_Overview - Related technique for array problems</li> <li>Sliding_Window_Problems - Practice problems and solutions</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/","title":"Sliding Window Problems","text":"<p>Practice problems using the sliding window technique, organized by window type and difficulty level.</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#fixed-size-window-problems","title":"Fixed Size Window Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#easy-problems","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-maximum-average-subarray-i-leetcode-643","title":"1. Maximum Average Subarray I (LeetCode 643)","text":"<pre><code>def find_max_average(nums, k):\n    \"\"\"Find maximum average of subarray of size k.\"\"\"\n    # Calculate sum of first window\n    window_sum = sum(nums[:k])\n    max_sum = window_sum\n\n    # Slide window and update maximum\n    for i in range(k, len(nums)):\n        window_sum = window_sum - nums[i - k] + nums[i]\n        max_sum = max(max_sum, window_sum)\n\n    return max_sum / k\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#2-find-all-anagrams-in-a-string-leetcode-438","title":"2. Find All Anagrams in a String (LeetCode 438)","text":"<pre><code>def find_anagrams(s, p):\n    \"\"\"Find all start indices of anagrams of p in s.\"\"\"\n    if len(p) &gt; len(s):\n        return []\n\n    from collections import Counter\n\n    p_count = Counter(p)\n    window_count = Counter()\n    result = []\n\n    for i in range(len(s)):\n        # Add current character\n        window_count[s[i]] += 1\n\n        # Remove character outside window\n        if i &gt;= len(p):\n            left_char = s[i - len(p)]\n            window_count[left_char] -= 1\n            if window_count[left_char] == 0:\n                del window_count[left_char]\n\n        # Check if current window is anagram\n        if i &gt;= len(p) - 1 and window_count == p_count:\n            result.append(i - len(p) + 1)\n\n    return result\n\n# Time: O(n), Space: O(k) where k is size of character set\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#medium-problems","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-sliding-window-maximum-leetcode-239","title":"1. Sliding Window Maximum (LeetCode 239)","text":"<pre><code>def max_sliding_window(nums, k):\n    \"\"\"Find maximum in each sliding window of size k.\"\"\"\n    from collections import deque\n\n    if not nums or k == 0:\n        return []\n\n    dq = deque()  # Store indices\n    result = []\n\n    for i in range(len(nums)):\n        # Remove elements outside current window\n        while dq and dq[0] &lt;= i - k:\n            dq.popleft()\n\n        # Remove smaller elements (they can't be maximum)\n        while dq and nums[dq[-1]] &lt; nums[i]:\n            dq.pop()\n\n        dq.append(i)\n\n        # Add maximum of current window to result\n        if i &gt;= k - 1:\n            result.append(nums[dq[0]])\n\n    return result\n\n# Time: O(n), Space: O(k)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#2-permutation-in-string-leetcode-567","title":"2. Permutation in String (LeetCode 567)","text":"<pre><code>def check_inclusion(s1, s2):\n    \"\"\"Check if s2 contains permutation of s1.\"\"\"\n    if len(s1) &gt; len(s2):\n        return False\n\n    from collections import Counter\n\n    s1_count = Counter(s1)\n    window_count = Counter()\n\n    for i in range(len(s2)):\n        # Add current character\n        window_count[s2[i]] += 1\n\n        # Remove character outside window\n        if i &gt;= len(s1):\n            left_char = s2[i - len(s1)]\n            window_count[left_char] -= 1\n            if window_count[left_char] == 0:\n                del window_count[left_char]\n\n        # Check if current window is permutation\n        if i &gt;= len(s1) - 1 and window_count == s1_count:\n            return True\n\n    return False\n\n# Time: O(n), Space: O(k)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#3-maximum-number-of-vowels-in-substring-leetcode-1456","title":"3. Maximum Number of Vowels in Substring (LeetCode 1456)","text":"<pre><code>def max_vowels(s, k):\n    \"\"\"Find maximum number of vowels in any substring of length k.\"\"\"\n    vowels = set('aeiou')\n\n    # Count vowels in first window\n    vowel_count = sum(1 for char in s[:k] if char in vowels)\n    max_vowels = vowel_count\n\n    # Slide window\n    for i in range(k, len(s)):\n        # Remove leftmost character\n        if s[i - k] in vowels:\n            vowel_count -= 1\n\n        # Add rightmost character\n        if s[i] in vowels:\n            vowel_count += 1\n\n        max_vowels = max(max_vowels, vowel_count)\n\n    return max_vowels\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#variable-size-window-problems","title":"Variable Size Window Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#easy-problems_1","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-best-time-to-buy-and-sell-stock-leetcode-121","title":"1. Best Time to Buy and Sell Stock (LeetCode 121)","text":"<pre><code>def max_profit(prices):\n    \"\"\"Find maximum profit from buying and selling stock once.\"\"\"\n    min_price = float('inf')\n    max_profit = 0\n\n    for price in prices:\n        if price &lt; min_price:\n            min_price = price\n        else:\n            max_profit = max(max_profit, price - min_price)\n\n    return max_profit\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#medium-problems_1","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-longest-substring-without-repeating-characters-leetcode-3","title":"1. Longest Substring Without Repeating Characters (LeetCode 3)","text":"<pre><code>def length_of_longest_substring(s):\n    \"\"\"Find length of longest substring without repeating characters.\"\"\"\n    char_set = set()\n    left = 0\n    max_length = 0\n\n    for right in range(len(s)):\n        # Shrink window until no duplicates\n        while s[right] in char_set:\n            char_set.remove(s[left])\n            left += 1\n\n        char_set.add(s[right])\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Time: O(n), Space: O(min(m,n))\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#2-minimum-size-subarray-sum-leetcode-209","title":"2. Minimum Size Subarray Sum (LeetCode 209)","text":"<pre><code>def min_subarray_len(target, nums):\n    \"\"\"Minimum length subarray with sum &gt;= target.\"\"\"\n    left = 0\n    min_length = float('inf')\n    current_sum = 0\n\n    for right in range(len(nums)):\n        current_sum += nums[right]\n\n        # Shrink window while sum &gt;= target\n        while current_sum &gt;= target:\n            min_length = min(min_length, right - left + 1)\n            current_sum -= nums[left]\n            left += 1\n\n    return min_length if min_length != float('inf') else 0\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#3-max-consecutive-ones-iii-leetcode-1004","title":"3. Max Consecutive Ones III (LeetCode 1004)","text":"<pre><code>def longest_ones(nums, k):\n    \"\"\"Longest subarray of 1s after flipping at most k zeros.\"\"\"\n    left = 0\n    zero_count = 0\n    max_length = 0\n\n    for right in range(len(nums)):\n        if nums[right] == 0:\n            zero_count += 1\n\n        # Shrink window if too many zeros\n        while zero_count &gt; k:\n            if nums[left] == 0:\n                zero_count -= 1\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#4-fruit-into-baskets-leetcode-904","title":"4. Fruit Into Baskets (LeetCode 904)","text":"<pre><code>def total_fruit(fruits):\n    \"\"\"Maximum fruits collected (at most 2 types).\"\"\"\n    fruit_count = {}\n    left = 0\n    max_fruits = 0\n\n    for right in range(len(fruits)):\n        # Add current fruit\n        fruit_count[fruits[right]] = fruit_count.get(fruits[right], 0) + 1\n\n        # Shrink window if more than 2 fruit types\n        while len(fruit_count) &gt; 2:\n            fruit_count[fruits[left]] -= 1\n            if fruit_count[fruits[left]] == 0:\n                del fruit_count[fruits[left]]\n            left += 1\n\n        max_fruits = max(max_fruits, right - left + 1)\n\n    return max_fruits\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#5-longest-substring-with-at-most-k-distinct-characters-leetcode-340","title":"5. Longest Substring with At Most K Distinct Characters (LeetCode 340)","text":"<pre><code>def length_of_longest_substring_k_distinct(s, k):\n    \"\"\"Longest substring with at most k distinct characters.\"\"\"\n    if k == 0:\n        return 0\n\n    char_count = {}\n    left = 0\n    max_length = 0\n\n    for right in range(len(s)):\n        # Add current character\n        char_count[s[right]] = char_count.get(s[right], 0) + 1\n\n        # Shrink window if too many distinct characters\n        while len(char_count) &gt; k:\n            char_count[s[left]] -= 1\n            if char_count[s[left]] == 0:\n                del char_count[s[left]]\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Time: O(n), Space: O(k)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#hard-problems","title":"Hard Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-minimum-window-substring-leetcode-76","title":"1. Minimum Window Substring (LeetCode 76)","text":"<pre><code>def min_window(s, t):\n    \"\"\"Minimum window substring containing all characters of t.\"\"\"\n    if not s or not t:\n        return \"\"\n\n    from collections import Counter\n\n    t_count = Counter(t)\n    required = len(t_count)\n    formed = 0\n    window_count = {}\n\n    left = 0\n    min_len = float('inf')\n    min_left = 0\n\n    for right in range(len(s)):\n        char = s[right]\n        window_count[char] = window_count.get(char, 0) + 1\n\n        # Check if current character contributes to desired frequency\n        if char in t_count and window_count[char] == t_count[char]:\n            formed += 1\n\n        # Try to shrink window\n        while formed == required and left &lt;= right:\n            char = s[left]\n\n            # Update minimum window if current is smaller\n            if right - left + 1 &lt; min_len:\n                min_len = right - left + 1\n                min_left = left\n\n            window_count[char] -= 1\n            if char in t_count and window_count[char] &lt; t_count[char]:\n                formed -= 1\n\n            left += 1\n\n    return \"\" if min_len == float('inf') else s[min_left:min_left + min_len]\n\n# Time: O(|s| + |t|), Space: O(|s| + |t|)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#2-subarrays-with-k-different-integers-leetcode-992","title":"2. Subarrays with K Different Integers (LeetCode 992)","text":"<pre><code>def subarrays_with_k_distinct(nums, k):\n    \"\"\"Count subarrays with exactly k distinct integers.\"\"\"\n    def at_most_k(k):\n        if k == 0:\n            return 0\n\n        count_map = {}\n        left = 0\n        result = 0\n\n        for right in range(len(nums)):\n            count_map[nums[right]] = count_map.get(nums[right], 0) + 1\n\n            while len(count_map) &gt; k:\n                count_map[nums[left]] -= 1\n                if count_map[nums[left]] == 0:\n                    del count_map[nums[left]]\n                left += 1\n\n            result += right - left + 1\n\n        return result\n\n    return at_most_k(k) - at_most_k(k - 1)\n\n# Time: O(n), Space: O(k)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#specialized-sliding-window-problems","title":"Specialized Sliding Window Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#string-pattern-problems","title":"String Pattern Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-longest-repeating-character-replacement-leetcode-424","title":"1. Longest Repeating Character Replacement (LeetCode 424)","text":"<pre><code>def character_replacement(s, k):\n    \"\"\"Longest substring with same character after k replacements.\"\"\"\n    char_count = {}\n    left = 0\n    max_length = 0\n    max_freq = 0\n\n    for right in range(len(s)):\n        char_count[s[right]] = char_count.get(s[right], 0) + 1\n        max_freq = max(max_freq, char_count[s[right]])\n\n        # If window size - max frequency &gt; k, shrink window\n        if right - left + 1 - max_freq &gt; k:\n            char_count[s[left]] -= 1\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Time: O(n), Space: O(1) since at most 26 characters\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#2-minimum-window-subsequence-leetcode-727","title":"2. Minimum Window Subsequence (LeetCode 727)","text":"<pre><code>def min_window(s, t):\n    \"\"\"Minimum window subsequence of s that contains t.\"\"\"\n    m, n = len(s), len(t)\n    min_len = float('inf')\n    min_start = 0\n\n    i = 0\n    while i &lt; m:\n        j = 0\n        # Find subsequence starting from i\n        start = i\n        while i &lt; m and j &lt; n:\n            if s[i] == t[j]:\n                j += 1\n            i += 1\n\n        if j == n:  # Found complete subsequence\n            # Shrink from right to find minimum window\n            i -= 1\n            j -= 1\n            while j &gt;= 0:\n                if s[i] == t[j]:\n                    j -= 1\n                i -= 1\n            i += 1\n\n            if i - start &lt; min_len:\n                min_len = i - start\n                min_start = start\n        else:\n            break\n\n    return \"\" if min_len == float('inf') else s[min_start:min_start + min_len]\n\n# Time: O(m * n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#array-sum-problems","title":"Array Sum Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-binary-subarrays-with-sum-leetcode-930","title":"1. Binary Subarrays With Sum (LeetCode 930)","text":"<pre><code>def num_subarrays_with_sum(nums, goal):\n    \"\"\"Number of binary subarrays with sum equal to goal.\"\"\"\n    def at_most(k):\n        if k &lt; 0:\n            return 0\n\n        left = 0\n        current_sum = 0\n        count = 0\n\n        for right in range(len(nums)):\n            current_sum += nums[right]\n\n            while current_sum &gt; k:\n                current_sum -= nums[left]\n                left += 1\n\n            count += right - left + 1\n\n        return count\n\n    return at_most(goal) - at_most(goal - 1)\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#2-subarray-product-less-than-k-leetcode-713","title":"2. Subarray Product Less Than K (LeetCode 713)","text":"<pre><code>def num_subarrays_less_than_k(nums, k):\n    \"\"\"Count subarrays with product less than k.\"\"\"\n    if k &lt;= 1:\n        return 0\n\n    left = 0\n    product = 1\n    count = 0\n\n    for right in range(len(nums)):\n        product *= nums[right]\n\n        while product &gt;= k:\n            product //= nums[left]\n            left += 1\n\n        count += right - left + 1\n\n    return count\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#advanced-sliding-window-techniques","title":"Advanced Sliding Window Techniques","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#multiple-conditions","title":"Multiple Conditions","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-number-of-substrings-containing-all-three-characters-leetcode-1358","title":"1. Number of Substrings Containing All Three Characters (LeetCode 1358)","text":"<pre><code>def number_of_substrings(s):\n    \"\"\"Count substrings containing all three characters a, b, c.\"\"\"\n    last_seen = {'a': -1, 'b': -1, 'c': -1}\n    count = 0\n\n    for i, char in enumerate(s):\n        last_seen[char] = i\n\n        # Count substrings ending at position i\n        min_index = min(last_seen.values())\n        if min_index != -1:\n            count += min_index + 1\n\n    return count\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#optimization-problems","title":"Optimization Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-get-equal-substrings-within-budget-leetcode-1208","title":"1. Get Equal Substrings Within Budget (LeetCode 1208)","text":"<pre><code>def equal_substring(s, t, max_cost):\n    \"\"\"Longest substring where cost &lt;= max_cost.\"\"\"\n    def get_cost(c1, c2):\n        return abs(ord(c1) - ord(c2))\n\n    left = 0\n    current_cost = 0\n    max_length = 0\n\n    for right in range(len(s)):\n        current_cost += get_cost(s[right], t[right])\n\n        # Shrink window if cost exceeds budget\n        while current_cost &gt; max_cost:\n            current_cost -= get_cost(s[left], t[left])\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#problem-solving-strategies","title":"Problem-Solving Strategies","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-identifying-window-type","title":"1. Identifying Window Type","text":"<pre><code>def identify_window_type(problem_description):\n    if \"size k\" in problem_description or \"length k\" in problem_description:\n        return \"fixed_size\"\n    elif \"at most\" in problem_description or \"maximum\" in problem_description:\n        return \"variable_size_maximum\"\n    elif \"minimum\" in problem_description:\n        return \"variable_size_minimum\"\n    elif \"exactly\" in problem_description:\n        return \"at_most_trick\"  # exactly k = at_most(k) - at_most(k-1)\n    else:\n        return \"analyze_further\"\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#2-template-selection","title":"2. Template Selection","text":"<pre><code># Fixed size template\ndef fixed_size_template(arr, k):\n    window_state = initialize_window(arr[:k])\n    result = [process_window(window_state)]\n\n    for i in range(k, len(arr)):\n        update_window(window_state, remove=arr[i-k], add=arr[i])\n        result.append(process_window(window_state))\n\n    return result\n\n# Variable size maximum template\ndef variable_max_template(arr, condition):\n    left = 0\n    max_result = 0\n    window_state = initialize_state()\n\n    for right in range(len(arr)):\n        update_state(window_state, arr[right])\n\n        while violates_condition(window_state, condition):\n            remove_from_state(window_state, arr[left])\n            left += 1\n\n        max_result = max(max_result, right - left + 1)\n\n    return max_result\n\n# Variable size minimum template\ndef variable_min_template(arr, condition):\n    left = 0\n    min_result = float('inf')\n    window_state = initialize_state()\n\n    for right in range(len(arr)):\n        update_state(window_state, arr[right])\n\n        while satisfies_condition(window_state, condition):\n            min_result = min(min_result, right - left + 1)\n            remove_from_state(window_state, arr[left])\n            left += 1\n\n    return min_result if min_result != float('inf') else 0\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#3-common-optimizations","title":"3. Common Optimizations","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#at-most-k-trick","title":"At Most K Trick","text":"<pre><code>def exactly_k(arr, k):\n    return at_most_k(arr, k) - at_most_k(arr, k - 1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#early-termination","title":"Early Termination","text":"<pre><code># For minimum problems\nif current_window_size &gt; min_found:\n    break  # Can't get smaller\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#state-caching","title":"State Caching","text":"<pre><code># Cache expensive computations\nif state not in cache:\n    cache[state] = expensive_computation(state)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#practice-schedule","title":"Practice Schedule","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#week-1-fixed-size-windows","title":"Week 1: Fixed Size Windows","text":"<ol> <li>Maximum Average Subarray I</li> <li>Find All Anagrams in a String  </li> <li>Sliding Window Maximum</li> <li>Maximum Number of Vowels</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#week-2-variable-size-windows","title":"Week 2: Variable Size Windows","text":"<ol> <li>Longest Substring Without Repeating Characters</li> <li>Minimum Size Subarray Sum</li> <li>Max Consecutive Ones III</li> <li>Fruit Into Baskets</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#week-3-advanced-problems","title":"Week 3: Advanced Problems","text":"<ol> <li>Minimum Window Substring</li> <li>Longest Repeating Character Replacement</li> <li>Subarrays with K Different Integers</li> <li>Minimum Window Subsequence</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#1-window-state-management","title":"1. Window State Management","text":"<pre><code># Wrong: Not updating state correctly\nwindow_sum += arr[right]\n# Missing: window_sum -= arr[left] when shrinking\n\n# Correct: Update state for both expand and shrink\nwindow_sum += arr[right]  # Expand\nwhile condition_violated:\n    window_sum -= arr[left]  # Shrink\n    left += 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#2-boundary-conditions","title":"2. Boundary Conditions","text":"<pre><code># Check for empty input\nif not arr or k &lt;= 0:\n    return appropriate_default\n\n# Ensure k doesn't exceed array length\nif k &gt; len(arr):\n    return handle_edge_case()\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#3-state-consistency","title":"3. State Consistency","text":"<pre><code># Ensure hash map state is consistent\nchar_count[char] -= 1\nif char_count[char] == 0:\n    del char_count[char]  # Important for distinct count problems\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Sliding_Window_Problems/#next-topics","title":"Next Topics","text":"<ul> <li>Fixed_Size_Window - Deep dive into fixed window techniques</li> <li>Variable_Size_Window - Advanced variable window patterns</li> <li>Two_Pointers_Overview - Related technique for array problems</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/","title":"Variable Size Window","text":"<p>Variable size sliding window dynamically adjusts the window size based on certain conditions. This technique is powerful for optimization problems where you need to find the optimal subarray or substring.</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#core-concept","title":"Core Concept","text":"<p>In variable size window problems: 1. Window size changes based on conditions 2. Expand window by moving right pointer 3. Shrink window by moving left pointer 4. Track optimal solution during the process</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#basic-template","title":"Basic Template","text":"<pre><code>def variable_window_template(arr, condition):\n    \"\"\"Template for variable size window problems.\"\"\"\n    left = 0\n    best_result = 0  # or float('inf') for minimum problems\n    current_state = initialize_state()\n\n    for right in range(len(arr)):\n        # Expand window: add arr[right]\n        update_state_add(current_state, arr[right])\n\n        # Shrink window while condition is violated\n        while violates_condition(current_state, condition):\n            update_state_remove(current_state, arr[left])\n            left += 1\n\n        # Update best result\n        best_result = update_best(best_result, right - left + 1)\n\n    return best_result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#maximum-window-problems","title":"Maximum Window Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#1-longest-substring-without-repeating-characters","title":"1. Longest Substring Without Repeating Characters","text":"<pre><code>def length_of_longest_substring(s):\n    \"\"\"Find length of longest substring without repeating characters.\"\"\"\n    char_set = set()\n    left = 0\n    max_length = 0\n\n    for right in range(len(s)):\n        # Shrink window until no duplicates\n        while s[right] in char_set:\n            char_set.remove(s[left])\n            left += 1\n\n        # Add current character and update max\n        char_set.add(s[right])\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Example: s = \"abcabcbb\"\n# Result: 3 (substring \"abc\")\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#2-longest-substring-with-at-most-k-distinct-characters","title":"2. Longest Substring with At Most K Distinct Characters","text":"<pre><code>def length_of_longest_substring_k_distinct(s, k):\n    \"\"\"Longest substring with at most k distinct characters.\"\"\"\n    if k == 0:\n        return 0\n\n    char_count = {}\n    left = 0\n    max_length = 0\n\n    for right in range(len(s)):\n        # Add current character\n        char_count[s[right]] = char_count.get(s[right], 0) + 1\n\n        # Shrink window if too many distinct characters\n        while len(char_count) &gt; k:\n            char_count[s[left]] -= 1\n            if char_count[s[left]] == 0:\n                del char_count[s[left]]\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Example: s = \"eceba\", k = 2\n# Result: 3 (substring \"ece\")\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#3-max-consecutive-ones-iii","title":"3. Max Consecutive Ones III","text":"<pre><code>def longest_ones(nums, k):\n    \"\"\"Longest subarray of 1s after flipping at most k zeros.\"\"\"\n    left = 0\n    zero_count = 0\n    max_length = 0\n\n    for right in range(len(nums)):\n        # Count zeros in current window\n        if nums[right] == 0:\n            zero_count += 1\n\n        # Shrink window if too many zeros\n        while zero_count &gt; k:\n            if nums[left] == 0:\n                zero_count -= 1\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Example: nums = [1,1,1,0,0,0,1,1,1,1,0], k = 2\n# Result: 6\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#4-fruit-into-baskets","title":"4. Fruit Into Baskets","text":"<pre><code>def total_fruit(fruits):\n    \"\"\"Maximum fruits you can collect (at most 2 types).\"\"\"\n    fruit_count = {}\n    left = 0\n    max_fruits = 0\n\n    for right in range(len(fruits)):\n        # Add current fruit\n        fruit_count[fruits[right]] = fruit_count.get(fruits[right], 0) + 1\n\n        # Shrink window if more than 2 fruit types\n        while len(fruit_count) &gt; 2:\n            fruit_count[fruits[left]] -= 1\n            if fruit_count[fruits[left]] == 0:\n                del fruit_count[fruits[left]]\n            left += 1\n\n        max_fruits = max(max_fruits, right - left + 1)\n\n    return max_fruits\n\n# Example: fruits = [1,2,1]\n# Result: 3 (all fruits)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#minimum-window-problems","title":"Minimum Window Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#1-minimum-window-substring","title":"1. Minimum Window Substring","text":"<pre><code>def min_window(s, t):\n    \"\"\"Minimum window substring containing all characters of t.\"\"\"\n    if not s or not t:\n        return \"\"\n\n    from collections import Counter\n\n    t_count = Counter(t)\n    required = len(t_count)\n    formed = 0\n    window_count = {}\n\n    left = 0\n    min_len = float('inf')\n    min_left = 0\n\n    for right in range(len(s)):\n        char = s[right]\n        window_count[char] = window_count.get(char, 0) + 1\n\n        # Check if current character contributes to desired frequency\n        if char in t_count and window_count[char] == t_count[char]:\n            formed += 1\n\n        # Try to shrink window\n        while formed == required and left &lt;= right:\n            char = s[left]\n\n            # Update minimum window if current is smaller\n            if right - left + 1 &lt; min_len:\n                min_len = right - left + 1\n                min_left = left\n\n            window_count[char] -= 1\n            if char in t_count and window_count[char] &lt; t_count[char]:\n                formed -= 1\n\n            left += 1\n\n    return \"\" if min_len == float('inf') else s[min_left:min_left + min_len]\n\n# Example: s = \"ADOBECODEBANC\", t = \"ABC\"\n# Result: \"BANC\"\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#2-minimum-size-subarray-sum","title":"2. Minimum Size Subarray Sum","text":"<pre><code>def min_subarray_len(target, nums):\n    \"\"\"Minimum length subarray with sum &gt;= target.\"\"\"\n    left = 0\n    min_length = float('inf')\n    current_sum = 0\n\n    for right in range(len(nums)):\n        current_sum += nums[right]\n\n        # Shrink window while sum &gt;= target\n        while current_sum &gt;= target:\n            min_length = min(min_length, right - left + 1)\n            current_sum -= nums[left]\n            left += 1\n\n    return min_length if min_length != float('inf') else 0\n\n# Example: target = 7, nums = [2,3,1,2,4,3]\n# Result: 2 (subarray [4,3])\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#3-smallest-window-with-all-characters","title":"3. Smallest Window with All Characters","text":"<pre><code>def min_window_all_chars(s):\n    \"\"\"Smallest window containing all unique characters of string.\"\"\"\n    from collections import Counter\n\n    char_count = Counter(s)\n    required = len(char_count)\n    window_count = {}\n    formed = 0\n\n    left = 0\n    min_len = float('inf')\n    min_left = 0\n\n    for right in range(len(s)):\n        char = s[right]\n        window_count[char] = window_count.get(char, 0) + 1\n\n        if char in char_count and window_count[char] == char_count[char]:\n            formed += 1\n\n        # Try to shrink window\n        while formed == required and left &lt;= right:\n            if right - left + 1 &lt; min_len:\n                min_len = right - left + 1\n                min_left = left\n\n            char = s[left]\n            window_count[char] -= 1\n            if char in char_count and window_count[char] &lt; char_count[char]:\n                formed -= 1\n\n            left += 1\n\n    return s[min_left:min_left + min_len] if min_len != float('inf') else \"\"\n\n# Time: O(n), Space: O(k) where k is unique characters\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#exact-match-problems","title":"Exact Match Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#1-subarray-sum-equals-k","title":"1. Subarray Sum Equals K","text":"<pre><code>def subarray_sum(nums, k):\n    \"\"\"Count subarrays with sum equal to k.\"\"\"\n    from collections import defaultdict\n\n    count = 0\n    prefix_sum = 0\n    sum_count = defaultdict(int)\n    sum_count[0] = 1  # Empty prefix\n\n    for num in nums:\n        prefix_sum += num\n\n        # Check if (prefix_sum - k) exists\n        if prefix_sum - k in sum_count:\n            count += sum_count[prefix_sum - k]\n\n        sum_count[prefix_sum] += 1\n\n    return count\n\n# Note: This uses prefix sum, not sliding window\n# For positive numbers only, can use sliding window\ndef subarray_sum_positive(nums, k):\n    \"\"\"Count subarrays with sum = k (positive numbers only).\"\"\"\n    left = 0\n    current_sum = 0\n    count = 0\n\n    for right in range(len(nums)):\n        current_sum += nums[right]\n\n        # Shrink window if sum &gt; k\n        while current_sum &gt; k and left &lt;= right:\n            current_sum -= nums[left]\n            left += 1\n\n        # Check if current sum equals k\n        if current_sum == k:\n            count += 1\n\n    return count\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#2-binary-subarrays-with-sum","title":"2. Binary Subarrays with Sum","text":"<pre><code>def num_subarrays_with_sum(nums, goal):\n    \"\"\"Number of binary subarrays with sum equal to goal.\"\"\"\n    def at_most(k):\n        if k &lt; 0:\n            return 0\n\n        left = 0\n        current_sum = 0\n        count = 0\n\n        for right in range(len(nums)):\n            current_sum += nums[right]\n\n            while current_sum &gt; k:\n                current_sum -= nums[left]\n                left += 1\n\n            count += right - left + 1\n\n        return count\n\n    return at_most(goal) - at_most(goal - 1)\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#advanced-variable-window-techniques","title":"Advanced Variable Window Techniques","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#1-sliding-window-with-multiple-conditions","title":"1. Sliding Window with Multiple Conditions","text":"<pre><code>def complex_window_condition(s, k1, k2):\n    \"\"\"Example with multiple sliding conditions.\"\"\"\n    from collections import defaultdict\n\n    char_count = defaultdict(int)\n    left = 0\n    result = 0\n\n    for right in range(len(s)):\n        char_count[s[right]] += 1\n\n        # Multiple shrinking conditions\n        while (len(char_count) &gt; k1 or \n               max(char_count.values()) &gt; k2):\n            char_count[s[left]] -= 1\n            if char_count[s[left]] == 0:\n                del char_count[s[left]]\n            left += 1\n\n        result = max(result, right - left + 1)\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#2-sliding-window-with-state-tracking","title":"2. Sliding Window with State Tracking","text":"<pre><code>def window_with_state(nums, target):\n    \"\"\"Window that tracks complex state.\"\"\"\n    left = 0\n    current_sum = 0\n    current_product = 1\n    valid_windows = 0\n\n    for right in range(len(nums)):\n        current_sum += nums[right]\n        current_product *= nums[right]\n\n        # Shrink based on multiple conditions\n        while (left &lt;= right and \n               (current_sum &gt; target or current_product &gt; target)):\n            current_sum -= nums[left]\n            current_product //= nums[left] if nums[left] != 0 else 1\n            left += 1\n\n        valid_windows += right - left + 1\n\n    return valid_windows\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#implementation-strategies","title":"Implementation Strategies","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#1-choosing-window-type","title":"1. Choosing Window Type","text":"<pre><code># Maximum/Longest problems\ndef max_window_template(arr):\n    left = 0\n    max_result = 0\n\n    for right in range(len(arr)):\n        # Add arr[right] to window\n\n        # Shrink if condition violated\n        while condition_violated():\n            # Remove arr[left] from window\n            left += 1\n\n        max_result = max(max_result, right - left + 1)\n\n    return max_result\n\n# Minimum problems\ndef min_window_template(arr):\n    left = 0\n    min_result = float('inf')\n\n    for right in range(len(arr)):\n        # Add arr[right] to window\n\n        # Shrink while condition satisfied\n        while condition_satisfied():\n            min_result = min(min_result, right - left + 1)\n            # Remove arr[left] from window\n            left += 1\n\n    return min_result if min_result != float('inf') else 0\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#2-state-management","title":"2. State Management","text":"<pre><code># Using hash map for frequency\nfrom collections import defaultdict\nchar_count = defaultdict(int)\n\n# Using set for uniqueness\nchar_set = set()\n\n# Using variables for simple state\nzero_count = 0\nsum_value = 0\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#common-patterns","title":"Common Patterns","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#1-at-most-k-pattern","title":"1. At Most K Pattern","text":"<pre><code>def at_most_k(arr, k):\n    \"\"\"Subarrays with at most k distinct elements.\"\"\"\n    count_map = {}\n    left = 0\n    result = 0\n\n    for right in range(len(arr)):\n        count_map[arr[right]] = count_map.get(arr[right], 0) + 1\n\n        while len(count_map) &gt; k:\n            count_map[arr[left]] -= 1\n            if count_map[arr[left]] == 0:\n                del count_map[arr[left]]\n            left += 1\n\n        result += right - left + 1  # All subarrays ending at right\n\n    return result\n\n# Exactly k = at_most(k) - at_most(k-1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#2-two-pointer-shrinking","title":"2. Two Pointer Shrinking","text":"<pre><code>def two_pointer_shrink(arr, target):\n    \"\"\"Shrink from both ends based on condition.\"\"\"\n    left, right = 0, len(arr) - 1\n    result = 0\n\n    while left &lt; right:\n        current = calculate_value(arr, left, right)\n\n        if current == target:\n            result += 1\n            left += 1\n            right -= 1\n        elif current &lt; target:\n            left += 1\n        else:\n            right -= 1\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#common-mistakes","title":"Common Mistakes","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#1-incorrect-shrinking-condition","title":"1. Incorrect Shrinking Condition","text":"<pre><code># Wrong: May miss valid windows\nwhile condition_violated():\n    left += 1\n\n# Correct: Update state while shrinking\nwhile condition_violated():\n    remove_from_state(arr[left])\n    left += 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#2-not-handling-empty-windows","title":"2. Not Handling Empty Windows","text":"<pre><code># Add boundary checks\nif left &gt; right:\n    continue  # or break, depending on problem\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#3-state-inconsistency","title":"3. State Inconsistency","text":"<pre><code># Ensure state is updated correctly\ndef add_to_window(char):\n    char_count[char] += 1\n\ndef remove_from_window(char):\n    char_count[char] -= 1\n    if char_count[char] == 0:\n        del char_count[char]  # Important for distinct count\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#practice-problems","title":"Practice Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#easy","title":"Easy","text":"<ol> <li>Maximum Average Subarray I (LeetCode 643)</li> <li>Longest Substring Without Repeating Characters (LeetCode 3)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#medium","title":"Medium","text":"<ol> <li>Minimum Window Substring (LeetCode 76)</li> <li>Longest Substring with At Most K Distinct Characters (LeetCode 340)</li> <li>Max Consecutive Ones III (LeetCode 1004)</li> <li>Minimum Size Subarray Sum (LeetCode 209)</li> <li>Fruit Into Baskets (LeetCode 904)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#hard","title":"Hard","text":"<ol> <li>Sliding Window Maximum (LeetCode 239)</li> <li>Minimum Window Subsequence (LeetCode 727)</li> <li>Subarrays with K Different Integers (LeetCode 992)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Sliding_Window/Variable_Size_Window/#next-topics","title":"Next Topics","text":"<ul> <li>Fixed_Size_Window - Learn about constant window size problems</li> <li>Sliding_Window_Problems - Practice problems using sliding window</li> <li>Two_Pointers_Overview - Related technique for array traversal</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/","title":"Opposite Direction Pointers","text":"<p>Opposite direction pointers (also called convergent pointers) start from opposite ends of the data structure and move toward each other. This technique is particularly effective for problems on sorted arrays and palindrome checking.</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#core-concept","title":"Core Concept","text":"<p>In opposite direction pointer problems: 1. Left pointer starts at the beginning (index 0) 2. Right pointer starts at the end (index n-1) 3. Pointers move toward each other based on conditions 4. Stop when pointers meet or cross</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#basic-template","title":"Basic Template","text":"<pre><code>def opposite_pointers_template(arr):\n    \"\"\"Template for opposite direction pointers.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt; right:\n        # Process current pair\n        if condition_met(arr[left], arr[right]):\n            # Found solution or update result\n            process_result(left, right)\n            left += 1\n            right -= 1\n        elif arr[left] &lt; arr[right]:  # or custom condition\n            left += 1\n        else:\n            right -= 1\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#target-sum-problems","title":"Target Sum Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#1-two-sum-in-sorted-array","title":"1. Two Sum in Sorted Array","text":"<pre><code>def two_sum_sorted(numbers, target):\n    \"\"\"Find two numbers that add up to target in sorted array.\"\"\"\n    left, right = 0, len(numbers) - 1\n\n    while left &lt; right:\n        current_sum = numbers[left] + numbers[right]\n\n        if current_sum == target:\n            return [left + 1, right + 1]  # 1-indexed\n        elif current_sum &lt; target:\n            left += 1  # Need larger sum\n        else:\n            right -= 1  # Need smaller sum\n\n    return []  # No solution found\n\n# Example: numbers = [2,7,11,15], target = 9\n# Result: [1, 2] (2 + 7 = 9)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#2-three-sum","title":"2. Three Sum","text":"<pre><code>def three_sum(nums):\n    \"\"\"Find all unique triplets that sum to zero.\"\"\"\n    nums.sort()  # Essential for this approach\n    result = []\n\n    for i in range(len(nums) - 2):\n        # Skip duplicates for first element\n        if i &gt; 0 and nums[i] == nums[i - 1]:\n            continue\n\n        left, right = i + 1, len(nums) - 1\n\n        while left &lt; right:\n            current_sum = nums[i] + nums[left] + nums[right]\n\n            if current_sum == 0:\n                result.append([nums[i], nums[left], nums[right]])\n\n                # Skip duplicates\n                while left &lt; right and nums[left] == nums[left + 1]:\n                    left += 1\n                while left &lt; right and nums[right] == nums[right - 1]:\n                    right -= 1\n\n                left += 1\n                right -= 1\n            elif current_sum &lt; 0:\n                left += 1\n            else:\n                right -= 1\n\n    return result\n\n# Example: nums = [-1,0,1,2,-1,-4]\n# Result: triplets \\[\\[-1, -1, 2], [-1, 0, 1\\]\\]\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#3-three-sum-closest","title":"3. Three Sum Closest","text":"<pre><code>def three_sum_closest(nums, target):\n    \"\"\"Find three numbers whose sum is closest to target.\"\"\"\n    nums.sort()\n    n = len(nums)\n    closest_sum = float('inf')\n\n    for i in range(n - 2):\n        left, right = i + 1, n - 1\n\n        while left &lt; right:\n            current_sum = nums[i] + nums[left] + nums[right]\n\n            # Update closest sum if current is closer\n            if abs(current_sum - target) &lt; abs(closest_sum - target):\n                closest_sum = current_sum\n\n            if current_sum == target:\n                return target\n            elif current_sum &lt; target:\n                left += 1\n            else:\n                right -= 1\n\n    return closest_sum\n\n# Time: O(n\u00b2), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#4-four-sum","title":"4. Four Sum","text":"<pre><code>def four_sum(nums, target):\n    \"\"\"Find all unique quadruplets that sum to target.\"\"\"\n    nums.sort()\n    n = len(nums)\n    result = []\n\n    for i in range(n - 3):\n        if i &gt; 0 and nums[i] == nums[i - 1]:\n            continue\n\n        for j in range(i + 1, n - 2):\n            if j &gt; i + 1 and nums[j] == nums[j - 1]:\n                continue\n\n            left, right = j + 1, n - 1\n\n            while left &lt; right:\n                current_sum = nums[i] + nums[j] + nums[left] + nums[right]\n\n                if current_sum == target:\n                    result.append([nums[i], nums[j], nums[left], nums[right]])\n\n                    # Skip duplicates\n                    while left &lt; right and nums[left] == nums[left + 1]:\n                        left += 1\n                    while left &lt; right and nums[right] == nums[right - 1]:\n                        right -= 1\n\n                    left += 1\n                    right -= 1\n                elif current_sum &lt; target:\n                    left += 1\n                else:\n                    right -= 1\n\n    return result\n\n# Time: O(n\u00b3), Space: O(1) excluding result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#palindrome-problems","title":"Palindrome Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#1-valid-palindrome","title":"1. Valid Palindrome","text":"<pre><code>def is_palindrome(s):\n    \"\"\"Check if string is palindrome (ignoring case and non-alphanumeric).\"\"\"\n    left, right = 0, len(s) - 1\n\n    while left &lt; right:\n        # Skip non-alphanumeric characters\n        while left &lt; right and not s[left].isalnum():\n            left += 1\n        while left &lt; right and not s[right].isalnum():\n            right -= 1\n\n        # Compare characters\n        if s[left].lower() != s[right].lower():\n            return False\n\n        left += 1\n        right -= 1\n\n    return True\n\n# Example: s = \"A man, a plan, a canal: Panama\"\n# Result: True\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#2-valid-palindrome-ii","title":"2. Valid Palindrome II","text":"<pre><code>def valid_palindrome_deletion(s):\n    \"\"\"Check if string can be palindrome by deleting at most one character.\"\"\"\n    def is_palindrome_range(left, right):\n        while left &lt; right:\n            if s[left] != s[right]:\n                return False\n            left += 1\n            right -= 1\n        return True\n\n    left, right = 0, len(s) - 1\n\n    while left &lt; right:\n        if s[left] != s[right]:\n            # Try deleting either left or right character\n            return (is_palindrome_range(left + 1, right) or \n                    is_palindrome_range(left, right - 1))\n        left += 1\n        right -= 1\n\n    return True  # Already a palindrome\n\n# Example: s = \"aba\" \u2192 True, s = \"abca\" \u2192 True (delete 'c')\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#3-palindromic-substrings","title":"3. Palindromic Substrings","text":"<pre><code>def count_palindromic_substrings(s):\n    \"\"\"Count all palindromic substrings.\"\"\"\n    def expand_around_center(left, right):\n        count = 0\n        while left &gt;= 0 and right &lt; len(s) and s[left] == s[right]:\n            count += 1\n            left -= 1\n            right += 1\n        return count\n\n    total_count = 0\n\n    for i in range(len(s)):\n        # Odd length palindromes (center at i)\n        total_count += expand_around_center(i, i)\n\n        # Even length palindromes (center between i and i+1)\n        total_count += expand_around_center(i, i + 1)\n\n    return total_count\n\n# Example: s = \"abc\" \u2192 3, s = \"aaa\" \u2192 6\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#container-and-trapping-problems","title":"Container and Trapping Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#1-container-with-most-water","title":"1. Container With Most Water","text":"<pre><code>def max_area(height):\n    \"\"\"Find two lines that form container with most water.\"\"\"\n    left, right = 0, len(height) - 1\n    max_water = 0\n\n    while left &lt; right:\n        # Calculate current area\n        width = right - left\n        current_area = min(height[left], height[right]) * width\n        max_water = max(max_water, current_area)\n\n        # Move pointer with smaller height\n        if height[left] &lt; height[right]:\n            left += 1\n        else:\n            right -= 1\n\n    return max_water\n\n# Example: height = [1,8,6,2,5,4,8,3,7]\n# Result: 49\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#2-trapping-rain-water","title":"2. Trapping Rain Water","text":"<pre><code>def trap_rain_water(height):\n    \"\"\"Calculate trapped rainwater.\"\"\"\n    if not height:\n        return 0\n\n    left, right = 0, len(height) - 1\n    left_max, right_max = 0, 0\n    water_trapped = 0\n\n    while left &lt; right:\n        if height[left] &lt; height[right]:\n            if height[left] &gt;= left_max:\n                left_max = height[left]\n            else:\n                water_trapped += left_max - height[left]\n            left += 1\n        else:\n            if height[right] &gt;= right_max:\n                right_max = height[right]\n            else:\n                water_trapped += right_max - height[right]\n            right -= 1\n\n    return water_trapped\n\n# Example: height = [0,1,0,2,1,0,1,3,2,1,2,1]\n# Result: 6\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#array-manipulation","title":"Array Manipulation","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#1-reverse-array","title":"1. Reverse Array","text":"<pre><code>def reverse_array(arr):\n    \"\"\"Reverse array in-place using two pointers.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt; right:\n        arr[left], arr[right] = arr[right], arr[left]\n        left += 1\n        right -= 1\n\n    return arr\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#2-remove-duplicates-from-sorted-array","title":"2. Remove Duplicates from Sorted Array","text":"<pre><code>def remove_duplicates(nums):\n    \"\"\"Remove duplicates from sorted array in-place.\"\"\"\n    if not nums:\n        return 0\n\n    write_index = 1  # Position for next unique element\n\n    for read_index in range(1, len(nums)):\n        if nums[read_index] != nums[read_index - 1]:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    return write_index\n\n# Example: nums = [1,1,2] \u2192 returns 2, nums becomes [1,2,...]\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#3-sort-colors-dutch-flag","title":"3. Sort Colors (Dutch Flag)","text":"<pre><code>def sort_colors(nums):\n    \"\"\"Sort array of 0s, 1s, and 2s in-place.\"\"\"\n    left, right = 0, len(nums) - 1\n    current = 0\n\n    while current &lt;= right:\n        if nums[current] == 0:\n            nums[left], nums[current] = nums[current], nums[left]\n            left += 1\n            current += 1\n        elif nums[current] == 1:\n            current += 1\n        else:  # nums[current] == 2\n            nums[current], nums[right] = nums[right], nums[current]\n            right -= 1\n            # Don't increment current, need to check swapped element\n\n    return nums\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#string-problems","title":"String Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#1-reverse-words-in-string","title":"1. Reverse Words in String","text":"<pre><code>def reverse_words(s):\n    \"\"\"Reverse words in string while preserving word order.\"\"\"\n    def reverse_range(arr, start, end):\n        while start &lt; end:\n            arr[start], arr[end] = arr[end], arr[start]\n            start += 1\n            end -= 1\n\n    # Convert to list for in-place operations\n    chars = list(s.strip())\n\n    # Reverse entire string\n    reverse_range(chars, 0, len(chars) - 1)\n\n    # Reverse each word\n    start = 0\n    for i in range(len(chars) + 1):\n        if i == len(chars) or chars[i] == ' ':\n            reverse_range(chars, start, i - 1)\n            start = i + 1\n\n    return ''.join(chars)\n\n# Example: \"the sky is blue\" \u2192 \"blue is sky the\"\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#2-compare-version-numbers","title":"2. Compare Version Numbers","text":"<pre><code>def compare_version(version1, version2):\n    \"\"\"Compare two version numbers.\"\"\"\n    v1_parts = version1.split('.')\n    v2_parts = version2.split('.')\n\n    i, j = 0, 0\n\n    while i &lt; len(v1_parts) or j &lt; len(v2_parts):\n        num1 = int(v1_parts[i]) if i &lt; len(v1_parts) else 0\n        num2 = int(v2_parts[j]) if j &lt; len(v2_parts) else 0\n\n        if num1 &lt; num2:\n            return -1\n        elif num1 &gt; num2:\n            return 1\n\n        i += 1\n        j += 1\n\n    return 0\n\n# Example: version1 = \"1.01\", version2 = \"1.001\" \u2192 0\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#1-partition-array","title":"1. Partition Array","text":"<pre><code>def partition_array(nums, pivot):\n    \"\"\"Partition array around pivot value.\"\"\"\n    left, right = 0, len(nums) - 1\n\n    while left &lt;= right:\n        while left &lt;= right and nums[left] &lt; pivot:\n            left += 1\n        while left &lt;= right and nums[right] &gt; pivot:\n            right -= 1\n\n        if left &lt;= right:\n            nums[left], nums[right] = nums[right], nums[left]\n            left += 1\n            right -= 1\n\n    return left  # Partition point\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#2-find-pair-with-given-difference","title":"2. Find Pair with Given Difference","text":"<pre><code>def find_pair_difference(nums, k):\n    \"\"\"Find pair with difference k in sorted array.\"\"\"\n    left, right = 0, 1\n\n    while right &lt; len(nums):\n        diff = nums[right] - nums[left]\n\n        if diff == k:\n            return [nums[left], nums[right]]\n        elif diff &lt; k:\n            right += 1\n        else:\n            left += 1\n            if left == right:\n                right += 1\n\n    return []\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#common-patterns-and-tips","title":"Common Patterns and Tips","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#1-when-to-use-opposite-pointers","title":"1. When to Use Opposite Pointers","text":"<ul> <li>Sorted arrays: Target sum, closest sum problems</li> <li>Palindromes: String or array palindrome checking</li> <li>Optimization: Container, trapping water problems</li> <li>Partitioning: Dutch flag, quicksort partition</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#2-movement-strategies","title":"2. Movement Strategies","text":"<pre><code># Equal movement\nleft += 1\nright -= 1\n\n# Conditional movement\nif condition:\n    left += 1\nelse:\n    right -= 1\n\n# Greedy movement (container problem)\nif height[left] &lt; height[right]:\n    left += 1\nelse:\n    right -= 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#3-common-mistakes","title":"3. Common Mistakes","text":"<pre><code># Wrong: May cause infinite loop\nwhile left &lt;= right:  # Should be left &lt; right for most cases\n\n# Wrong: Not handling duplicates\n# Should skip duplicates in problems like 3Sum\n\n# Wrong: Incorrect boundary conditions\nleft, right = 0, len(arr)  # Should be len(arr) - 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#practice-problems","title":"Practice Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#easy","title":"Easy","text":"<ol> <li>Two Sum II - Input Array Is Sorted (LeetCode 167)</li> <li>Valid Palindrome (LeetCode 125)</li> <li>Reverse String (LeetCode 344)</li> <li>Remove Duplicates from Sorted Array (LeetCode 26)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#medium","title":"Medium","text":"<ol> <li>3Sum (LeetCode 15)</li> <li>Container With Most Water (LeetCode 11)</li> <li>Sort Colors (LeetCode 75)</li> <li>3Sum Closest (LeetCode 16)</li> <li>Valid Palindrome II (LeetCode 680)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#hard","title":"Hard","text":"<ol> <li>Trapping Rain Water (LeetCode 42)</li> <li>4Sum (LeetCode 18)</li> <li>Palindromic Substrings (LeetCode 647)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Opposite_Direction_Pointers/#next-topics","title":"Next Topics","text":"<ul> <li>Same_Direction_Pointers - Learn about fast and slow pointer techniques</li> <li>Two_Pointers_Problems - Practice problems using two pointers</li> <li>Sliding_Window_Overview - Related technique for subarray problems</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/","title":"Same Direction Pointers","text":"<p>Same direction pointers (also called fast and slow pointers, or tortoise and hare) move in the same direction but at different speeds or with different purposes. This technique is powerful for cycle detection, finding middle elements, and in-place array modifications.</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#core-concept","title":"Core Concept","text":"<p>In same direction pointer problems: 1. Both pointers start from the same end (usually beginning) 2. Pointers move at different speeds or serve different purposes 3. Fast pointer explores ahead while slow pointer processes elements 4. Gap between pointers is maintained or adjusted based on problem requirements</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#basic-templates","title":"Basic Templates","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#template-1-fast-and-slow-pointers","title":"Template 1: Fast and Slow Pointers","text":"<pre><code>def fast_slow_template(arr):\n    \"\"\"Template for fast and slow pointer problems.\"\"\"\n    slow = fast = 0\n\n    while fast &lt; len(arr) and condition:\n        # Move fast pointer\n        fast += 1  # or more steps\n\n        # Move slow pointer conditionally\n        if some_condition:\n            slow += 1\n\n    return slow  # or process result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#template-2-read-and-write-pointers","title":"Template 2: Read and Write Pointers","text":"<pre><code>def read_write_template(arr):\n    \"\"\"Template for in-place array modification.\"\"\"\n    write_index = 0\n\n    for read_index in range(len(arr)):\n        if should_keep(arr[read_index]):\n            arr[write_index] = arr[read_index]\n            write_index += 1\n\n    return write_index  # New length\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#linked-list-problems","title":"Linked List Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#1-cycle-detection-floyds-algorithm","title":"1. Cycle Detection (Floyd's Algorithm)","text":"<pre><code>class ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\ndef has_cycle(head):\n    \"\"\"Detect if linked list has cycle.\"\"\"\n    if not head or not head.next:\n        return False\n\n    slow = fast = head\n\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n\n        if slow == fast:\n            return True\n\n    return False\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#2-find-cycle-start","title":"2. Find Cycle Start","text":"<pre><code>def detect_cycle_start(head):\n    \"\"\"Find the start of cycle in linked list.\"\"\"\n    if not head or not head.next:\n        return None\n\n    # Phase 1: Detect cycle\n    slow = fast = head\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        if slow == fast:\n            break\n    else:\n        return None  # No cycle\n\n    # Phase 2: Find cycle start\n    slow = head\n    while slow != fast:\n        slow = slow.next\n        fast = fast.next\n\n    return slow\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#3-find-middle-node","title":"3. Find Middle Node","text":"<pre><code>def find_middle(head):\n    \"\"\"Find middle node of linked list.\"\"\"\n    if not head:\n        return None\n\n    slow = fast = head\n\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n\n    return slow  # Middle node\n\n# For even length, returns second middle node\n# For odd length, returns exact middle\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#4-remove-nth-node-from-end","title":"4. Remove Nth Node from End","text":"<pre><code>def remove_nth_from_end(head, n):\n    \"\"\"Remove nth node from end of linked list.\"\"\"\n    dummy = ListNode(0, head)\n    slow = fast = dummy\n\n    # Move fast pointer n+1 steps ahead\n    for _ in range(n + 1):\n        fast = fast.next\n\n    # Move both pointers until fast reaches end\n    while fast:\n        slow = slow.next\n        fast = fast.next\n\n    # Remove the nth node from end\n    slow.next = slow.next.next\n\n    return dummy.next\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#5-palindrome-linked-list","title":"5. Palindrome Linked List","text":"<pre><code>def is_palindrome_list(head):\n    \"\"\"Check if linked list is palindrome.\"\"\"\n    if not head or not head.next:\n        return True\n\n    # Find middle using fast/slow pointers\n    slow = fast = head\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n\n    # Reverse second half\n    def reverse_list(node):\n        prev = None\n        while node:\n            next_node = node.next\n            node.next = prev\n            prev = node\n            node = next_node\n        return prev\n\n    second_half = reverse_list(slow)\n\n    # Compare first and second half\n    first_half = head\n    while second_half:\n        if first_half.val != second_half.val:\n            return False\n        first_half = first_half.next\n        second_half = second_half.next\n\n    return True\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#array-modification-problems","title":"Array Modification Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#1-remove-duplicates","title":"1. Remove Duplicates","text":"<pre><code>def remove_duplicates(nums):\n    \"\"\"Remove duplicates from sorted array in-place.\"\"\"\n    if not nums:\n        return 0\n\n    write_index = 1  # Position for next unique element\n\n    for read_index in range(1, len(nums)):\n        if nums[read_index] != nums[read_index - 1]:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    return write_index\n\n# Example: [1,1,2] \u2192 returns 2, array becomes [1,2,...]\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#2-remove-element","title":"2. Remove Element","text":"<pre><code>def remove_element(nums, val):\n    \"\"\"Remove all instances of val in-place.\"\"\"\n    write_index = 0\n\n    for read_index in range(len(nums)):\n        if nums[read_index] != val:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    return write_index\n\n# Example: nums = [3,2,2,3], val = 3 \u2192 returns 2\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#3-move-zeros","title":"3. Move Zeros","text":"<pre><code>def move_zeros(nums):\n    \"\"\"Move all zeros to end while maintaining order of non-zeros.\"\"\"\n    write_index = 0  # Position for next non-zero element\n\n    # Move all non-zeros to front\n    for read_index in range(len(nums)):\n        if nums[read_index] != 0:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    # Fill remaining positions with zeros\n    while write_index &lt; len(nums):\n        nums[write_index] = 0\n        write_index += 1\n\n# Example: [0,1,0,3,12] \u2192 [1,3,12,0,0]\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#4-remove-duplicates-ii-at-most-2","title":"4. Remove Duplicates II (At Most 2)","text":"<pre><code>def remove_duplicates_ii(nums):\n    \"\"\"Remove duplicates so each element appears at most twice.\"\"\"\n    if len(nums) &lt;= 2:\n        return len(nums)\n\n    write_index = 2  # Position for next valid element\n\n    for read_index in range(2, len(nums)):\n        # Keep element if it's different from element 2 positions back\n        if nums[read_index] != nums[write_index - 2]:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    return write_index\n\n# Example: [1,1,1,2,2,3] \u2192 returns 5, array becomes [1,1,2,2,3,...]\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#subarray-problems","title":"Subarray Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#1-longest-subarray-with-at-most-k-zeros","title":"1. Longest Subarray with At Most K Zeros","text":"<pre><code>def longest_subarray_k_zeros(nums, k):\n    \"\"\"Find longest subarray with at most k zeros.\"\"\"\n    left = 0\n    zero_count = 0\n    max_length = 0\n\n    for right in range(len(nums)):\n        if nums[right] == 0:\n            zero_count += 1\n\n        # Shrink window if too many zeros\n        while zero_count &gt; k:\n            if nums[left] == 0:\n                zero_count -= 1\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#2-max-consecutive-ones","title":"2. Max Consecutive Ones","text":"<pre><code>def find_max_consecutive_ones(nums):\n    \"\"\"Find maximum number of consecutive 1s.\"\"\"\n    max_count = 0\n    current_count = 0\n\n    for num in nums:\n        if num == 1:\n            current_count += 1\n            max_count = max(max_count, current_count)\n        else:\n            current_count = 0\n\n    return max_count\n\n# Alternative using two pointers\ndef find_max_consecutive_ones_v2(nums):\n    left = 0\n    max_length = 0\n\n    for right in range(len(nums)):\n        if nums[right] == 0:\n            left = right + 1  # Reset left pointer\n        else:\n            max_length = max(max_length, right - left + 1)\n\n    return max_length\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#string-problems","title":"String Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#1-valid-subsequence","title":"1. Valid Subsequence","text":"<pre><code>def is_subsequence(s, t):\n    \"\"\"Check if s is subsequence of t.\"\"\"\n    s_index = 0\n\n    for t_index in range(len(t)):\n        if s_index &lt; len(s) and s[s_index] == t[t_index]:\n            s_index += 1\n\n    return s_index == len(s)\n\n# Example: s = \"ace\", t = \"abcde\" \u2192 True\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#2-merge-strings-alternately","title":"2. Merge Strings Alternately","text":"<pre><code>def merge_alternately(word1, word2):\n    \"\"\"Merge strings alternately.\"\"\"\n    result = []\n    i = j = 0\n\n    # Merge characters alternately\n    while i &lt; len(word1) and j &lt; len(word2):\n        result.append(word1[i])\n        result.append(word2[j])\n        i += 1\n        j += 1\n\n    # Append remaining characters\n    while i &lt; len(word1):\n        result.append(word1[i])\n        i += 1\n\n    while j &lt; len(word2):\n        result.append(word2[j])\n        j += 1\n\n    return ''.join(result)\n\n# Example: word1 = \"abc\", word2 = \"pqr\" \u2192 \"apbqcr\"\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#3-backspace-string-compare","title":"3. Backspace String Compare","text":"<pre><code>def backspace_compare(s, t):\n    \"\"\"Compare strings with backspace operations.\"\"\"\n    def get_next_valid_char(string, index):\n        backspace_count = 0\n        while index &gt;= 0:\n            if string[index] == '#':\n                backspace_count += 1\n            elif backspace_count &gt; 0:\n                backspace_count -= 1\n            else:\n                return index\n            index -= 1\n        return index\n\n    s_index, t_index = len(s) - 1, len(t) - 1\n\n    while s_index &gt;= 0 or t_index &gt;= 0:\n        s_index = get_next_valid_char(s, s_index)\n        t_index = get_next_valid_char(t, t_index)\n\n        # Compare characters\n        if s_index &lt; 0 and t_index &lt; 0:\n            return True\n        if s_index &lt; 0 or t_index &lt; 0:\n            return False\n        if s[s_index] != t[t_index]:\n            return False\n\n        s_index -= 1\n        t_index -= 1\n\n    return True\n\n# Example: s = \"ab#c\", t = \"ad#c\" \u2192 True (both become \"ac\")\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#advanced-same-direction-techniques","title":"Advanced Same Direction Techniques","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#1-sliding-window-with-condition","title":"1. Sliding Window with Condition","text":"<pre><code>def longest_substring_condition(s, condition_func):\n    \"\"\"Find longest substring satisfying condition.\"\"\"\n    left = 0\n    max_length = 0\n    current_state = {}\n\n    for right in range(len(s)):\n        # Update state with new character\n        char = s[right]\n        current_state[char] = current_state.get(char, 0) + 1\n\n        # Shrink window while condition is violated\n        while not condition_func(current_state):\n            left_char = s[left]\n            current_state[left_char] -= 1\n            if current_state[left_char] == 0:\n                del current_state[left_char]\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#2-k-way-merge-using-pointers","title":"2. K-Way Merge Using Pointers","text":"<pre><code>def merge_k_sorted_arrays(arrays):\n    \"\"\"Merge k sorted arrays using pointers.\"\"\"\n    import heapq\n\n    result = []\n    heap = []\n\n    # Initialize heap with first element from each array\n    for i, array in enumerate(arrays):\n        if array:\n            heapq.heappush(heap, (array[0], i, 0))\n\n    while heap:\n        val, array_idx, element_idx = heapq.heappop(heap)\n        result.append(val)\n\n        # Add next element from same array\n        if element_idx + 1 &lt; len(arrays[array_idx]):\n            next_val = arrays[array_idx][element_idx + 1]\n            heapq.heappush(heap, (next_val, array_idx, element_idx + 1))\n\n    return result\n\n# Time: O(n log k), Space: O(k)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#common-patterns","title":"Common Patterns","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#1-distance-maintenance","title":"1. Distance Maintenance","text":"<pre><code># Maintain fixed distance between pointers\ndef maintain_distance(arr, k):\n    slow = 0\n    for fast in range(k, len(arr)):\n        # Process pair (slow, fast) with distance k\n        process_pair(arr[slow], arr[fast])\n        slow += 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#2-conditional-advancement","title":"2. Conditional Advancement","text":"<pre><code># Advance pointers based on conditions\ndef conditional_advance(arr):\n    slow = 0\n    for fast in range(len(arr)):\n        if condition(arr[fast]):\n            arr[slow] = arr[fast]\n            slow += 1\n    return slow\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#3-state-tracking","title":"3. State Tracking","text":"<pre><code># Track state between pointers\ndef track_state(arr):\n    slow = 0\n    state = initialize_state()\n\n    for fast in range(len(arr)):\n        update_state(state, arr[fast])\n\n        while violates_condition(state):\n            remove_from_state(state, arr[slow])\n            slow += 1\n\n        process_window(slow, fast)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#common-mistakes","title":"Common Mistakes","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#1-incorrect-pointer-initialization","title":"1. Incorrect Pointer Initialization","text":"<pre><code># Wrong: Both pointers start at same position when distance needed\nslow = fast = 0\n\n# Correct: Initialize with proper distance\nslow = 0\nfast = k\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#2-not-handling-edge-cases","title":"2. Not Handling Edge Cases","text":"<pre><code># Always check for empty input\nif not arr:\n    return appropriate_default\n\n# Check bounds before accessing\nif fast &lt; len(arr):\n    process(arr[fast])\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#3-infinite-loops-in-linked-lists","title":"3. Infinite Loops in Linked Lists","text":"<pre><code># Ensure proper termination conditions\nwhile fast and fast.next:  # Not just while fast\n    slow = slow.next\n    fast = fast.next.next\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#practice-problems","title":"Practice Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#easy","title":"Easy","text":"<ol> <li>Remove Duplicates from Sorted Array (LeetCode 26)</li> <li>Remove Element (LeetCode 27)</li> <li>Move Zeroes (LeetCode 283)</li> <li>Linked List Cycle (LeetCode 141)</li> <li>Is Subsequence (LeetCode 392)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#medium","title":"Medium","text":"<ol> <li>Remove Nth Node From End of List (LeetCode 19)</li> <li>Linked List Cycle II (LeetCode 142)</li> <li>Remove Duplicates from Sorted Array II (LeetCode 80)</li> <li>Palindrome Linked List (LeetCode 234)</li> <li>Max Consecutive Ones III (LeetCode 1004)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#hard","title":"Hard","text":"<ol> <li>Merge k Sorted Lists (LeetCode 23)</li> <li>Trapping Rain Water (LeetCode 42)</li> <li>Minimum Window Substring (LeetCode 76)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Same_Direction_Pointers/#next-topics","title":"Next Topics","text":"<ul> <li>Opposite_Direction_Pointers - Learn about convergent pointer techniques</li> <li>Two_Pointers_Problems - Practice problems using two pointers</li> <li>Sliding_Window_Overview - Related technique for subarray problems</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/","title":"Two Pointers Overview","text":"<p>The Two Pointers technique is a powerful algorithmic pattern that uses two pointers to traverse data structures efficiently. It's particularly useful for solving problems on arrays, strings, and linked lists.</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#what-is-the-two-pointers-technique","title":"What is the Two Pointers Technique?","text":"<p>Two pointers is an algorithmic pattern where you use two pointers (indices) to traverse a data structure. The pointers can move: - In the same direction (both left to right) - In opposite directions (one from start, one from end) - At different speeds (fast and slow pointers)</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#types-of-two-pointers","title":"Types of Two Pointers","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#1-opposite-direction-pointers","title":"1. Opposite Direction Pointers","text":"<pre><code>def two_sum_sorted(arr, target):\n    \"\"\"Find two numbers that add up to target in sorted array.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt; right:\n        current_sum = arr[left] + arr[right]\n        if current_sum == target:\n            return [left, right]\n        elif current_sum &lt; target:\n            left += 1\n        else:\n            right -= 1\n\n    return []\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#2-same-direction-pointers","title":"2. Same Direction Pointers","text":"<pre><code>def remove_duplicates(arr):\n    \"\"\"Remove duplicates from sorted array in-place.\"\"\"\n    if not arr:\n        return 0\n\n    slow = 0  # Position for next unique element\n\n    for fast in range(1, len(arr)):\n        if arr[fast] != arr[slow]:\n            slow += 1\n            arr[slow] = arr[fast]\n\n    return slow + 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#3-fast-and-slow-pointers","title":"3. Fast and Slow Pointers","text":"<pre><code>def find_middle(head):\n    \"\"\"Find middle node of linked list.\"\"\"\n    slow = fast = head\n\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n\n    return slow\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#when-to-use-two-pointers","title":"When to Use Two Pointers","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#good-for","title":"\u2705 Good for:","text":"<ul> <li>Sorted arrays: Finding pairs, triplets, or specific sums</li> <li>Palindromes: Checking if string/array is palindrome</li> <li>Linked lists: Finding cycles, middle elements</li> <li>Sliding window problems: When window size varies</li> <li>In-place operations: Removing duplicates, rearranging elements</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#not-suitable-for","title":"\u274c Not suitable for:","text":"<ul> <li>Unsorted data (unless you sort first)</li> <li>Hash table lookups are more efficient</li> <li>Complex data structures without clear traversal order</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#common-problem-patterns","title":"Common Problem Patterns","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#1-target-sum-problems","title":"1. Target Sum Problems","text":"<pre><code>def two_sum_sorted(arr, target):\n    \"\"\"Classic two sum on sorted array.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt; right:\n        current_sum = arr[left] + arr[right]\n        if current_sum == target:\n            return [arr[left], arr[right]]\n        elif current_sum &lt; target:\n            left += 1\n        else:\n            right -= 1\n\n    return []\n\ndef three_sum(arr, target=0):\n    \"\"\"Find all unique triplets that sum to target.\"\"\"\n    arr.sort()\n    result = []\n\n    for i in range(len(arr) - 2):\n        # Skip duplicates for first element\n        if i &gt; 0 and arr[i] == arr[i-1]:\n            continue\n\n        left, right = i + 1, len(arr) - 1\n\n        while left &lt; right:\n            current_sum = arr[i] + arr[left] + arr[right]\n\n            if current_sum == target:\n                result.append([arr[i], arr[left], arr[right]])\n\n                # Skip duplicates\n                while left &lt; right and arr[left] == arr[left + 1]:\n                    left += 1\n                while left &lt; right and arr[right] == arr[right - 1]:\n                    right -= 1\n\n                left += 1\n                right -= 1\n            elif current_sum &lt; target:\n                left += 1\n            else:\n                right -= 1\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#2-palindrome-checking","title":"2. Palindrome Checking","text":"<pre><code>def is_palindrome(s):\n    \"\"\"Check if string is palindrome (ignoring case and non-alphanumeric).\"\"\"\n    left, right = 0, len(s) - 1\n\n    while left &lt; right:\n        # Skip non-alphanumeric characters\n        while left &lt; right and not s[left].isalnum():\n            left += 1\n        while left &lt; right and not s[right].isalnum():\n            right -= 1\n\n        # Compare characters\n        if s[left].lower() != s[right].lower():\n            return False\n\n        left += 1\n        right -= 1\n\n    return True\n\ndef valid_palindrome_with_deletion(s):\n    \"\"\"Check if string can be palindrome by deleting at most one character.\"\"\"\n    def is_palindrome_range(left, right):\n        while left &lt; right:\n            if s[left] != s[right]:\n                return False\n            left += 1\n            right -= 1\n        return True\n\n    left, right = 0, len(s) - 1\n\n    while left &lt; right:\n        if s[left] != s[right]:\n            # Try deleting either left or right character\n            return (is_palindrome_range(left + 1, right) or \n                    is_palindrome_range(left, right - 1))\n        left += 1\n        right -= 1\n\n    return True\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#3-array-manipulation","title":"3. Array Manipulation","text":"<pre><code>def remove_element(arr, val):\n    \"\"\"Remove all instances of val in-place.\"\"\"\n    slow = 0\n\n    for fast in range(len(arr)):\n        if arr[fast] != val:\n            arr[slow] = arr[fast]\n            slow += 1\n\n    return slow\n\ndef move_zeros(arr):\n    \"\"\"Move all zeros to end while maintaining order of non-zeros.\"\"\"\n    slow = 0  # Position for next non-zero element\n\n    # Move all non-zeros to front\n    for fast in range(len(arr)):\n        if arr[fast] != 0:\n            arr[slow] = arr[fast]\n            slow += 1\n\n    # Fill remaining positions with zeros\n    while slow &lt; len(arr):\n        arr[slow] = 0\n        slow += 1\n\ndef reverse_array(arr):\n    \"\"\"Reverse array in-place.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt; right:\n        arr[left], arr[right] = arr[right], arr[left]\n        left += 1\n        right -= 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#4-linked-list-problems","title":"4. Linked List Problems","text":"<pre><code>class ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\ndef has_cycle(head):\n    \"\"\"Detect if linked list has cycle using Floyd's algorithm.\"\"\"\n    if not head or not head.next:\n        return False\n\n    slow = fast = head\n\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n\n        if slow == fast:\n            return True\n\n    return False\n\ndef find_cycle_start(head):\n    \"\"\"Find the start of cycle in linked list.\"\"\"\n    if not head or not head.next:\n        return None\n\n    # Phase 1: Detect cycle\n    slow = fast = head\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        if slow == fast:\n            break\n    else:\n        return None  # No cycle\n\n    # Phase 2: Find cycle start\n    slow = head\n    while slow != fast:\n        slow = slow.next\n        fast = fast.next\n\n    return slow\n\ndef remove_nth_from_end(head, n):\n    \"\"\"Remove nth node from end of linked list.\"\"\"\n    dummy = ListNode(0, head)\n    slow = fast = dummy\n\n    # Move fast pointer n+1 steps ahead\n    for _ in range(n + 1):\n        fast = fast.next\n\n    # Move both pointers until fast reaches end\n    while fast:\n        slow = slow.next\n        fast = fast.next\n\n    # Remove the nth node from end\n    slow.next = slow.next.next\n\n    return dummy.next\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#time-and-space-complexity","title":"Time and Space Complexity","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#time-complexity","title":"Time Complexity","text":"<ul> <li>Most cases: O(n) - single pass through data</li> <li>Sorted array problems: O(n) after O(n log n) sorting</li> <li>Linked list problems: O(n) - traverse list once</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#space-complexity","title":"Space Complexity","text":"<ul> <li>Usually: O(1) - only use two pointer variables</li> <li>In-place operations: O(1) extra space</li> <li>Result storage: O(k) where k is size of result</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#advantages","title":"Advantages","text":"<ol> <li>Efficient: Often reduces time complexity from O(n\u00b2) to O(n)</li> <li>Space-efficient: Usually O(1) extra space</li> <li>Intuitive: Easy to understand and implement</li> <li>Versatile: Works on arrays, strings, linked lists</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#common-mistakes","title":"Common Mistakes","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#1-incorrect-boundary-conditions","title":"1. Incorrect Boundary Conditions","text":"<pre><code># Wrong: May cause index out of bounds\nwhile left &lt;= right:  # Should be left &lt; right for most cases\n\n# Correct: Proper boundary check\nwhile left &lt; right:\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#2-not-handling-edge-cases","title":"2. Not Handling Edge Cases","text":"<pre><code>def two_sum_sorted(arr, target):\n    # Always check for empty or single-element arrays\n    if len(arr) &lt; 2:\n        return []\n\n    left, right = 0, len(arr) - 1\n    # ... rest of implementation\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#3-forgetting-to-skip-duplicates","title":"3. Forgetting to Skip Duplicates","text":"<pre><code>def three_sum_unique(arr):\n    arr.sort()\n    result = []\n\n    for i in range(len(arr) - 2):\n        # Important: Skip duplicate values for first element\n        if i &gt; 0 and arr[i] == arr[i-1]:\n            continue\n        # ... rest of implementation\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#practice-problems","title":"Practice Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#easy","title":"Easy","text":"<ol> <li>Two Sum (sorted array)</li> <li>Valid Palindrome</li> <li>Remove Duplicates from Sorted Array</li> <li>Move Zeros</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#medium","title":"Medium","text":"<ol> <li>3Sum</li> <li>Container With Most Water</li> <li>Linked List Cycle II</li> <li>Remove Nth Node From End</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#hard","title":"Hard","text":"<ol> <li>Trapping Rain Water</li> <li>4Sum</li> <li>Minimum Window Substring (with sliding window)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Overview/#next-topics","title":"Next Topics","text":"<ul> <li>Opposite_Direction_Pointers - Deep dive into convergent pointers</li> <li>Same_Direction_Pointers - Fast and slow pointer patterns</li> <li>Sliding_Window_Overview - Related technique for subarray problems</li> <li>Two_Pointers_Problems - Practice problems and solutions</li> </ul>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/","title":"Two Pointers Problems","text":"<p>Practice problems that utilize the two pointers technique. Problems are organized by pattern type and difficulty level.</p>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#opposite-direction-pointers-problems","title":"Opposite Direction Pointers Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#easy-problems","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-two-sum-ii-input-array-is-sorted-leetcode-167","title":"1. Two Sum II - Input Array Is Sorted (LeetCode 167)","text":"<pre><code>def two_sum(numbers, target):\n    \"\"\"Find two numbers that add up to target in sorted array.\"\"\"\n    left, right = 0, len(numbers) - 1\n\n    while left &lt; right:\n        current_sum = numbers[left] + numbers[right]\n\n        if current_sum == target:\n            return [left + 1, right + 1]  # 1-indexed\n        elif current_sum &lt; target:\n            left += 1\n        else:\n            right -= 1\n\n    return []\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#2-valid-palindrome-leetcode-125","title":"2. Valid Palindrome (LeetCode 125)","text":"<pre><code>def is_palindrome(s):\n    \"\"\"Check if string is palindrome ignoring case and non-alphanumeric.\"\"\"\n    left, right = 0, len(s) - 1\n\n    while left &lt; right:\n        # Skip non-alphanumeric characters\n        while left &lt; right and not s[left].isalnum():\n            left += 1\n        while left &lt; right and not s[right].isalnum():\n            right -= 1\n\n        # Compare characters\n        if s[left].lower() != s[right].lower():\n            return False\n\n        left += 1\n        right -= 1\n\n    return True\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#3-reverse-string-leetcode-344","title":"3. Reverse String (LeetCode 344)","text":"<pre><code>def reverse_string(s):\n    \"\"\"Reverse string in-place.\"\"\"\n    left, right = 0, len(s) - 1\n\n    while left &lt; right:\n        s[left], s[right] = s[right], s[left]\n        left += 1\n        right -= 1\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#medium-problems","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-3sum-leetcode-15","title":"1. 3Sum (LeetCode 15)","text":"<pre><code>def three_sum(nums):\n    \"\"\"Find all unique triplets that sum to zero.\"\"\"\n    nums.sort()\n    result = []\n\n    for i in range(len(nums) - 2):\n        # Skip duplicates for first element\n        if i &gt; 0 and nums[i] == nums[i - 1]:\n            continue\n\n        left, right = i + 1, len(nums) - 1\n\n        while left &lt; right:\n            current_sum = nums[i] + nums[left] + nums[right]\n\n            if current_sum == 0:\n                result.append([nums[i], nums[left], nums[right]])\n\n                # Skip duplicates\n                while left &lt; right and nums[left] == nums[left + 1]:\n                    left += 1\n                while left &lt; right and nums[right] == nums[right - 1]:\n                    right -= 1\n\n                left += 1\n                right -= 1\n            elif current_sum &lt; 0:\n                left += 1\n            else:\n                right -= 1\n\n    return result\n\n# Time: O(n\u00b2), Space: O(1) excluding result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#2-container-with-most-water-leetcode-11","title":"2. Container With Most Water (LeetCode 11)","text":"<pre><code>def max_area(height):\n    \"\"\"Find two lines that form container with most water.\"\"\"\n    left, right = 0, len(height) - 1\n    max_water = 0\n\n    while left &lt; right:\n        # Calculate current area\n        width = right - left\n        current_area = min(height[left], height[right]) * width\n        max_water = max(max_water, current_area)\n\n        # Move pointer with smaller height\n        if height[left] &lt; height[right]:\n            left += 1\n        else:\n            right -= 1\n\n    return max_water\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#3-3sum-closest-leetcode-16","title":"3. 3Sum Closest (LeetCode 16)","text":"<pre><code>def three_sum_closest(nums, target):\n    \"\"\"Find three numbers whose sum is closest to target.\"\"\"\n    nums.sort()\n    n = len(nums)\n    closest_sum = float('inf')\n\n    for i in range(n - 2):\n        left, right = i + 1, n - 1\n\n        while left &lt; right:\n            current_sum = nums[i] + nums[left] + nums[right]\n\n            if abs(current_sum - target) &lt; abs(closest_sum - target):\n                closest_sum = current_sum\n\n            if current_sum == target:\n                return target\n            elif current_sum &lt; target:\n                left += 1\n            else:\n                right -= 1\n\n    return closest_sum\n\n# Time: O(n\u00b2), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#hard-problems","title":"Hard Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-trapping-rain-water-leetcode-42","title":"1. Trapping Rain Water (LeetCode 42)","text":"<pre><code>def trap(height):\n    \"\"\"Calculate trapped rainwater using two pointers.\"\"\"\n    if not height:\n        return 0\n\n    left, right = 0, len(height) - 1\n    left_max, right_max = 0, 0\n    water_trapped = 0\n\n    while left &lt; right:\n        if height[left] &lt; height[right]:\n            if height[left] &gt;= left_max:\n                left_max = height[left]\n            else:\n                water_trapped += left_max - height[left]\n            left += 1\n        else:\n            if height[right] &gt;= right_max:\n                right_max = height[right]\n            else:\n                water_trapped += right_max - height[right]\n            right -= 1\n\n    return water_trapped\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#same-direction-pointers-problems","title":"Same Direction Pointers Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#easy-problems_1","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-remove-duplicates-from-sorted-array-leetcode-26","title":"1. Remove Duplicates from Sorted Array (LeetCode 26)","text":"<pre><code>def remove_duplicates(nums):\n    \"\"\"Remove duplicates from sorted array in-place.\"\"\"\n    if not nums:\n        return 0\n\n    write_index = 1\n\n    for read_index in range(1, len(nums)):\n        if nums[read_index] != nums[read_index - 1]:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    return write_index\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#2-remove-element-leetcode-27","title":"2. Remove Element (LeetCode 27)","text":"<pre><code>def remove_element(nums, val):\n    \"\"\"Remove all instances of val in-place.\"\"\"\n    write_index = 0\n\n    for read_index in range(len(nums)):\n        if nums[read_index] != val:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    return write_index\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#3-move-zeroes-leetcode-283","title":"3. Move Zeroes (LeetCode 283)","text":"<pre><code>def move_zeroes(nums):\n    \"\"\"Move all zeros to end maintaining order of non-zeros.\"\"\"\n    write_index = 0\n\n    # Move all non-zeros to front\n    for read_index in range(len(nums)):\n        if nums[read_index] != 0:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    # Fill remaining with zeros\n    while write_index &lt; len(nums):\n        nums[write_index] = 0\n        write_index += 1\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#4-linked-list-cycle-leetcode-141","title":"4. Linked List Cycle (LeetCode 141)","text":"<pre><code>def has_cycle(head):\n    \"\"\"Detect if linked list has cycle using Floyd's algorithm.\"\"\"\n    if not head or not head.next:\n        return False\n\n    slow = fast = head\n\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n\n        if slow == fast:\n            return True\n\n    return False\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#medium-problems_1","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-remove-nth-node-from-end-of-list-leetcode-19","title":"1. Remove Nth Node From End of List (LeetCode 19)","text":"<pre><code>def remove_nth_from_end(head, n):\n    \"\"\"Remove nth node from end of linked list.\"\"\"\n    dummy = ListNode(0, head)\n    slow = fast = dummy\n\n    # Move fast pointer n+1 steps ahead\n    for _ in range(n + 1):\n        fast = fast.next\n\n    # Move both until fast reaches end\n    while fast:\n        slow = slow.next\n        fast = fast.next\n\n    # Remove nth node from end\n    slow.next = slow.next.next\n\n    return dummy.next\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#2-linked-list-cycle-ii-leetcode-142","title":"2. Linked List Cycle II (LeetCode 142)","text":"<pre><code>def detect_cycle(head):\n    \"\"\"Find the start of cycle in linked list.\"\"\"\n    if not head or not head.next:\n        return None\n\n    # Phase 1: Detect cycle\n    slow = fast = head\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        if slow == fast:\n            break\n    else:\n        return None\n\n    # Phase 2: Find cycle start\n    slow = head\n    while slow != fast:\n        slow = slow.next\n        fast = fast.next\n\n    return slow\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#3-remove-duplicates-from-sorted-array-ii-leetcode-80","title":"3. Remove Duplicates from Sorted Array II (LeetCode 80)","text":"<pre><code>def remove_duplicates(nums):\n    \"\"\"Remove duplicates so each element appears at most twice.\"\"\"\n    if len(nums) &lt;= 2:\n        return len(nums)\n\n    write_index = 2\n\n    for read_index in range(2, len(nums)):\n        if nums[read_index] != nums[write_index - 2]:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    return write_index\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#sliding-window-with-two-pointers","title":"Sliding Window with Two Pointers","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#medium-problems_2","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-longest-substring-without-repeating-characters-leetcode-3","title":"1. Longest Substring Without Repeating Characters (LeetCode 3)","text":"<pre><code>def length_of_longest_substring(s):\n    \"\"\"Find length of longest substring without repeating characters.\"\"\"\n    char_set = set()\n    left = 0\n    max_length = 0\n\n    for right in range(len(s)):\n        # Shrink window until no duplicates\n        while s[right] in char_set:\n            char_set.remove(s[left])\n            left += 1\n\n        char_set.add(s[right])\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Time: O(n), Space: O(min(m,n)) where m is charset size\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#2-max-consecutive-ones-iii-leetcode-1004","title":"2. Max Consecutive Ones III (LeetCode 1004)","text":"<pre><code>def longest_ones(nums, k):\n    \"\"\"Longest subarray of 1s after flipping at most k zeros.\"\"\"\n    left = 0\n    zero_count = 0\n    max_length = 0\n\n    for right in range(len(nums)):\n        if nums[right] == 0:\n            zero_count += 1\n\n        # Shrink window if too many zeros\n        while zero_count &gt; k:\n            if nums[left] == 0:\n                zero_count -= 1\n            left += 1\n\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#3-minimum-size-subarray-sum-leetcode-209","title":"3. Minimum Size Subarray Sum (LeetCode 209)","text":"<pre><code>def min_subarray_len(target, nums):\n    \"\"\"Minimum length subarray with sum &gt;= target.\"\"\"\n    left = 0\n    min_length = float('inf')\n    current_sum = 0\n\n    for right in range(len(nums)):\n        current_sum += nums[right]\n\n        # Shrink window while sum &gt;= target\n        while current_sum &gt;= target:\n            min_length = min(min_length, right - left + 1)\n            current_sum -= nums[left]\n            left += 1\n\n    return min_length if min_length != float('inf') else 0\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#string-problems-with-two-pointers","title":"String Problems with Two Pointers","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-valid-palindrome-ii-leetcode-680","title":"1. Valid Palindrome II (LeetCode 680)","text":"<pre><code>def valid_palindrome(s):\n    \"\"\"Check if string can be palindrome by deleting at most one character.\"\"\"\n    def is_palindrome_range(left, right):\n        while left &lt; right:\n            if s[left] != s[right]:\n                return False\n            left += 1\n            right -= 1\n        return True\n\n    left, right = 0, len(s) - 1\n\n    while left &lt; right:\n        if s[left] != s[right]:\n            # Try deleting either left or right character\n            return (is_palindrome_range(left + 1, right) or \n                    is_palindrome_range(left, right - 1))\n        left += 1\n        right -= 1\n\n    return True\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#2-is-subsequence-leetcode-392","title":"2. Is Subsequence (LeetCode 392)","text":"<pre><code>def is_subsequence(s, t):\n    \"\"\"Check if s is subsequence of t.\"\"\"\n    s_index = 0\n\n    for t_index in range(len(t)):\n        if s_index &lt; len(s) and s[s_index] == t[t_index]:\n            s_index += 1\n\n    return s_index == len(s)\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#advanced-two-pointer-problems","title":"Advanced Two Pointer Problems","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-sort-colors-leetcode-75","title":"1. Sort Colors (LeetCode 75)","text":"<pre><code>def sort_colors(nums):\n    \"\"\"Sort array of 0s, 1s, and 2s in-place (Dutch Flag Algorithm).\"\"\"\n    left, right = 0, len(nums) - 1\n    current = 0\n\n    while current &lt;= right:\n        if nums[current] == 0:\n            nums[left], nums[current] = nums[current], nums[left]\n            left += 1\n            current += 1\n        elif nums[current] == 1:\n            current += 1\n        else:  # nums[current] == 2\n            nums[current], nums[right] = nums[right], nums[current]\n            right -= 1\n            # Don't increment current, need to check swapped element\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#2-4sum-leetcode-18","title":"2. 4Sum (LeetCode 18)","text":"<pre><code>def four_sum(nums, target):\n    \"\"\"Find all unique quadruplets that sum to target.\"\"\"\n    nums.sort()\n    n = len(nums)\n    result = []\n\n    for i in range(n - 3):\n        if i &gt; 0 and nums[i] == nums[i - 1]:\n            continue\n\n        for j in range(i + 1, n - 2):\n            if j &gt; i + 1 and nums[j] == nums[j - 1]:\n                continue\n\n            left, right = j + 1, n - 1\n\n            while left &lt; right:\n                current_sum = nums[i] + nums[j] + nums[left] + nums[right]\n\n                if current_sum == target:\n                    result.append([nums[i], nums[j], nums[left], nums[right]])\n\n                    # Skip duplicates\n                    while left &lt; right and nums[left] == nums[left + 1]:\n                        left += 1\n                    while left &lt; right and nums[right] == nums[right - 1]:\n                        right -= 1\n\n                    left += 1\n                    right -= 1\n                elif current_sum &lt; target:\n                    left += 1\n                else:\n                    right -= 1\n\n    return result\n\n# Time: O(n\u00b3), Space: O(1) excluding result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#problem-solving-strategies","title":"Problem-Solving Strategies","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-choosing-the-right-pattern","title":"1. Choosing the Right Pattern","text":"<pre><code># Decision Tree for Two Pointers\ndef choose_pattern(problem_type):\n    if problem_type == \"target_sum_sorted\":\n        return \"opposite_direction\"\n    elif problem_type == \"palindrome\":\n        return \"opposite_direction\" \n    elif problem_type == \"remove_elements\":\n        return \"same_direction_read_write\"\n    elif problem_type == \"cycle_detection\":\n        return \"same_direction_fast_slow\"\n    elif problem_type == \"sliding_window\":\n        return \"same_direction_variable_gap\"\n    else:\n        return \"analyze_further\"\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#2-common-templates-by-problem-type","title":"2. Common Templates by Problem Type","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#target-sum-template","title":"Target Sum Template","text":"<pre><code>def target_sum_template(arr, target):\n    arr.sort()  # Often needed\n    left, right = 0, len(arr) - 1\n\n    while left &lt; right:\n        current_sum = arr[left] + arr[right]\n        if current_sum == target:\n            return [left, right]\n        elif current_sum &lt; target:\n            left += 1\n        else:\n            right -= 1\n    return []\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#array-modification-template","title":"Array Modification Template","text":"<pre><code>def modify_array_template(arr, condition):\n    write_index = 0\n\n    for read_index in range(len(arr)):\n        if condition(arr[read_index]):\n            arr[write_index] = arr[read_index]\n            write_index += 1\n\n    return write_index\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#cycle-detection-template","title":"Cycle Detection Template","text":"<pre><code>def detect_cycle_template(head):\n    if not head or not head.next:\n        return False\n\n    slow = fast = head\n\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        if slow == fast:\n            return True\n\n    return False\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#3-optimization-techniques","title":"3. Optimization Techniques","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#skip-duplicates","title":"Skip Duplicates","text":"<pre><code># In sorted arrays\nwhile left &lt; right and nums[left] == nums[left + 1]:\n    left += 1\nwhile left &lt; right and nums[right] == nums[right - 1]:\n    right -= 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#early-termination","title":"Early Termination","text":"<pre><code># For target sum problems\nif nums[i] + nums[i + 1] + nums[i + 2] &gt; target:\n    break  # Remaining triplets will be too large\nif nums[i] + nums[n - 2] + nums[n - 1] &lt; target:\n    continue  # Current triplet too small\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#practice-schedule","title":"Practice Schedule","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#week-1-basic-two-pointers","title":"Week 1: Basic Two Pointers","text":"<ol> <li>Two Sum II - Input Array Is Sorted</li> <li>Valid Palindrome</li> <li>Remove Duplicates from Sorted Array</li> <li>Move Zeroes</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#week-2-intermediate-problems","title":"Week 2: Intermediate Problems","text":"<ol> <li>3Sum</li> <li>Container With Most Water</li> <li>Linked List Cycle</li> <li>Remove Nth Node From End</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#week-3-advanced-applications","title":"Week 3: Advanced Applications","text":"<ol> <li>Trapping Rain Water</li> <li>4Sum</li> <li>Minimum Window Substring</li> <li>Sort Colors</li> </ol>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#1-boundary-conditions","title":"1. Boundary Conditions","text":"<pre><code># Always check for empty input\nif not arr:\n    return default_value\n\n# Proper loop conditions\nwhile left &lt; right:  # Not left &lt;= right for most cases\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#2-pointer-updates","title":"2. Pointer Updates","text":"<pre><code># Ensure pointers always make progress\nif condition:\n    left += 1\nelse:\n    right -= 1  # Both branches should move pointers\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#3-duplicate-handling","title":"3. Duplicate Handling","text":"<pre><code># Skip duplicates properly in sorted arrays\nwhile left &lt; right and arr[left] == arr[left + 1]:\n    left += 1\n# Similar for right pointer\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithmic_Patterns/Two_Pointers/Two_Pointers_Problems/#next-topics","title":"Next Topics","text":"<ul> <li>Opposite_Direction_Pointers - Deep dive into convergent pointers</li> <li>Same_Direction_Pointers - Fast and slow pointer patterns</li> <li>Sliding_Window_Overview - Related technique for subarray problems</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/","title":"Binary Search Fundamentals","text":"<p>Binary search is one of the most important and efficient search algorithms. It uses a divide-and-conquer approach to find elements in sorted arrays with O(log n) time complexity.</p>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#how-binary-search-works","title":"How Binary Search Works","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#core-concept","title":"Core Concept","text":"<p>Binary search works by repeatedly dividing the search space in half: 1. Compare the target with the middle element 2. If equal, we found the target 3. If target is smaller, search the left half 4. If target is larger, search the right half 5. Repeat until found or search space is empty</p>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#visual-example","title":"Visual Example","text":"<pre><code>Array: [1, 3, 5, 7, 9, 11, 13, 15]\nTarget: 7\n\nStep 1: left=0, right=7, mid=3\n[1, 3, 5, 7, 9, 11, 13, 15]\n          \u2191\narr[3] = 7 = target \u2192 Found at index 3!\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#implementation","title":"Implementation","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#iterative-approach-recommended","title":"Iterative Approach (Recommended)","text":"<pre><code>def binary_search(arr, target):\n    \"\"\"\n    Search for target in sorted array using binary search.\n\n    Args:\n        arr: Sorted array of comparable elements\n        target: Element to search for\n\n    Returns:\n        Index of target if found, -1 otherwise\n    \"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt;= right:\n        # Calculate middle index (avoid overflow)\n        mid = left + (right - left) // 2\n\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            left = mid + 1  # Search right half\n        else:\n            right = mid - 1  # Search left half\n\n    return -1  # Target not found\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#recursive-approach","title":"Recursive Approach","text":"<pre><code>def binary_search_recursive(arr, target, left=0, right=None):\n    \"\"\"\n    Recursive implementation of binary search.\n    \"\"\"\n    if right is None:\n        right = len(arr) - 1\n\n    # Base case: search space is empty\n    if left &gt; right:\n        return -1\n\n    mid = left + (right - left) // 2\n\n    if arr[mid] == target:\n        return mid\n    elif arr[mid] &lt; target:\n        return binary_search_recursive(arr, target, mid + 1, right)\n    else:\n        return binary_search_recursive(arr, target, left, mid - 1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#time-and-space-complexity","title":"Time and Space Complexity","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#time-complexity-olog-n","title":"Time Complexity: O(log n)","text":"<ul> <li>Each comparison eliminates half of the remaining elements</li> <li>Maximum comparisons: log\u2082(n)</li> <li>Example: Array of 1000 elements needs at most 10 comparisons</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#space-complexity","title":"Space Complexity","text":"<ul> <li>Iterative: O(1) - only uses a few variables</li> <li>Recursive: O(log n) - due to call stack</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#key-requirements","title":"Key Requirements","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#1-sorted-data","title":"1. Sorted Data","text":"<p>Binary search only works on sorted arrays: <pre><code># Correct: sorted array\nsorted_arr = [1, 3, 5, 7, 9, 11]\nresult = binary_search(sorted_arr, 7)  # Works correctly\n\n# Incorrect: unsorted array\nunsorted_arr = [3, 1, 7, 5, 9, 11]\nresult = binary_search(unsorted_arr, 7)  # May give wrong result\n</code></pre></p>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#2-comparable-elements","title":"2. Comparable Elements","text":"<p>Elements must be comparable with &lt;, &gt;, == operators: <pre><code># Works with numbers\nnumbers = [1, 2, 3, 4, 5]\n\n# Works with strings (lexicographical order)\nwords = [\"apple\", \"banana\", \"cherry\", \"date\"]\n\n# Works with custom objects if comparison is defined\n</code></pre></p>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#common-pitfalls-and-solutions","title":"Common Pitfalls and Solutions","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#1-integer-overflow","title":"1. Integer Overflow","text":"<pre><code># Wrong: Can overflow in other languages\nmid = (left + right) // 2\n\n# Correct: Prevents overflow\nmid = left + (right - left) // 2\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#2-infinite-loops","title":"2. Infinite Loops","text":"<pre><code># Ensure loop terminates\nwhile left &lt;= right:  # Note: &lt;= not &lt;\n    mid = left + (right - left) // 2\n    if arr[mid] == target:\n        return mid\n    elif arr[mid] &lt; target:\n        left = mid + 1   # Important: +1\n    else:\n        right = mid - 1  # Important: -1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#3-off-by-one-errors","title":"3. Off-by-One Errors","text":"<pre><code># Correct initialization\nleft, right = 0, len(arr) - 1  # right is last valid index\n\n# Correct updates\nleft = mid + 1   # Exclude mid from next search\nright = mid - 1  # Exclude mid from next search\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#variations-and-extensions","title":"Variations and Extensions","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#1-find-first-occurrence","title":"1. Find First Occurrence","text":"<pre><code>def find_first_occurrence(arr, target):\n    left, right = 0, len(arr) - 1\n    result = -1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if arr[mid] == target:\n            result = mid\n            right = mid - 1  # Continue searching left\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#2-find-last-occurrence","title":"2. Find Last Occurrence","text":"<pre><code>def find_last_occurrence(arr, target):\n    left, right = 0, len(arr) - 1\n    result = -1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if arr[mid] == target:\n            result = mid\n            left = mid + 1  # Continue searching right\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#3-find-insertion-point","title":"3. Find Insertion Point","text":"<pre><code>def find_insertion_point(arr, target):\n    \"\"\"Find index where target should be inserted to maintain sorted order.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return left  # Insertion point\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#practical-examples","title":"Practical Examples","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#example-1-search-in-library-catalog","title":"Example 1: Search in Library Catalog","text":"<pre><code>def search_book(catalog, isbn):\n    \"\"\"Search for book by ISBN in sorted catalog.\"\"\"\n    return binary_search([book.isbn for book in catalog], isbn)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#example-2-finding-square-root","title":"Example 2: Finding Square Root","text":"<pre><code>def sqrt_binary_search(x, precision=6):\n    \"\"\"Find square root using binary search.\"\"\"\n    if x &lt; 0:\n        return None\n\n    left, right = 0, max(1, x)\n\n    while right - left &gt; 10**(-precision):\n        mid = (left + right) / 2\n        if mid * mid &gt; x:\n            right = mid\n        else:\n            left = mid\n\n    return (left + right) / 2\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#when-to-use-binary-search","title":"When to Use Binary Search","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#good-for","title":"\u2705 Good for:","text":"<ul> <li>Sorted arrays or lists</li> <li>Large datasets (&gt; 100 elements)</li> <li>Frequent searches on static data</li> <li>Finding boundaries or ranges</li> <li>Mathematical problems (finding roots, etc.)</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#not-suitable-for","title":"\u274c Not suitable for:","text":"<ul> <li>Unsorted data</li> <li>Linked lists (no random access)</li> <li>Very small datasets (&lt; 10 elements)</li> <li>Data that changes frequently</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#performance-comparison","title":"Performance Comparison","text":"<pre><code>import time\nimport random\n\n# Generate test data\ndata = sorted(random.randint(1, 10000) for _ in range(10000))\ntarget = random.choice(data)\n\n# Linear search timing\nstart = time.time()\nfor _ in range(1000):\n    linear_search(data, target)\nlinear_time = time.time() - start\n\n# Binary search timing\nstart = time.time()\nfor _ in range(1000):\n    binary_search(data, target)\nbinary_time = time.time() - start\n\nprint(f\"Linear search: {linear_time:.4f}s\")\nprint(f\"Binary search: {binary_time:.4f}s\")\nprint(f\"Speedup: {linear_time/binary_time:.1f}x\")\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Fundamentals/#next-topics","title":"Next Topics","text":"<ul> <li>Binary_Search_Variations - Advanced patterns and applications</li> <li>Search_Problems - Practice problems using binary search</li> <li>Sorting_Algorithms_Overview - Preparing data for binary search</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/","title":"Binary Search Variations","text":"<p>While basic binary search finds if an element exists, many real-world problems require variations of binary search. These patterns extend the core concept to solve more complex problems.</p>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#common-binary-search-patterns","title":"Common Binary Search Patterns","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#1-find-first-occurrence","title":"1. Find First Occurrence","text":"<p>Find the leftmost occurrence of a target in a sorted array with duplicates.</p> <pre><code>def find_first_occurrence(arr, target):\n    \"\"\"Find the first (leftmost) occurrence of target.\"\"\"\n    left, right = 0, len(arr) - 1\n    result = -1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if arr[mid] == target:\n            result = mid\n            right = mid - 1  # Continue searching left\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return result\n\n# Example: [1, 2, 2, 2, 3], target = 2\n# Returns: 1 (first occurrence at index 1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#2-find-last-occurrence","title":"2. Find Last Occurrence","text":"<p>Find the rightmost occurrence of a target.</p> <pre><code>def find_last_occurrence(arr, target):\n    \"\"\"Find the last (rightmost) occurrence of target.\"\"\"\n    left, right = 0, len(arr) - 1\n    result = -1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if arr[mid] == target:\n            result = mid\n            left = mid + 1  # Continue searching right\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return result\n\n# Example: [1, 2, 2, 2, 3], target = 2\n# Returns: 3 (last occurrence at index 3)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#3-find-insert-position","title":"3. Find Insert Position","text":"<p>Find where to insert target to maintain sorted order.</p> <pre><code>def search_insert_position(arr, target):\n    \"\"\"Find insertion point for target in sorted array.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return left  # Insertion position\n\n# Example: [1, 3, 5, 6], target = 5 \u2192 returns 2\n# Example: [1, 3, 5, 6], target = 2 \u2192 returns 1\n# Example: [1, 3, 5, 6], target = 7 \u2192 returns 4\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#4-find-range","title":"4. Find Range","text":"<p>Find the range [first, last] of target occurrences.</p> <pre><code>def find_range(arr, target):\n    \"\"\"Find range of target occurrences.\"\"\"\n    def find_boundary(arr, target, find_left):\n        left, right = 0, len(arr) - 1\n        result = -1\n\n        while left &lt;= right:\n            mid = left + (right - left) // 2\n\n            if arr[mid] == target:\n                result = mid\n                if find_left:\n                    right = mid - 1  # Search left\n                else:\n                    left = mid + 1   # Search right\n            elif arr[mid] &lt; target:\n                left = mid + 1\n            else:\n                right = mid - 1\n\n        return result\n\n    first = find_boundary(arr, target, True)\n    if first == -1:\n        return [-1, -1]\n\n    last = find_boundary(arr, target, False)\n    return [first, last]\n\n# Example: [5, 7, 7, 8, 8, 10], target = 8\n# Returns: [3, 4]\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#advanced-binary-search-patterns","title":"Advanced Binary Search Patterns","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#1-peak-finding","title":"1. Peak Finding","text":"<p>Find a peak element (greater than its neighbors).</p> <pre><code>def find_peak_element(arr):\n    \"\"\"Find any peak element in the array.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt; right:\n        mid = left + (right - left) // 2\n\n        if arr[mid] &gt; arr[mid + 1]:\n            # Peak is in left half (including mid)\n            right = mid\n        else:\n            # Peak is in right half\n            left = mid + 1\n\n    return left\n\n# Example: [1, 2, 3, 1] \u2192 returns 2 (element 3 at index 2)\n# Example: [1, 2, 1, 3, 5, 6, 4] \u2192 returns 1 or 5 (multiple peaks)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#2-search-in-rotated-sorted-array","title":"2. Search in Rotated Sorted Array","text":"<p>Search in a sorted array that has been rotated.</p> <pre><code>def search_rotated_array(arr, target):\n    \"\"\"Search in rotated sorted array.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if arr[mid] == target:\n            return mid\n\n        # Check which half is sorted\n        if arr[left] &lt;= arr[mid]:  # Left half is sorted\n            if arr[left] &lt;= target &lt; arr[mid]:\n                right = mid - 1  # Target in left half\n            else:\n                left = mid + 1   # Target in right half\n        else:  # Right half is sorted\n            if arr[mid] &lt; target &lt;= arr[right]:\n                left = mid + 1   # Target in right half\n            else:\n                right = mid - 1  # Target in left half\n\n    return -1\n\n# Example: [4, 5, 6, 7, 0, 1, 2], target = 0 \u2192 returns 4\n# Example: [4, 5, 6, 7, 0, 1, 2], target = 3 \u2192 returns -1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#3-find-minimum-in-rotated-array","title":"3. Find Minimum in Rotated Array","text":"<p>Find the minimum element in a rotated sorted array.</p> <pre><code>def find_min_rotated(arr):\n    \"\"\"Find minimum element in rotated sorted array.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt; right:\n        mid = left + (right - left) // 2\n\n        if arr[mid] &gt; arr[right]:\n            # Minimum is in right half\n            left = mid + 1\n        else:\n            # Minimum is in left half (including mid)\n            right = mid\n\n    return arr[left]\n\n# Example: [3, 4, 5, 1, 2] \u2192 returns 1\n# Example: [4, 5, 6, 7, 0, 1, 2] \u2192 returns 0\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#binary-search-on-answer-space","title":"Binary Search on Answer Space","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#1-square-root","title":"1. Square Root","text":"<p>Find integer square root using binary search.</p> <pre><code>def sqrt_binary_search(x):\n    \"\"\"Find integer square root using binary search.\"\"\"\n    if x &lt; 0:\n        return -1\n    if x &lt; 2:\n        return x\n\n    left, right = 1, x // 2\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n        square = mid * mid\n\n        if square == x:\n            return mid\n        elif square &lt; x:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return right  # Largest integer whose square &lt;= x\n\n# Example: sqrt(8) \u2192 returns 2 (since 2\u00b2 = 4 \u2264 8 &lt; 3\u00b2 = 9)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#2-find-kth-smallest-element","title":"2. Find Kth Smallest Element","text":"<p>Find kth smallest element in sorted matrix.</p> <pre><code>def kth_smallest_in_matrix(matrix, k):\n    \"\"\"Find kth smallest element in row and column sorted matrix.\"\"\"\n    n = len(matrix)\n    left, right = matrix[0][0], matrix[n-1][n-1]\n\n    def count_less_equal(target):\n        \"\"\"Count elements &lt;= target.\"\"\"\n        count = 0\n        row, col = n - 1, 0\n\n        while row &gt;= 0 and col &lt; n:\n            if matrix[row][col] &lt;= target:\n                count += row + 1\n                col += 1\n            else:\n                row -= 1\n\n        return count\n\n    while left &lt; right:\n        mid = left + (right - left) // 2\n\n        if count_less_equal(mid) &lt; k:\n            left = mid + 1\n        else:\n            right = mid\n\n    return left\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#template-for-binary-search-variations","title":"Template for Binary Search Variations","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#general-template","title":"General Template","text":"<pre><code>def binary_search_template(arr, target):\n    \"\"\"General template for binary search variations.\"\"\"\n    left, right = 0, len(arr) - 1\n\n    while left &lt;= right:  # or left &lt; right for some variations\n        mid = left + (right - left) // 2\n\n        if condition_met(arr[mid], target):\n            return mid  # or update result and continue\n        elif arr[mid] &lt; target:  # or custom condition\n            left = mid + 1\n        else:\n            right = mid - 1  # or right = mid\n\n    return left  # or right, or -1, depending on problem\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#key-decisions","title":"Key Decisions","text":"<ol> <li>Loop condition: <code>left &lt;= right</code> vs <code>left &lt; right</code></li> <li>Update strategy: <code>left = mid + 1</code> vs <code>left = mid</code></li> <li>Return value: <code>left</code>, <code>right</code>, <code>mid</code>, or <code>-1</code></li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#1-infinite-loops","title":"1. Infinite Loops","text":"<pre><code># Wrong: Can cause infinite loop\nwhile left &lt; right:\n    mid = left + (right - left) // 2\n    if condition:\n        left = mid  # Should be mid + 1\n    else:\n        right = mid - 1\n\n# Correct: Ensure progress\nwhile left &lt; right:\n    mid = left + (right - left) // 2\n    if condition:\n        left = mid + 1\n    else:\n        right = mid\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#2-off-by-one-errors","title":"2. Off-by-One Errors","text":"<pre><code># Be careful with boundary updates\nif arr[mid] == target:\n    result = mid\n    right = mid - 1  # For first occurrence\n    # vs\n    left = mid + 1   # For last occurrence\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#3-integer-overflow","title":"3. Integer Overflow","text":"<pre><code># Wrong: Can overflow in other languages\nmid = (left + right) // 2\n\n# Correct: Prevents overflow\nmid = left + (right - left) // 2\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#practice-problems","title":"Practice Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#easy","title":"Easy","text":"<ol> <li>First Bad Version</li> <li>Search Insert Position</li> <li>Find First and Last Position</li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#medium","title":"Medium","text":"<ol> <li>Search in Rotated Sorted Array</li> <li>Find Peak Element</li> <li>Find Minimum in Rotated Sorted Array</li> <li>Kth Smallest Element in Sorted Matrix</li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#hard","title":"Hard","text":"<ol> <li>Median of Two Sorted Arrays</li> <li>Split Array Largest Sum</li> <li>Capacity to Ship Packages</li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Binary_Search_Variations/#next-topics","title":"Next Topics","text":"<ul> <li>Search_Problems - Practice problems using binary search variations</li> <li>Sorting_Algorithms_Overview - Preparing data for binary search</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/","title":"Search Algorithms Overview","text":"<p>Search algorithms are fundamental techniques used to find specific elements within data structures. The choice of search algorithm depends on the data organization, size, and performance requirements.</p>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#types-of-search-algorithms","title":"Types of Search Algorithms","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#1-linear-search","title":"1. Linear Search","text":"<ul> <li>Time Complexity: O(n)</li> <li>Space Complexity: O(1)</li> <li>Use Case: Unsorted data, small datasets</li> <li>How it works: Check each element sequentially</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#2-binary-search","title":"2. Binary Search","text":"<ul> <li>Time Complexity: O(log n)</li> <li>Space Complexity: O(1) iterative, O(log n) recursive</li> <li>Use Case: Sorted data</li> <li>How it works: Divide and conquer approach</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#3-hash-based-search","title":"3. Hash-based Search","text":"<ul> <li>Time Complexity: O(1) average, O(n) worst case</li> <li>Space Complexity: O(n)</li> <li>Use Case: When fast lookups are needed</li> <li>How it works: Direct access using hash function</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#search-algorithm-comparison","title":"Search Algorithm Comparison","text":"Algorithm Best Case Average Case Worst Case Space Prerequisites Linear O(1) O(n) O(n) O(1) None Binary O(1) O(log n) O(log n) O(1) Sorted data Hash O(1) O(1) O(n) O(n) Hash function"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#when-to-use-each-algorithm","title":"When to Use Each Algorithm","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#linear-search","title":"Linear Search","text":"<pre><code>def linear_search(arr, target):\n    for i in range(len(arr)):\n        if arr[i] == target:\n            return i\n    return -1\n\n# Use when:\n# - Data is unsorted\n# - Small datasets (&lt; 100 elements)\n# - Simple implementation needed\n# - Memory is very limited\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#binary-search","title":"Binary Search","text":"<pre><code>def binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n\n    while left &lt;= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return -1\n\n# Use when:\n# - Data is sorted\n# - Large datasets\n# - Logarithmic performance needed\n# - Memory usage should be minimal\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#hash-based-search","title":"Hash-based Search","text":"<pre><code># Using Python dictionary (hash table)\ndef create_hash_table(arr):\n    hash_table = {}\n    for i, value in enumerate(arr):\n        hash_table[value] = i\n    return hash_table\n\ndef hash_search(hash_table, target):\n    return hash_table.get(target, -1)\n\n# Use when:\n# - Very frequent searches\n# - Constant time lookup needed\n# - Extra memory is available\n# - Data doesn't change often\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#search-in-different-data-structures","title":"Search in Different Data Structures","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#arrayslists","title":"Arrays/Lists","text":"<ul> <li>Unsorted: Linear search O(n)</li> <li>Sorted: Binary search O(log n)</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#linked-lists","title":"Linked Lists","text":"<ul> <li>Always: Linear search O(n)</li> <li>No random access: Binary search not applicable</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#trees","title":"Trees","text":"<ul> <li>Binary Search Tree: O(log n) average, O(n) worst</li> <li>Balanced Trees: O(log n) guaranteed</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#hash-tables","title":"Hash Tables","text":"<ul> <li>Direct access: O(1) average</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#practical-considerations","title":"Practical Considerations","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#1-data-size","title":"1. Data Size","text":"<ul> <li>Small data (&lt; 100): Linear search is often fine</li> <li>Medium data (100-10000): Consider sorting + binary search</li> <li>Large data (&gt; 10000): Hash tables or advanced data structures</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#2-search-frequency","title":"2. Search Frequency","text":"<ul> <li>One-time search: Linear search</li> <li>Frequent searches: Invest in sorting or hash tables</li> <li>Real-time requirements: Hash tables</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#3-memory-constraints","title":"3. Memory Constraints","text":"<ul> <li>Limited memory: Linear or binary search</li> <li>Abundant memory: Hash tables</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#4-data-mutability","title":"4. Data Mutability","text":"<ul> <li>Static data: Sort once, use binary search</li> <li>Frequently changing: Hash tables or linear search</li> <li>Append-only: Consider keeping sorted order</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#advanced-search-techniques","title":"Advanced Search Techniques","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#1-interpolation-search","title":"1. Interpolation Search","text":"<ul> <li>Better than binary search for uniformly distributed data</li> <li>O(log log n) average case</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#2-exponential-search","title":"2. Exponential Search","text":"<ul> <li>Good for unbounded/infinite arrays</li> <li>O(log n) time complexity</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#3-ternary-search","title":"3. Ternary Search","text":"<ul> <li>Divides array into three parts</li> <li>Useful for finding maximum/minimum in unimodal functions</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#implementation-tips","title":"Implementation Tips","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#1-handle-edge-cases","title":"1. Handle Edge Cases","text":"<pre><code>def robust_binary_search(arr, target):\n    if not arr:  # Empty array\n        return -1\n\n    left, right = 0, len(arr) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2  # Avoid overflow\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return -1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#2-consider-return-values","title":"2. Consider Return Values","text":"<ul> <li>Return index vs boolean vs element</li> <li>Handle duplicates appropriately</li> <li>Define behavior for not found cases</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Algorithms_Overview/#next-topics","title":"Next Topics","text":"<ul> <li>Binary_Search_Fundamentals - Deep dive into binary search</li> <li>Binary_Search_Variations - Advanced binary search patterns</li> <li>Search_Problems - Practice problems and applications</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/","title":"Search Algorithm Problems","text":"<p>This section contains practice problems that use various search algorithms. Problems are organized by difficulty and algorithm type.</p>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#linear-search-problems","title":"Linear Search Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#easy-problems","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#1-find-maximum-element","title":"1. Find Maximum Element","text":"<pre><code>def find_maximum(arr):\n    \"\"\"Find the maximum element in an unsorted array.\"\"\"\n    if not arr:\n        return None\n\n    max_element = arr[0]\n    for element in arr[1:]:\n        if element &gt; max_element:\n            max_element = element\n\n    return max_element\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#2-count-occurrences","title":"2. Count Occurrences","text":"<pre><code>def count_occurrences(arr, target):\n    \"\"\"Count how many times target appears in array.\"\"\"\n    count = 0\n    for element in arr:\n        if element == target:\n            count += 1\n    return count\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#3-find-all-indices","title":"3. Find All Indices","text":"<pre><code>def find_all_indices(arr, target):\n    \"\"\"Find all indices where target appears.\"\"\"\n    indices = []\n    for i, element in enumerate(arr):\n        if element == target:\n            indices.append(i)\n    return indices\n\n# Time: O(n), Space: O(k) where k is number of occurrences\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#binary-search-problems","title":"Binary Search Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#easy-problems_1","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#1-search-insert-position-leetcode-35","title":"1. Search Insert Position (LeetCode 35)","text":"<pre><code>def search_insert(nums, target):\n    \"\"\"Find position to insert target in sorted array.\"\"\"\n    left, right = 0, len(nums) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if nums[mid] == target:\n            return mid\n        elif nums[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return left\n\n# Example: nums = [1,3,5,6], target = 5 \u2192 return 2\n# Example: nums = [1,3,5,6], target = 2 \u2192 return 1\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#2-first-bad-version-leetcode-278","title":"2. First Bad Version (LeetCode 278)","text":"<pre><code>def first_bad_version(n):\n    \"\"\"Find first bad version using binary search.\"\"\"\n    def is_bad_version(version):\n        # This function is provided by the problem\n        pass\n\n    left, right = 1, n\n\n    while left &lt; right:\n        mid = left + (right - left) // 2\n\n        if is_bad_version(mid):\n            right = mid  # First bad could be mid\n        else:\n            left = mid + 1  # First bad is after mid\n\n    return left\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#3-perfect-square-leetcode-367","title":"3. Perfect Square (LeetCode 367)","text":"<pre><code>def is_perfect_square(num):\n    \"\"\"Check if number is perfect square using binary search.\"\"\"\n    if num &lt; 1:\n        return False\n\n    left, right = 1, num\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n        square = mid * mid\n\n        if square == num:\n            return True\n        elif square &lt; num:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return False\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#medium-problems","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#1-find-first-and-last-position-leetcode-34","title":"1. Find First and Last Position (LeetCode 34)","text":"<pre><code>def search_range(nums, target):\n    \"\"\"Find first and last position of target in sorted array.\"\"\"\n    def find_boundary(is_first):\n        left, right = 0, len(nums) - 1\n        result = -1\n\n        while left &lt;= right:\n            mid = left + (right - left) // 2\n\n            if nums[mid] == target:\n                result = mid\n                if is_first:\n                    right = mid - 1  # Continue left for first\n                else:\n                    left = mid + 1   # Continue right for last\n            elif nums[mid] &lt; target:\n                left = mid + 1\n            else:\n                right = mid - 1\n\n        return result\n\n    first = find_boundary(True)\n    if first == -1:\n        return [-1, -1]\n\n    last = find_boundary(False)\n    return [first, last]\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#2-search-in-rotated-sorted-array-leetcode-33","title":"2. Search in Rotated Sorted Array (LeetCode 33)","text":"<pre><code>def search_rotated(nums, target):\n    \"\"\"Search target in rotated sorted array.\"\"\"\n    left, right = 0, len(nums) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if nums[mid] == target:\n            return mid\n\n        # Determine which half is sorted\n        if nums[left] &lt;= nums[mid]:  # Left half sorted\n            if nums[left] &lt;= target &lt; nums[mid]:\n                right = mid - 1\n            else:\n                left = mid + 1\n        else:  # Right half sorted\n            if nums[mid] &lt; target &lt;= nums[right]:\n                left = mid + 1\n            else:\n                right = mid - 1\n\n    return -1\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#3-find-peak-element-leetcode-162","title":"3. Find Peak Element (LeetCode 162)","text":"<pre><code>def find_peak_element(nums):\n    \"\"\"Find any peak element in the array.\"\"\"\n    left, right = 0, len(nums) - 1\n\n    while left &lt; right:\n        mid = left + (right - left) // 2\n\n        if nums[mid] &gt; nums[mid + 1]:\n            right = mid  # Peak in left half (including mid)\n        else:\n            left = mid + 1  # Peak in right half\n\n    return left\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#4-find-minimum-in-rotated-array-leetcode-153","title":"4. Find Minimum in Rotated Array (LeetCode 153)","text":"<pre><code>def find_min(nums):\n    \"\"\"Find minimum element in rotated sorted array.\"\"\"\n    left, right = 0, len(nums) - 1\n\n    while left &lt; right:\n        mid = left + (right - left) // 2\n\n        if nums[mid] &gt; nums[right]:\n            left = mid + 1  # Min in right half\n        else:\n            right = mid     # Min in left half (including mid)\n\n    return nums[left]\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#hard-problems","title":"Hard Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#1-median-of-two-sorted-arrays-leetcode-4","title":"1. Median of Two Sorted Arrays (LeetCode 4)","text":"<pre><code>def find_median_sorted_arrays(nums1, nums2):\n    \"\"\"Find median of two sorted arrays.\"\"\"\n    # Ensure nums1 is shorter\n    if len(nums1) &gt; len(nums2):\n        nums1, nums2 = nums2, nums1\n\n    m, n = len(nums1), len(nums2)\n    left, right = 0, m\n\n    while left &lt;= right:\n        partition1 = (left + right) // 2\n        partition2 = (m + n + 1) // 2 - partition1\n\n        # Handle edge cases\n        max_left1 = float('-inf') if partition1 == 0 else nums1[partition1 - 1]\n        min_right1 = float('inf') if partition1 == m else nums1[partition1]\n\n        max_left2 = float('-inf') if partition2 == 0 else nums2[partition2 - 1]\n        min_right2 = float('inf') if partition2 == n else nums2[partition2]\n\n        if max_left1 &lt;= min_right2 and max_left2 &lt;= min_right1:\n            # Found correct partition\n            if (m + n) % 2 == 0:\n                return (max(max_left1, max_left2) + min(min_right1, min_right2)) / 2\n            else:\n                return max(max_left1, max_left2)\n        elif max_left1 &gt; min_right2:\n            right = partition1 - 1\n        else:\n            left = partition1 + 1\n\n# Time: O(log(min(m,n))), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#binary-search-on-answer-space","title":"Binary Search on Answer Space","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#1-capacity-to-ship-packages-leetcode-1011","title":"1. Capacity to Ship Packages (LeetCode 1011)","text":"<pre><code>def ship_within_days(weights, days):\n    \"\"\"Find minimum ship capacity to ship all packages within days.\"\"\"\n    def can_ship(capacity):\n        current_weight = 0\n        days_needed = 1\n\n        for weight in weights:\n            if current_weight + weight &gt; capacity:\n                days_needed += 1\n                current_weight = weight\n            else:\n                current_weight += weight\n\n        return days_needed &lt;= days\n\n    left, right = max(weights), sum(weights)\n\n    while left &lt; right:\n        mid = left + (right - left) // 2\n\n        if can_ship(mid):\n            right = mid\n        else:\n            left = mid + 1\n\n    return left\n\n# Time: O(n * log(sum - max)), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#2-koko-eating-bananas-leetcode-875","title":"2. Koko Eating Bananas (LeetCode 875)","text":"<pre><code>def min_eating_speed(piles, h):\n    \"\"\"Find minimum eating speed to finish all bananas in h hours.\"\"\"\n    import math\n\n    def can_finish(speed):\n        hours = 0\n        for pile in piles:\n            hours += math.ceil(pile / speed)\n        return hours &lt;= h\n\n    left, right = 1, max(piles)\n\n    while left &lt; right:\n        mid = left + (right - left) // 2\n\n        if can_finish(mid):\n            right = mid\n        else:\n            left = mid + 1\n\n    return left\n\n# Time: O(n * log(max_pile)), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#two-pointer-search-problems","title":"Two Pointer Search Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#1-two-sum-ii-sorted-array-leetcode-167","title":"1. Two Sum II - Sorted Array (LeetCode 167)","text":"<pre><code>def two_sum_sorted(numbers, target):\n    \"\"\"Find two numbers that add up to target in sorted array.\"\"\"\n    left, right = 0, len(numbers) - 1\n\n    while left &lt; right:\n        current_sum = numbers[left] + numbers[right]\n\n        if current_sum == target:\n            return [left + 1, right + 1]  # 1-indexed\n        elif current_sum &lt; target:\n            left += 1\n        else:\n            right -= 1\n\n    return []  # No solution found\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#2-3sum-leetcode-15","title":"2. 3Sum (LeetCode 15)","text":"<pre><code>def three_sum(nums):\n    \"\"\"Find all unique triplets that sum to zero.\"\"\"\n    nums.sort()\n    result = []\n\n    for i in range(len(nums) - 2):\n        if i &gt; 0 and nums[i] == nums[i - 1]:\n            continue  # Skip duplicates\n\n        left, right = i + 1, len(nums) - 1\n\n        while left &lt; right:\n            current_sum = nums[i] + nums[left] + nums[right]\n\n            if current_sum == 0:\n                result.append([nums[i], nums[left], nums[right]])\n\n                # Skip duplicates\n                while left &lt; right and nums[left] == nums[left + 1]:\n                    left += 1\n                while left &lt; right and nums[right] == nums[right - 1]:\n                    right -= 1\n\n                left += 1\n                right -= 1\n            elif current_sum &lt; 0:\n                left += 1\n            else:\n                right -= 1\n\n    return result\n\n# Time: O(n\u00b2), Space: O(1) excluding result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#problem-solving-strategies","title":"Problem-Solving Strategies","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#1-identify-the-pattern","title":"1. Identify the Pattern","text":"<ul> <li>Sorted array \u2192 Binary Search</li> <li>Find pair/triplet with sum \u2192 Two Pointers</li> <li>Search in range \u2192 Binary Search on Answer</li> <li>Unsorted array \u2192 Linear Search or Hash Map</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#2-binary-search-decision-tree","title":"2. Binary Search Decision Tree","text":"<pre><code>Is array sorted?\n\u251c\u2500\u2500 Yes\n\u2502   \u251c\u2500\u2500 Find exact element? \u2192 Basic Binary Search\n\u2502   \u251c\u2500\u2500 Find boundary? \u2192 Modified Binary Search\n\u2502   \u2514\u2500\u2500 Find in rotated? \u2192 Rotated Array Search\n\u2514\u2500\u2500 No\n    \u251c\u2500\u2500 Can sort? \u2192 Sort + Binary Search\n    \u251c\u2500\u2500 Small array? \u2192 Linear Search\n    \u2514\u2500\u2500 Need fast lookup? \u2192 Hash Map\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#3-common-mistakes","title":"3. Common Mistakes","text":"<ul> <li>Off-by-one errors in boundary conditions</li> <li>Infinite loops due to incorrect updates</li> <li>Not handling edge cases (empty arrays, single elements)</li> <li>Using wrong comparison operators</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#practice-recommendations","title":"Practice Recommendations","text":""},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#week-1-basic-binary-search","title":"Week 1: Basic Binary Search","text":"<ol> <li>Binary Search (LeetCode 704)</li> <li>Search Insert Position (LeetCode 35)</li> <li>First Bad Version (LeetCode 278)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#week-2-binary-search-variations","title":"Week 2: Binary Search Variations","text":"<ol> <li>Find First and Last Position (LeetCode 34)</li> <li>Search in Rotated Sorted Array (LeetCode 33)</li> <li>Find Peak Element (LeetCode 162)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#week-3-advanced-applications","title":"Week 3: Advanced Applications","text":"<ol> <li>Median of Two Sorted Arrays (LeetCode 4)</li> <li>Capacity to Ship Packages (LeetCode 1011)</li> <li>Koko Eating Bananas (LeetCode 875)</li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Search_Algorithms/Search_Problems/#next-topics","title":"Next Topics","text":"<ul> <li>Binary_Search_Fundamentals - Review binary search basics</li> <li>Two_Pointers_Overview - Learn two pointers technique</li> <li>Sorting_Algorithms_Overview - Understand sorting for search preparation</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/","title":"Sorting Algorithms Overview","text":"<p>Sorting algorithms arrange elements in a specific order (typically ascending or descending). They are fundamental to computer science and serve as building blocks for many other algorithms.</p>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#why-sorting-matters","title":"Why Sorting Matters","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#1-enables-binary-search","title":"1. Enables Binary Search","text":"<ul> <li>Sorted data allows O(log n) search instead of O(n)</li> <li>Critical for performance in large datasets</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#2-data-organization","title":"2. Data Organization","text":"<ul> <li>Makes data easier to understand and process</li> <li>Enables efficient algorithms for other problems</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#3-algorithm-foundation","title":"3. Algorithm Foundation","text":"<ul> <li>Many algorithms assume sorted input</li> <li>Sorting is often a preprocessing step</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#classification-of-sorting-algorithms","title":"Classification of Sorting Algorithms","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#by-stability","title":"By Stability","text":"<ul> <li>Stable: Maintains relative order of equal elements</li> <li>Unstable: May change relative order of equal elements</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#by-comparison","title":"By Comparison","text":"<ul> <li>Comparison-based: Compare elements to determine order</li> <li>Non-comparison: Use element properties (like digits)</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#by-memory-usage","title":"By Memory Usage","text":"<ul> <li>In-place: Uses O(1) extra space</li> <li>Out-of-place: Uses O(n) or more extra space</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#common-sorting-algorithms","title":"Common Sorting Algorithms","text":"Algorithm Best Case Average Case Worst Case Space Stable In-place Bubble Sort O(n) O(n\u00b2) O(n\u00b2) O(1) \u2705 \u2705 Selection Sort O(n\u00b2) O(n\u00b2) O(n\u00b2) O(1) \u274c \u2705 Insertion Sort O(n) O(n\u00b2) O(n\u00b2) O(1) \u2705 \u2705 Merge Sort O(n log n) O(n log n) O(n log n) O(n) \u2705 \u274c Quick Sort O(n log n) O(n log n) O(n\u00b2) O(log n) \u274c \u2705 Heap Sort O(n log n) O(n log n) O(n log n) O(1) \u274c \u2705 Counting Sort O(n+k) O(n+k) O(n+k) O(k) \u2705 \u274c Radix Sort O(d(n+k)) O(d(n+k)) O(d(n+k)) O(n+k) \u2705 \u274c <p>k = range of input, d = number of digits</p>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#simple-sorting-algorithms-on2","title":"Simple Sorting Algorithms (O(n\u00b2))","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#1-bubble-sort","title":"1. Bubble Sort","text":"<pre><code>def bubble_sort(arr):\n    n = len(arr)\n    for i in range(n):\n        swapped = False\n        for j in range(0, n - i - 1):\n            if arr[j] &gt; arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                swapped = True\n        if not swapped:  # Optimization: stop if no swaps\n            break\n    return arr\n\n# Good for: Small datasets, educational purposes\n# Bad for: Large datasets, performance-critical applications\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#2-selection-sort","title":"2. Selection Sort","text":"<pre><code>def selection_sort(arr):\n    n = len(arr)\n    for i in range(n):\n        min_idx = i\n        for j in range(i + 1, n):\n            if arr[j] &lt; arr[min_idx]:\n                min_idx = j\n        arr[i], arr[min_idx] = arr[min_idx], arr[i]\n    return arr\n\n# Good for: Minimizing memory writes, small datasets\n# Bad for: Large datasets, when stability is needed\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#3-insertion-sort","title":"3. Insertion Sort","text":"<pre><code>def insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j &gt;= 0 and arr[j] &gt; key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n    return arr\n\n# Good for: Small datasets, nearly sorted data, online algorithms\n# Bad for: Large datasets with random order\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#efficient-sorting-algorithms-on-log-n","title":"Efficient Sorting Algorithms (O(n log n))","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#1-merge-sort","title":"1. Merge Sort","text":"<pre><code>def merge_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n\n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i, j = 0, 0\n\n    while i &lt; len(left) and j &lt; len(right):\n        if left[i] &lt;= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result\n\n# Good for: Guaranteed O(n log n), stable sorting, large datasets\n# Bad for: Memory-constrained environments\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#2-quick-sort","title":"2. Quick Sort","text":"<pre><code>def quick_sort(arr, low=0, high=None):\n    if high is None:\n        high = len(arr) - 1\n\n    if low &lt; high:\n        pivot_idx = partition(arr, low, high)\n        quick_sort(arr, low, pivot_idx - 1)\n        quick_sort(arr, pivot_idx + 1, high)\n\n    return arr\n\ndef partition(arr, low, high):\n    pivot = arr[high]\n    i = low - 1\n\n    for j in range(low, high):\n        if arr[j] &lt;= pivot:\n            i += 1\n            arr[i], arr[j] = arr[j], arr[i]\n\n    arr[i + 1], arr[high] = arr[high], arr[i + 1]\n    return i + 1\n\n# Good for: Average case performance, in-place sorting\n# Bad for: Worst-case guarantees, already sorted data (without optimization)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#specialized-sorting-algorithms","title":"Specialized Sorting Algorithms","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#1-counting-sort-non-comparison","title":"1. Counting Sort (Non-comparison)","text":"<pre><code>def counting_sort(arr, max_val):\n    # Only works for integers in known range\n    count = [0] * (max_val + 1)\n\n    # Count occurrences\n    for num in arr:\n        count[num] += 1\n\n    # Reconstruct sorted array\n    result = []\n    for i, freq in enumerate(count):\n        result.extend([i] * freq)\n\n    return result\n\n# Good for: Small range of integers, linear time needed\n# Bad for: Large range, non-integer data\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#2-radix-sort-non-comparison","title":"2. Radix Sort (Non-comparison)","text":"<pre><code>def radix_sort(arr):\n    # Find maximum number to determine digits\n    max_num = max(arr)\n    exp = 1\n\n    while max_num // exp &gt; 0:\n        counting_sort_by_digit(arr, exp)\n        exp *= 10\n\n    return arr\n\ndef counting_sort_by_digit(arr, exp):\n    output = [0] * len(arr)\n    count = [0] * 10\n\n    # Count occurrences of each digit\n    for num in arr:\n        digit = (num // exp) % 10\n        count[digit] += 1\n\n    # Calculate positions\n    for i in range(1, 10):\n        count[i] += count[i - 1]\n\n    # Build output array\n    for i in range(len(arr) - 1, -1, -1):\n        digit = (arr[i] // exp) % 10\n        output[count[digit] - 1] = arr[i]\n        count[digit] -= 1\n\n    # Copy back to original array\n    for i in range(len(arr)):\n        arr[i] = output[i]\n\n# Good for: Fixed-width integers, linear time needed\n# Bad for: Variable-length data, small datasets\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#choosing-the-right-sorting-algorithm","title":"Choosing the Right Sorting Algorithm","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#for-small-arrays-50-elements","title":"For Small Arrays (&lt; 50 elements)","text":"<ul> <li>Insertion Sort: Simple, efficient for small data</li> <li>Selection Sort: Minimizes memory writes</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#for-large-arrays","title":"For Large Arrays","text":"<ul> <li>Merge Sort: Guaranteed O(n log n), stable</li> <li>Quick Sort: Average O(n log n), in-place</li> <li>Heap Sort: Guaranteed O(n log n), in-place</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#for-specific-data-types","title":"For Specific Data Types","text":"<ul> <li>Integers in small range: Counting Sort</li> <li>Integers with fixed digits: Radix Sort</li> <li>Strings: Usually Quick Sort or Merge Sort</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#for-specific-requirements","title":"For Specific Requirements","text":"<ul> <li>Stability needed: Merge Sort, Insertion Sort</li> <li>Memory constrained: Heap Sort, Quick Sort</li> <li>Nearly sorted data: Insertion Sort</li> <li>Online sorting: Insertion Sort</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#hybrid-approaches","title":"Hybrid Approaches","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#timsort-pythons-built-in","title":"Timsort (Python's Built-in)","text":"<pre><code># Python's sorted() and list.sort() use Timsort\n# Combines merge sort and insertion sort\n# Optimized for real-world data patterns\n\narr = [3, 1, 4, 1, 5, 9, 2, 6]\nsorted_arr = sorted(arr)  # Uses Timsort\narr.sort()  # In-place Timsort\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#introsort-c-stdsort","title":"Introsort (C++ std::sort)","text":"<ul> <li>Starts with Quick Sort</li> <li>Switches to Heap Sort if recursion depth exceeds limit</li> <li>Uses Insertion Sort for small subarrays</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#performance-testing","title":"Performance Testing","text":"<pre><code>import time\nimport random\n\ndef benchmark_sorting_algorithms():\n    sizes = [100, 1000, 10000]\n    algorithms = {\n        'Bubble': bubble_sort,\n        'Selection': selection_sort,\n        'Insertion': insertion_sort,\n        'Merge': merge_sort,\n        'Quick': quick_sort,\n        'Python Built-in': sorted\n    }\n\n    for size in sizes:\n        print(f\"\\nArray size: {size}\")\n        data = [random.randint(1, 1000) for _ in range(size)]\n\n        for name, func in algorithms.items():\n            test_data = data.copy()\n            start = time.time()\n            func(test_data)\n            end = time.time()\n            print(f\"{name}: {end - start:.4f}s\")\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Algorithms_Overview/#next-topics","title":"Next Topics","text":"<ul> <li>Sorting_Problems - Practice problems using various sorting techniques</li> <li>Binary_Search_Fundamentals - Use sorting to enable binary search</li> <li>Two_Pointers_Overview - Techniques that work well with sorted data</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/","title":"Sorting Algorithm Problems","text":"<p>Practice problems that utilize various sorting algorithms and sorting-based techniques. Problems are organized by difficulty and approach.</p>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#basic-sorting-problems","title":"Basic Sorting Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#easy-problems","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#1-sort-array-leetcode-912","title":"1. Sort Array (LeetCode 912)","text":"<pre><code>def sort_array(nums):\n    \"\"\"Sort array using different algorithms.\"\"\"\n\n    # Merge Sort Implementation\n    def merge_sort(arr):\n        if len(arr) &lt;= 1:\n            return arr\n\n        mid = len(arr) // 2\n        left = merge_sort(arr[:mid])\n        right = merge_sort(arr[mid:])\n\n        return merge(left, right)\n\n    def merge(left, right):\n        result = []\n        i = j = 0\n\n        while i &lt; len(left) and j &lt; len(right):\n            if left[i] &lt;= right[j]:\n                result.append(left[i])\n                i += 1\n            else:\n                result.append(right[j])\n                j += 1\n\n        result.extend(left[i:])\n        result.extend(right[j:])\n        return result\n\n    return merge_sort(nums)\n\n# Time: O(n log n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#2-merge-sorted-array-leetcode-88","title":"2. Merge Sorted Array (LeetCode 88)","text":"<pre><code>def merge_sorted_arrays(nums1, m, nums2, n):\n    \"\"\"Merge two sorted arrays in-place.\"\"\"\n    # Start from the end to avoid overwriting\n    i, j, k = m - 1, n - 1, m + n - 1\n\n    while i &gt;= 0 and j &gt;= 0:\n        if nums1[i] &gt; nums2[j]:\n            nums1[k] = nums1[i]\n            i -= 1\n        else:\n            nums1[k] = nums2[j]\n            j -= 1\n        k -= 1\n\n    # Copy remaining elements from nums2\n    while j &gt;= 0:\n        nums1[k] = nums2[j]\n        j -= 1\n        k -= 1\n\n# Time: O(m + n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#3-squares-of-sorted-array-leetcode-977","title":"3. Squares of Sorted Array (LeetCode 977)","text":"<pre><code>def sorted_squares(nums):\n    \"\"\"Return sorted squares of sorted array.\"\"\"\n    # Two pointers approach\n    left, right = 0, len(nums) - 1\n    result = [0] * len(nums)\n    pos = len(nums) - 1\n\n    while left &lt;= right:\n        left_square = nums[left] ** 2\n        right_square = nums[right] ** 2\n\n        if left_square &gt; right_square:\n            result[pos] = left_square\n            left += 1\n        else:\n            result[pos] = right_square\n            right -= 1\n\n        pos -= 1\n\n    return result\n\n# Time: O(n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#medium-problems","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#1-sort-colors-leetcode-75","title":"1. Sort Colors (LeetCode 75)","text":"<pre><code>def sort_colors(nums):\n    \"\"\"Sort array of 0s, 1s, and 2s in-place.\"\"\"\n    # Dutch National Flag Algorithm\n    left, current, right = 0, 0, len(nums) - 1\n\n    while current &lt;= right:\n        if nums[current] == 0:\n            nums[left], nums[current] = nums[current], nums[left]\n            left += 1\n            current += 1\n        elif nums[current] == 1:\n            current += 1\n        else:  # nums[current] == 2\n            nums[current], nums[right] = nums[right], nums[current]\n            right -= 1\n            # Don't increment current, need to check swapped element\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#2-kth-largest-element-leetcode-215","title":"2. Kth Largest Element (LeetCode 215)","text":"<pre><code>def find_kth_largest(nums, k):\n    \"\"\"Find kth largest element using quickselect.\"\"\"\n    import random\n\n    def quickselect(left, right, k_smallest):\n        if left == right:\n            return nums[left]\n\n        # Random pivot for better average performance\n        pivot_index = random.randint(left, right)\n        pivot_index = partition(left, right, pivot_index)\n\n        if k_smallest == pivot_index:\n            return nums[k_smallest]\n        elif k_smallest &lt; pivot_index:\n            return quickselect(left, pivot_index - 1, k_smallest)\n        else:\n            return quickselect(pivot_index + 1, right, k_smallest)\n\n    def partition(left, right, pivot_index):\n        pivot = nums[pivot_index]\n        # Move pivot to end\n        nums[pivot_index], nums[right] = nums[right], nums[pivot_index]\n\n        store_index = left\n        for i in range(left, right):\n            if nums[i] &lt; pivot:\n                nums[store_index], nums[i] = nums[i], nums[store_index]\n                store_index += 1\n\n        # Move pivot to final position\n        nums[right], nums[store_index] = nums[store_index], nums[right]\n        return store_index\n\n    return quickselect(0, len(nums) - 1, len(nums) - k)\n\n# Average: O(n), Worst: O(n\u00b2), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#3-merge-intervals-leetcode-56","title":"3. Merge Intervals (LeetCode 56)","text":"<pre><code>def merge_intervals(intervals):\n    \"\"\"Merge overlapping intervals.\"\"\"\n    if not intervals:\n        return []\n\n    # Sort by start time\n    intervals.sort(key=lambda x: x[0])\n    merged = [intervals[0]]\n\n    for current in intervals[1:]:\n        last = merged[-1]\n\n        if current[0] &lt;= last[1]:  # Overlapping\n            merged[-1] = [last[0], max(last[1], current[1])]\n        else:  # Non-overlapping\n            merged.append(current)\n\n    return merged\n\n# Time: O(n log n), Space: O(1) excluding result\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#4-top-k-frequent-elements-leetcode-347","title":"4. Top K Frequent Elements (LeetCode 347)","text":"<pre><code>def top_k_frequent(nums, k):\n    \"\"\"Find k most frequent elements.\"\"\"\n    from collections import Counter\n    import heapq\n\n    # Count frequencies\n    count = Counter(nums)\n\n    # Use heap to find top k\n    return heapq.nlargest(k, count.keys(), key=count.get)\n\n# Alternative: Bucket sort approach\ndef top_k_frequent_bucket(nums, k):\n    from collections import Counter\n\n    count = Counter(nums)\n    # Bucket sort by frequency\n    buckets = [[] for _ in range(len(nums) + 1)]\n\n    for num, freq in count.items():\n        buckets[freq].append(num)\n\n    result = []\n    for i in range(len(buckets) - 1, 0, -1):\n        for num in buckets[i]:\n            result.append(num)\n            if len(result) == k:\n                return result\n\n    return result\n\n# Heap: O(n log k), Bucket: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#advanced-sorting-problems","title":"Advanced Sorting Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#hard-problems","title":"Hard Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#1-count-of-smaller-numbers-after-self-leetcode-315","title":"1. Count of Smaller Numbers After Self (LeetCode 315)","text":"<pre><code>def count_smaller(nums):\n    \"\"\"Count smaller numbers after each element.\"\"\"\n    def merge_sort_count(arr):\n        if len(arr) &lt;= 1:\n            return arr\n\n        mid = len(arr) // 2\n        left = merge_sort_count(arr[:mid])\n        right = merge_sort_count(arr[mid:])\n\n        return merge_count(left, right)\n\n    def merge_count(left, right):\n        result = []\n        i = j = 0\n\n        while i &lt; len(left) and j &lt; len(right):\n            if left[i][0] &gt; right[j][0]:\n                result.append(right[j])\n                j += 1\n            else:\n                # All elements in right[j:] are larger\n                counts[left[i][1]] += len(right) - j\n                result.append(left[i])\n                i += 1\n\n        while i &lt; len(left):\n            result.append(left[i])\n            i += 1\n\n        while j &lt; len(right):\n            result.append(right[j])\n            j += 1\n\n        return result\n\n    # Create (value, original_index) pairs\n    indexed_nums = [(nums[i], i) for i in range(len(nums))]\n    counts = [0] * len(nums)\n\n    merge_sort_count(indexed_nums)\n    return counts\n\n# Time: O(n log n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#2-reverse-pairs-leetcode-493","title":"2. Reverse Pairs (LeetCode 493)","text":"<pre><code>def reverse_pairs(nums):\n    \"\"\"Count reverse pairs where i &lt; j and nums[i] &gt; 2 * nums[j].\"\"\"\n    def merge_sort_count(left, right):\n        if left &gt;= right:\n            return 0\n\n        mid = (left + right) // 2\n        count = merge_sort_count(left, mid) + merge_sort_count(mid + 1, right)\n\n        # Count reverse pairs\n        j = mid + 1\n        for i in range(left, mid + 1):\n            while j &lt;= right and nums[i] &gt; 2 * nums[j]:\n                j += 1\n            count += j - (mid + 1)\n\n        # Merge\n        temp = []\n        i, j = left, mid + 1\n\n        while i &lt;= mid and j &lt;= right:\n            if nums[i] &lt;= nums[j]:\n                temp.append(nums[i])\n                i += 1\n            else:\n                temp.append(nums[j])\n                j += 1\n\n        while i &lt;= mid:\n            temp.append(nums[i])\n            i += 1\n\n        while j &lt;= right:\n            temp.append(nums[j])\n            j += 1\n\n        # Copy back\n        for i in range(len(temp)):\n            nums[left + i] = temp[i]\n\n        return count\n\n    return merge_sort_count(0, len(nums) - 1)\n\n# Time: O(n log n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#sorting-based-techniques","title":"Sorting-Based Techniques","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#1-meeting-rooms-problems","title":"1. Meeting Rooms Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#meeting-rooms-leetcode-252","title":"Meeting Rooms (LeetCode 252)","text":"<pre><code>def can_attend_meetings(intervals):\n    \"\"\"Check if person can attend all meetings.\"\"\"\n    intervals.sort(key=lambda x: x[0])\n\n    for i in range(1, len(intervals)):\n        if intervals[i][0] &lt; intervals[i-1][1]:\n            return False\n\n    return True\n\n# Time: O(n log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#meeting-rooms-ii-leetcode-253","title":"Meeting Rooms II (LeetCode 253)","text":"<pre><code>def min_meeting_rooms(intervals):\n    \"\"\"Find minimum meeting rooms needed.\"\"\"\n    if not intervals:\n        return 0\n\n    import heapq\n\n    intervals.sort(key=lambda x: x[0])\n    heap = []  # Min heap of end times\n\n    for interval in intervals:\n        # Remove meetings that have ended\n        while heap and heap[0] &lt;= interval[0]:\n            heapq.heappop(heap)\n\n        # Add current meeting's end time\n        heapq.heappush(heap, interval[1])\n\n    return len(heap)\n\n# Time: O(n log n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#2-array-transformation-problems","title":"2. Array Transformation Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#wiggle-sort-leetcode-280","title":"Wiggle Sort (LeetCode 280)","text":"<pre><code>def wiggle_sort(nums):\n    \"\"\"Reorder array so nums[0] &lt; nums[1] &gt; nums[2] &lt; nums[3]...\"\"\"\n    for i in range(len(nums) - 1):\n        if (i % 2 == 0 and nums[i] &gt; nums[i + 1]) or \\\n           (i % 2 == 1 and nums[i] &lt; nums[i + 1]):\n            nums[i], nums[i + 1] = nums[i + 1], nums[i]\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#wiggle-sort-ii-leetcode-324","title":"Wiggle Sort II (LeetCode 324)","text":"<pre><code>def wiggle_sort_ii(nums):\n    \"\"\"Wiggle sort with strict inequality.\"\"\"\n    nums.sort()\n    n = len(nums)\n\n    # Split into two halves\n    small = nums[:(n + 1) // 2]\n    large = nums[(n + 1) // 2:]\n\n    # Reverse to avoid adjacent equal elements\n    small.reverse()\n    large.reverse()\n\n    # Interleave\n    for i in range(n):\n        if i % 2 == 0:\n            nums[i] = small[i // 2]\n        else:\n            nums[i] = large[i // 2]\n\n# Time: O(n log n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#custom-sorting-problems","title":"Custom Sorting Problems","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#1-largest-number-leetcode-179","title":"1. Largest Number (LeetCode 179)","text":"<pre><code>def largest_number(nums):\n    \"\"\"Arrange numbers to form largest possible number.\"\"\"\n    from functools import cmp_to_key\n\n    def compare(x, y):\n        # Compare x+y vs y+x\n        if x + y &gt; y + x:\n            return -1\n        elif x + y &lt; y + x:\n            return 1\n        else:\n            return 0\n\n    # Convert to strings\n    str_nums = [str(num) for num in nums]\n\n    # Sort with custom comparator\n    str_nums.sort(key=cmp_to_key(compare))\n\n    # Handle edge case of all zeros\n    result = ''.join(str_nums)\n    return '0' if result[0] == '0' else result\n\n# Time: O(n log n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#2-custom-sort-string-leetcode-791","title":"2. Custom Sort String (LeetCode 791)","text":"<pre><code>def custom_sort_string(order, s):\n    \"\"\"Sort string s according to order.\"\"\"\n    from collections import Counter\n\n    count = Counter(s)\n    result = []\n\n    # Add characters in order\n    for char in order:\n        if char in count:\n            result.extend([char] * count[char])\n            del count[char]\n\n    # Add remaining characters\n    for char, freq in count.items():\n        result.extend([char] * freq)\n\n    return ''.join(result)\n\n# Time: O(n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#problem-solving-strategies","title":"Problem-Solving Strategies","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#1-choose-the-right-algorithm","title":"1. Choose the Right Algorithm","text":"<ul> <li>Small array (&lt; 50): Insertion sort</li> <li>Nearly sorted: Insertion sort, bubble sort</li> <li>Guaranteed O(n log n): Merge sort, heap sort</li> <li>Average case optimization: Quick sort</li> <li>Stable sorting needed: Merge sort, insertion sort</li> <li>Memory constrained: Heap sort, quick sort</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#2-sorting-decision-tree","title":"2. Sorting Decision Tree","text":"<pre><code>What's the constraint?\n\u251c\u2500\u2500 Time critical &amp; large data \u2192 Quick sort\n\u251c\u2500\u2500 Stability required \u2192 Merge sort\n\u251c\u2500\u2500 Memory limited \u2192 Heap sort\n\u251c\u2500\u2500 Small data \u2192 Insertion sort\n\u2514\u2500\u2500 Special properties \u2192 Custom algorithm\n</code></pre>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#3-common-patterns","title":"3. Common Patterns","text":"<ul> <li>Interval problems: Sort by start time</li> <li>Meeting rooms: Sort + greedy or heap</li> <li>Kth element: Quickselect or heap</li> <li>Custom order: Custom comparator</li> <li>Counting inversions: Merge sort</li> </ul>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#practice-schedule","title":"Practice Schedule","text":""},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#week-1-basic-sorting","title":"Week 1: Basic Sorting","text":"<ol> <li>Sort Array (multiple algorithms)</li> <li>Merge Sorted Array</li> <li>Squares of Sorted Array</li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#week-2-sorting-applications","title":"Week 2: Sorting Applications","text":"<ol> <li>Sort Colors</li> <li>Kth Largest Element</li> <li>Merge Intervals</li> <li>Top K Frequent Elements</li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#week-3-advanced-problems","title":"Week 3: Advanced Problems","text":"<ol> <li>Meeting Rooms II</li> <li>Largest Number</li> <li>Count of Smaller Numbers After Self</li> </ol>"},{"location":"engineering_and_data_structure/Algorithms/Sorting_Algorithms/Sorting_Problems/#next-topics","title":"Next Topics","text":"<ul> <li>Binary_Search_Fundamentals - Use sorting to enable binary search</li> <li>Two_Pointers_Overview - Techniques that work well with sorted data</li> <li>Sliding_Window_Overview - Another technique for array problems</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/","title":"Array Problems","text":"<p>Practice problems that focus on array data structure operations, manipulations, and algorithms.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#basic-array-operations","title":"Basic Array Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#easy-problems","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-two-sum-leetcode-1","title":"1. Two Sum (LeetCode 1)","text":"<pre><code>def two_sum(nums, target):\n    \"\"\"Find indices of two numbers that add up to target.\"\"\"\n    num_to_index = {}\n\n    for i, num in enumerate(nums):\n        complement = target - num\n        if complement in num_to_index:\n            return [num_to_index[complement], i]\n        num_to_index[num] = i\n\n    return []\n\n# Time: O(n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-best-time-to-buy-and-sell-stock-leetcode-121","title":"2. Best Time to Buy and Sell Stock (LeetCode 121)","text":"<pre><code>def max_profit(prices):\n    \"\"\"Find maximum profit from one buy and one sell.\"\"\"\n    min_price = float('inf')\n    max_profit = 0\n\n    for price in prices:\n        if price &lt; min_price:\n            min_price = price\n        else:\n            max_profit = max(max_profit, price - min_price)\n\n    return max_profit\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#3-contains-duplicate-leetcode-217","title":"3. Contains Duplicate (LeetCode 217)","text":"<pre><code>def contains_duplicate(nums):\n    \"\"\"Check if array contains duplicates.\"\"\"\n    return len(nums) != len(set(nums))\n\n# Alternative: Using hash set\ndef contains_duplicate_v2(nums):\n    seen = set()\n    for num in nums:\n        if num in seen:\n            return True\n        seen.add(num)\n    return False\n\n# Time: O(n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#4-maximum-subarray-leetcode-53","title":"4. Maximum Subarray (LeetCode 53)","text":"<pre><code>def max_subarray(nums):\n    \"\"\"Find maximum sum of contiguous subarray (Kadane's Algorithm).\"\"\"\n    max_sum = current_sum = nums[0]\n\n    for num in nums[1:]:\n        current_sum = max(num, current_sum + num)\n        max_sum = max(max_sum, current_sum)\n\n    return max_sum\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#medium-problems","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-product-of-array-except-self-leetcode-238","title":"1. Product of Array Except Self (LeetCode 238)","text":"<pre><code>def product_except_self(nums):\n    \"\"\"Return array where output[i] = product of all elements except nums[i].\"\"\"\n    n = len(nums)\n    result = [1] * n\n\n    # Forward pass: result[i] = product of all elements before i\n    for i in range(1, n):\n        result[i] = result[i - 1] * nums[i - 1]\n\n    # Backward pass: multiply by product of all elements after i\n    right_product = 1\n    for i in range(n - 1, -1, -1):\n        result[i] *= right_product\n        right_product *= nums[i]\n\n    return result\n\n# Time: O(n), Space: O(1) excluding output array\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-3sum-leetcode-15","title":"2. 3Sum (LeetCode 15)","text":"<pre><code>def three_sum(nums):\n    \"\"\"Find all unique triplets that sum to zero.\"\"\"\n    nums.sort()\n    result = []\n\n    for i in range(len(nums) - 2):\n        if i &gt; 0 and nums[i] == nums[i - 1]:\n            continue  # Skip duplicates\n\n        left, right = i + 1, len(nums) - 1\n\n        while left &lt; right:\n            current_sum = nums[i] + nums[left] + nums[right]\n\n            if current_sum == 0:\n                result.append([nums[i], nums[left], nums[right]])\n\n                # Skip duplicates\n                while left &lt; right and nums[left] == nums[left + 1]:\n                    left += 1\n                while left &lt; right and nums[right] == nums[right - 1]:\n                    right -= 1\n\n                left += 1\n                right -= 1\n            elif current_sum &lt; 0:\n                left += 1\n            else:\n                right -= 1\n\n    return result\n\n# Time: O(n\u00b2), Space: O(1) excluding result\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#3-container-with-most-water-leetcode-11","title":"3. Container With Most Water (LeetCode 11)","text":"<pre><code>def max_area(height):\n    \"\"\"Find two lines that form container with most water.\"\"\"\n    left, right = 0, len(height) - 1\n    max_water = 0\n\n    while left &lt; right:\n        width = right - left\n        current_area = min(height[left], height[right]) * width\n        max_water = max(max_water, current_area)\n\n        # Move pointer with smaller height\n        if height[left] &lt; height[right]:\n            left += 1\n        else:\n            right -= 1\n\n    return max_water\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#array-manipulation","title":"Array Manipulation","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#easy-problems_1","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-rotate-array-leetcode-189","title":"1. Rotate Array (LeetCode 189)","text":"<pre><code>def rotate(nums, k):\n    \"\"\"Rotate array to the right by k steps.\"\"\"\n    n = len(nums)\n    k = k % n  # Handle k &gt; n\n\n    # Reverse entire array\n    nums.reverse()\n\n    # Reverse first k elements\n    nums[:k] = reversed(nums[:k])\n\n    # Reverse remaining elements\n    nums[k:] = reversed(nums[k:])\n\n# Alternative: Using extra space\ndef rotate_v2(nums, k):\n    n = len(nums)\n    k = k % n\n    nums[:] = nums[-k:] + nums[:-k]\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-remove-duplicates-from-sorted-array-leetcode-26","title":"2. Remove Duplicates from Sorted Array (LeetCode 26)","text":"<pre><code>def remove_duplicates(nums):\n    \"\"\"Remove duplicates from sorted array in-place.\"\"\"\n    if not nums:\n        return 0\n\n    write_index = 1\n\n    for read_index in range(1, len(nums)):\n        if nums[read_index] != nums[read_index - 1]:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    return write_index\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#3-move-zeroes-leetcode-283","title":"3. Move Zeroes (LeetCode 283)","text":"<pre><code>def move_zeroes(nums):\n    \"\"\"Move all zeros to end while maintaining order of non-zeros.\"\"\"\n    write_index = 0\n\n    # Move all non-zeros to front\n    for read_index in range(len(nums)):\n        if nums[read_index] != 0:\n            nums[write_index] = nums[read_index]\n            write_index += 1\n\n    # Fill remaining positions with zeros\n    while write_index &lt; len(nums):\n        nums[write_index] = 0\n        write_index += 1\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#medium-problems_1","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-set-matrix-zeroes-leetcode-73","title":"1. Set Matrix Zeroes (LeetCode 73)","text":"<pre><code>def set_zeroes(matrix):\n    \"\"\"Set entire row and column to zero if element is zero.\"\"\"\n    m, n = len(matrix), len(matrix[0])\n    first_row_zero = any(matrix[0][j] == 0 for j in range(n))\n    first_col_zero = any(matrix[i][0] == 0 for i in range(m))\n\n    # Use first row and column as markers\n    for i in range(1, m):\n        for j in range(1, n):\n            if matrix[i][j] == 0:\n                matrix[i][0] = 0\n                matrix[0][j] = 0\n\n    # Set zeros based on markers\n    for i in range(1, m):\n        for j in range(1, n):\n            if matrix[i][0] == 0 or matrix[0][j] == 0:\n                matrix[i][j] = 0\n\n    # Handle first row and column\n    if first_row_zero:\n        for j in range(n):\n            matrix[0][j] = 0\n\n    if first_col_zero:\n        for i in range(m):\n            matrix[i][0] = 0\n\n# Time: O(m*n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-spiral-matrix-leetcode-54","title":"2. Spiral Matrix (LeetCode 54)","text":"<pre><code>def spiral_order(matrix):\n    \"\"\"Return elements of matrix in spiral order.\"\"\"\n    if not matrix or not matrix[0]:\n        return []\n\n    result = []\n    top, bottom = 0, len(matrix) - 1\n    left, right = 0, len(matrix[0]) - 1\n\n    while top &lt;= bottom and left &lt;= right:\n        # Traverse right\n        for col in range(left, right + 1):\n            result.append(matrix[top][col])\n        top += 1\n\n        # Traverse down\n        for row in range(top, bottom + 1):\n            result.append(matrix[row][right])\n        right -= 1\n\n        # Traverse left (if we still have rows)\n        if top &lt;= bottom:\n            for col in range(right, left - 1, -1):\n                result.append(matrix[bottom][col])\n            bottom -= 1\n\n        # Traverse up (if we still have columns)\n        if left &lt;= right:\n            for row in range(bottom, top - 1, -1):\n                result.append(matrix[row][left])\n            left += 1\n\n    return result\n\n# Time: O(m*n), Space: O(1) excluding result\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#searching-in-arrays","title":"Searching in Arrays","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#easy-problems_2","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-binary-search-leetcode-704","title":"1. Binary Search (LeetCode 704)","text":"<pre><code>def search(nums, target):\n    \"\"\"Binary search in sorted array.\"\"\"\n    left, right = 0, len(nums) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if nums[mid] == target:\n            return mid\n        elif nums[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return -1\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-search-insert-position-leetcode-35","title":"2. Search Insert Position (LeetCode 35)","text":"<pre><code>def search_insert(nums, target):\n    \"\"\"Find position to insert target in sorted array.\"\"\"\n    left, right = 0, len(nums) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if nums[mid] == target:\n            return mid\n        elif nums[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return left\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#medium-problems_2","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-search-in-rotated-sorted-array-leetcode-33","title":"1. Search in Rotated Sorted Array (LeetCode 33)","text":"<pre><code>def search(nums, target):\n    \"\"\"Search target in rotated sorted array.\"\"\"\n    left, right = 0, len(nums) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n\n        if nums[mid] == target:\n            return mid\n\n        # Check which half is sorted\n        if nums[left] &lt;= nums[mid]:  # Left half is sorted\n            if nums[left] &lt;= target &lt; nums[mid]:\n                right = mid - 1\n            else:\n                left = mid + 1\n        else:  # Right half is sorted\n            if nums[mid] &lt; target &lt;= nums[right]:\n                left = mid + 1\n            else:\n                right = mid - 1\n\n    return -1\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-find-peak-element-leetcode-162","title":"2. Find Peak Element (LeetCode 162)","text":"<pre><code>def find_peak_element(nums):\n    \"\"\"Find any peak element in the array.\"\"\"\n    left, right = 0, len(nums) - 1\n\n    while left &lt; right:\n        mid = left + (right - left) // 2\n\n        if nums[mid] &gt; nums[mid + 1]:\n            right = mid  # Peak is in left half (including mid)\n        else:\n            left = mid + 1  # Peak is in right half\n\n    return left\n\n# Time: O(log n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#sorting-problems","title":"Sorting Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#easy-problems_3","title":"Easy Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-merge-sorted-array-leetcode-88","title":"1. Merge Sorted Array (LeetCode 88)","text":"<pre><code>def merge(nums1, m, nums2, n):\n    \"\"\"Merge two sorted arrays in-place.\"\"\"\n    # Start from the end to avoid overwriting\n    i, j, k = m - 1, n - 1, m + n - 1\n\n    while i &gt;= 0 and j &gt;= 0:\n        if nums1[i] &gt; nums2[j]:\n            nums1[k] = nums1[i]\n            i -= 1\n        else:\n            nums1[k] = nums2[j]\n            j -= 1\n        k -= 1\n\n    # Copy remaining elements from nums2\n    while j &gt;= 0:\n        nums1[k] = nums2[j]\n        j -= 1\n        k -= 1\n\n# Time: O(m + n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-squares-of-sorted-array-leetcode-977","title":"2. Squares of Sorted Array (LeetCode 977)","text":"<pre><code>def sorted_squares(nums):\n    \"\"\"Return sorted squares of sorted array.\"\"\"\n    left, right = 0, len(nums) - 1\n    result = [0] * len(nums)\n    pos = len(nums) - 1\n\n    while left &lt;= right:\n        left_square = nums[left] ** 2\n        right_square = nums[right] ** 2\n\n        if left_square &gt; right_square:\n            result[pos] = left_square\n            left += 1\n        else:\n            result[pos] = right_square\n            right -= 1\n\n        pos -= 1\n\n    return result\n\n# Time: O(n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#medium-problems_3","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-sort-colors-leetcode-75","title":"1. Sort Colors (LeetCode 75)","text":"<pre><code>def sort_colors(nums):\n    \"\"\"Sort array of 0s, 1s, and 2s in-place (Dutch Flag Algorithm).\"\"\"\n    left, right = 0, len(nums) - 1\n    current = 0\n\n    while current &lt;= right:\n        if nums[current] == 0:\n            nums[left], nums[current] = nums[current], nums[left]\n            left += 1\n            current += 1\n        elif nums[current] == 1:\n            current += 1\n        else:  # nums[current] == 2\n            nums[current], nums[right] = nums[right], nums[current]\n            right -= 1\n            # Don't increment current, need to check swapped element\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#advanced-array-problems","title":"Advanced Array Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#medium-problems_4","title":"Medium Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-next-permutation-leetcode-31","title":"1. Next Permutation (LeetCode 31)","text":"<pre><code>def next_permutation(nums):\n    \"\"\"Find next lexicographically greater permutation.\"\"\"\n    # Find the largest index i such that nums[i] &lt; nums[i + 1]\n    i = len(nums) - 2\n    while i &gt;= 0 and nums[i] &gt;= nums[i + 1]:\n        i -= 1\n\n    if i &gt;= 0:\n        # Find the largest index j such that nums[i] &lt; nums[j]\n        j = len(nums) - 1\n        while nums[j] &lt;= nums[i]:\n            j -= 1\n\n        # Swap nums[i] and nums[j]\n        nums[i], nums[j] = nums[j], nums[i]\n\n    # Reverse the suffix starting at nums[i + 1]\n    nums[i + 1:] = reversed(nums[i + 1:])\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-jump-game-leetcode-55","title":"2. Jump Game (LeetCode 55)","text":"<pre><code>def can_jump(nums):\n    \"\"\"Check if you can reach the last index.\"\"\"\n    max_reach = 0\n\n    for i in range(len(nums)):\n        if i &gt; max_reach:\n            return False\n        max_reach = max(max_reach, i + nums[i])\n        if max_reach &gt;= len(nums) - 1:\n            return True\n\n    return True\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#3-subarray-sum-equals-k-leetcode-560","title":"3. Subarray Sum Equals K (LeetCode 560)","text":"<pre><code>def subarray_sum(nums, k):\n    \"\"\"Count subarrays with sum equal to k.\"\"\"\n    from collections import defaultdict\n\n    count = 0\n    prefix_sum = 0\n    sum_count = defaultdict(int)\n    sum_count[0] = 1  # Empty prefix\n\n    for num in nums:\n        prefix_sum += num\n\n        # Check if (prefix_sum - k) exists\n        if prefix_sum - k in sum_count:\n            count += sum_count[prefix_sum - k]\n\n        sum_count[prefix_sum] += 1\n\n    return count\n\n# Time: O(n), Space: O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#hard-problems","title":"Hard Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-trapping-rain-water-leetcode-42","title":"1. Trapping Rain Water (LeetCode 42)","text":"<pre><code>def trap(height):\n    \"\"\"Calculate trapped rainwater.\"\"\"\n    if not height:\n        return 0\n\n    left, right = 0, len(height) - 1\n    left_max, right_max = 0, 0\n    water_trapped = 0\n\n    while left &lt; right:\n        if height[left] &lt; height[right]:\n            if height[left] &gt;= left_max:\n                left_max = height[left]\n            else:\n                water_trapped += left_max - height[left]\n            left += 1\n        else:\n            if height[right] &gt;= right_max:\n                right_max = height[right]\n            else:\n                water_trapped += right_max - height[right]\n            right -= 1\n\n    return water_trapped\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-first-missing-positive-leetcode-41","title":"2. First Missing Positive (LeetCode 41)","text":"<pre><code>def first_missing_positive(nums):\n    \"\"\"Find the smallest missing positive integer.\"\"\"\n    n = len(nums)\n\n    # Mark presence of numbers\n    for i in range(n):\n        while 1 &lt;= nums[i] &lt;= n and nums[nums[i] - 1] != nums[i]:\n            # Place nums[i] at its correct position\n            nums[nums[i] - 1], nums[i] = nums[i], nums[nums[i] - 1]\n\n    # Find first missing positive\n    for i in range(n):\n        if nums[i] != i + 1:\n            return i + 1\n\n    return n + 1\n\n# Time: O(n), Space: O(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#problem-solving-strategies","title":"Problem-Solving Strategies","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#1-array-traversal-patterns","title":"1. Array Traversal Patterns","text":"<pre><code># Single pass\nfor i in range(len(arr)):\n    process(arr[i])\n\n# Two pointers\nleft, right = 0, len(arr) - 1\nwhile left &lt; right:\n    process(arr[left], arr[right])\n\n# Sliding window\nleft = 0\nfor right in range(len(arr)):\n    while condition_violated:\n        left += 1\n    process_window(left, right)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#2-space-optimization-techniques","title":"2. Space Optimization Techniques","text":"<pre><code># In-place modification\ndef modify_in_place(arr):\n    write_index = 0\n    for read_index in range(len(arr)):\n        if should_keep(arr[read_index]):\n            arr[write_index] = arr[read_index]\n            write_index += 1\n    return write_index\n\n# Using array indices as hash\ndef use_indices_as_hash(nums):\n    for i in range(len(nums)):\n        index = abs(nums[i]) - 1\n        if index &lt; len(nums):\n            nums[index] = -abs(nums[index])\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#3-common-array-algorithms","title":"3. Common Array Algorithms","text":"<ul> <li>Kadane's Algorithm: Maximum subarray sum</li> <li>Dutch Flag Algorithm: Partition array into three parts</li> <li>Binary Search: Search in sorted array</li> <li>Two Pointers: Various problems on sorted arrays</li> <li>Sliding Window: Subarray problems with conditions</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#practice-schedule","title":"Practice Schedule","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#week-1-basic-operations","title":"Week 1: Basic Operations","text":"<ol> <li>Two Sum</li> <li>Best Time to Buy and Sell Stock</li> <li>Maximum Subarray</li> <li>Contains Duplicate</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#week-2-array-manipulation","title":"Week 2: Array Manipulation","text":"<ol> <li>Rotate Array</li> <li>Move Zeroes</li> <li>Product of Array Except Self</li> <li>Set Matrix Zeroes</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#week-3-advanced-problems","title":"Week 3: Advanced Problems","text":"<ol> <li>3Sum</li> <li>Container With Most Water</li> <li>Trapping Rain Water</li> <li>Next Permutation</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Array_Problems/#next-topics","title":"Next Topics","text":"<ul> <li>Binary_Search_Fundamentals - Searching in sorted arrays</li> <li>Two_Pointers_Overview - Two pointer techniques for arrays</li> <li>Sliding_Window_Overview - Subarray problems with conditions</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/","title":"Arrays Overview","text":"<p>Arrays are one of the most fundamental data structures in computer science, providing a way to store multiple elements of the same type in a contiguous block of memory.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#what-is-an-array","title":"What is an Array?","text":"<p>An array is a collection of elements stored at contiguous memory locations. Each element can be accessed directly using its index.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#key-characteristics","title":"Key Characteristics","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#1-contiguous-memory","title":"1. Contiguous Memory","text":"<ul> <li>Elements are stored next to each other in memory</li> <li>Enables efficient cache usage</li> <li>Allows for pointer arithmetic</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#2-fixed-size-static-arrays","title":"2. Fixed Size (Static Arrays)","text":"<ul> <li>Size is determined at creation time</li> <li>Cannot be changed during runtime</li> <li>Memory is allocated on the stack or heap</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#3-random-access","title":"3. Random Access","text":"<ul> <li>O(1) time complexity for accessing any element</li> <li>Direct access using index: <code>array[index]</code></li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#time-complexities","title":"Time Complexities","text":"Operation Time Complexity Access O(1) Search O(n) Insertion O(n) Deletion O(n)"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#python-implementation","title":"Python Implementation","text":"<pre><code># Static-like array using list (Python lists are dynamic)\nnumbers = [1, 2, 3, 4, 5]\n\n# Access element\nfirst_element = numbers[0]  # O(1)\n\n# Search for element\ndef linear_search(arr, target):\n    for i in range(len(arr)):\n        if arr[i] == target:\n            return i\n    return -1\n\n# Insert element (at end)\nnumbers.append(6)  # O(1) amortized\n\n# Insert element (at specific position)\nnumbers.insert(2, 10)  # O(n)\n\n# Delete element\nnumbers.remove(10)  # O(n)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#advantages","title":"Advantages","text":"<ol> <li>Fast Access: O(1) random access to elements</li> <li>Memory Efficient: No extra memory overhead per element</li> <li>Cache Friendly: Contiguous memory improves cache performance</li> <li>Simple: Easy to understand and implement</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#disadvantages","title":"Disadvantages","text":"<ol> <li>Fixed Size: Cannot resize (for static arrays)</li> <li>Expensive Insertion/Deletion: O(n) for arbitrary positions</li> <li>Memory Waste: May allocate more memory than needed</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#when-to-use-arrays","title":"When to Use Arrays","text":"<ul> <li>Known size: When you know the number of elements in advance</li> <li>Frequent access: When you need to frequently access elements by index</li> <li>Memory constraints: When memory efficiency is important</li> <li>Mathematical operations: For matrix operations, numerical computations</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#array-vs-other-data-structures","title":"Array vs Other Data Structures","text":"Structure Access Search Insert Delete Memory Array O(1) O(n) O(n) O(n) Low Linked List O(n) O(n) O(1) O(1) High Hash Table O(1) O(1) O(1) O(1) Medium"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Arrays_Overview/#next-topics","title":"Next Topics","text":"<ul> <li>Binary_Search_Fundamentals - Efficient searching in sorted arrays</li> <li>Array_Problems - Common array-based coding problems</li> <li>Dynamic_Arrays - Resizable arrays (Python lists, Java ArrayList)</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/","title":"Dynamic Arrays","text":"<p>Dynamic arrays are resizable arrays that can grow or shrink during runtime. Unlike static arrays, they automatically manage memory allocation and provide flexibility in size.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#what-are-dynamic-arrays","title":"What are Dynamic Arrays?","text":"<p>Dynamic arrays automatically resize themselves when elements are added or removed. They maintain the benefits of arrays (random access) while providing flexibility in size.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#how-dynamic-arrays-work","title":"How Dynamic Arrays Work","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#1-capacity-vs-size","title":"1. Capacity vs Size","text":"<ul> <li>Size: Number of elements currently stored</li> <li>Capacity: Total memory allocated (usually larger than size)</li> <li>When size exceeds capacity, array is resized</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#2-resizing-strategy","title":"2. Resizing Strategy","text":"<ul> <li>Typically doubles the capacity when full</li> <li>May shrink when size becomes much smaller than capacity</li> <li>Amortizes the cost of resizing over many operations</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#python-lists-dynamic-arrays","title":"Python Lists (Dynamic Arrays)","text":"<pre><code># Python lists are dynamic arrays\nnumbers = []  # Empty dynamic array\n\n# Adding elements\nnumbers.append(1)      # O(1) amortized\nnumbers.append(2)      # O(1) amortized\nnumbers.extend([3, 4]) # O(k) where k is number of elements\n\n# Access\nprint(numbers[0])      # O(1)\n\n# Insertion at specific position\nnumbers.insert(1, 10)  # O(n)\n\n# Deletion\nnumbers.pop()          # O(1) - remove last\nnumbers.pop(0)         # O(n) - remove first\nnumbers.remove(10)     # O(n) - remove by value\n\n# Size information\nprint(len(numbers))    # Current size\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#time-complexities","title":"Time Complexities","text":"Operation Average Worst Case Access O(1) O(1) Append O(1) O(n)* Insert O(n) O(n) Delete O(n) O(n) Search O(n) O(n) <p>*Worst case append is O(n) when resizing is needed</p>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#memory-management","title":"Memory Management","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#resizing-process","title":"Resizing Process","text":"<pre><code># Conceptual implementation of dynamic array resizing\nclass DynamicArray:\n    def __init__(self):\n        self.capacity = 1\n        self.size = 0\n        self.data = [None] * self.capacity\n\n    def append(self, element):\n        # Check if resize is needed\n        if self.size &gt;= self.capacity:\n            self._resize()\n\n        self.data[self.size] = element\n        self.size += 1\n\n    def _resize(self):\n        # Double the capacity\n        old_capacity = self.capacity\n        self.capacity *= 2\n\n        # Create new array and copy elements\n        new_data = [None] * self.capacity\n        for i in range(self.size):\n            new_data[i] = self.data[i]\n\n        self.data = new_data\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#advantages","title":"Advantages","text":"<ol> <li>Flexible Size: Can grow and shrink as needed</li> <li>Automatic Management: Handles memory allocation automatically</li> <li>Amortized Performance: Most operations are still fast on average</li> <li>Easy to Use: Simple interface for adding/removing elements</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#disadvantages","title":"Disadvantages","text":"<ol> <li>Memory Overhead: May waste memory due to over-allocation</li> <li>Occasional Slow Operations: Resizing can cause O(n) operations</li> <li>Memory Fragmentation: Frequent resizing can fragment memory</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#common-dynamic-array-types","title":"Common Dynamic Array Types","text":""},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#python","title":"Python","text":"<pre><code># List (built-in dynamic array)\nmy_list = [1, 2, 3]\nmy_list.append(4)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#java","title":"Java","text":"<pre><code>// ArrayList\nArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;();\nlist.add(1);\nlist.add(2);\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#c","title":"C++","text":"<pre><code>// std::vector\nstd::vector&lt;int&gt; vec;\nvec.push_back(1);\nvec.push_back(2);\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Pre-allocate when size is known:    <pre><code># If you know approximate size\nnumbers = [None] * 1000  # Pre-allocate\n</code></pre></p> </li> <li> <p>Use appropriate initial capacity:    <pre><code># For large datasets, start with reasonable size\nlarge_list = []\nlarge_list.extend([0] * 10000)  # Better than 10000 appends\n</code></pre></p> </li> <li> <p>Consider memory usage:    <pre><code># Shrink if memory is a concern\nif len(my_list) &lt; len(my_list) // 4:\n    # Consider shrinking or using different structure\n</code></pre></p> </li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#when-to-use-dynamic-arrays","title":"When to Use Dynamic Arrays","text":"<ul> <li>Unknown size: When you don't know how many elements you'll need</li> <li>Frequent additions: When you frequently add elements to the end</li> <li>General purpose: Good default choice for most applications</li> <li>Random access needed: When you need O(1) access to elements</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Arrays/Dynamic_Arrays/#related-topics","title":"Related Topics","text":"<ul> <li>Arrays_Overview - Static arrays fundamentals</li> <li>Array_Problems - Common problems using arrays</li> <li>Sliding_Window_Overview - Pattern that works well with arrays</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/","title":"Hash Functions and Collisions","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#hash-functions","title":"Hash Functions","text":"<p>A hash function is the heart of any hash table. It takes a key as input and produces an integer (hash code) that determines where the key-value pair should be stored in the underlying array.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#properties-of-good-hash-functions","title":"Properties of Good Hash Functions","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#1-deterministic","title":"1. Deterministic","text":"<ul> <li>Same input always produces same output</li> <li>Essential for consistent lookups</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#2-uniform-distribution","title":"2. Uniform Distribution","text":"<ul> <li>Keys should be spread evenly across the hash table</li> <li>Minimizes clustering and collisions</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#3-fast-computation","title":"3. Fast Computation","text":"<ul> <li>Should be O(1) time complexity</li> <li>Avoid expensive operations</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#4-avalanche-effect","title":"4. Avalanche Effect","text":"<ul> <li>Small changes in input cause large changes in output</li> <li>Helps distribute similar keys</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#common-hash-function-techniques","title":"Common Hash Function Techniques","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#1-division-method","title":"1. Division Method","text":"<p><pre><code>def hash_function(key, table_size):\n    return key % table_size\n</code></pre> - Simple and fast - Works well with prime table sizes - Poor performance with certain key patterns</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#2-multiplication-method","title":"2. Multiplication Method","text":"<p><pre><code>def hash_function(key, table_size):\n    A = 0.6180339887  # Golden ratio - 1\n    return int(table_size * ((key * A) % 1))\n</code></pre> - More uniform distribution - Table size doesn't need to be prime - Slightly more expensive computation</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#3-string-hashing","title":"3. String Hashing","text":"<p><pre><code>def hash_string(s, table_size):\n    hash_value = 0\n    for char in s:\n        hash_value = (hash_value * 31 + ord(char)) % table_size\n    return hash_value\n</code></pre> - Polynomial rolling hash - 31 is a common multiplier (prime number) - Used in Java's String.hashCode()</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#collisions","title":"Collisions","text":"<p>A collision occurs when two different keys hash to the same index. Since hash tables have finite size, collisions are inevitable (pigeonhole principle). When a collision occurs, we are faced with a dilemma - where do we store the new key-value pair since that index is already occupied?</p> <p>Here are two common strategies to handle such scenarios:</p> <ol> <li> <p>Chaining: In this method, each index (or\u00a0<code>bucket</code>) in the array hosts a linked list of all key-value pairs that hash to the same index. When a collision occurs, we simply go to the collided index and append the new key-value pair to the existing linked list.</p> </li> <li> <p>Open Addressing: Upon encountering a collision, the hash table searches for another free slot or index in the table (possibly the next available empty slot) and assigns that location to the new key-value pair. This approach requires a suitable probing strategy to ensure efficient use of table space.</p> </li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#collision-resolution-strategies","title":"Collision Resolution Strategies","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#1-separate-chaining-open-hashing","title":"1. Separate Chaining (Open Hashing)","text":"<p>Store multiple key-value pairs at each array index using a secondary data structure.</p> <pre><code>class HashTableChaining:\n    def __init__(self, size):\n        self.size = size\n        self.table = [[] for _ in range(size)]\n\n    def _hash(self, key):\n        return hash(key) % self.size\n\n    def insert(self, key, value):\n        index = self._hash(key)\n        bucket = self.table[index]\n\n        # Check if key already exists\n        for i, (k, v) in enumerate(bucket):\n            if k == key:\n                bucket[i] = (key, value)  # Update existing\n                return\n\n        bucket.append((key, value))  # Add new\n\n    def get(self, key):\n        index = self._hash(key)\n        bucket = self.table[index]\n\n        for k, v in bucket:\n            if k == key:\n                return v\n\n        raise KeyError(key)\n</code></pre> <p>Advantages: - Simple to implement - Never runs out of space (can always add to chain) - Good performance with good hash function</p> <p>Disadvantages: - Extra memory overhead for pointers/lists - Cache performance can be poor - Worst case: O(n) if all keys hash to same bucket</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#2-open-addressing-closed-hashing","title":"2. Open Addressing (Closed Hashing)","text":"<p>Store all key-value pairs directly in the hash table array. When collision occurs, probe for next available slot.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#linear-probing","title":"Linear Probing","text":"<pre><code>class HashTableLinearProbing:\n    def __init__(self, size):\n        self.size = size\n        self.keys = [None] * size\n        self.values = [None] * size\n\n    def _hash(self, key):\n        return hash(key) % self.size\n\n    def insert(self, key, value):\n        index = self._hash(key)\n\n        # Linear probing\n        while self.keys[index] is not None:\n            if self.keys[index] == key:\n                self.values[index] = value  # Update existing\n                return\n            index = (index + 1) % self.size\n\n        # Insert at empty slot\n        self.keys[index] = key\n        self.values[index] = value\n\n    def get(self, key):\n        index = self._hash(key)\n\n        # Linear probing for search\n        while self.keys[index] is not None:\n            if self.keys[index] == key:\n                return self.values[index]\n            index = (index + 1) % self.size\n\n        raise KeyError(key)\n</code></pre> <p>Advantages: - Better cache performance (data locality) - No extra memory for pointers - Simple implementation</p> <p>Disadvantages: - Primary clustering (consecutive occupied slots) - Requires careful deletion handling - Performance degrades as load factor increases</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#quadratic-probing","title":"Quadratic Probing","text":"<pre><code>def quadratic_probe(self, key):\n    index = self._hash(key)\n    i = 0\n    while self.keys[index] is not None:\n        if self.keys[index] == key:\n            return index\n        i += 1\n        index = (self._hash(key) + i*i) % self.size\n    return index\n</code></pre> <p>Advantages: - Reduces primary clustering - Better distribution than linear probing</p> <p>Disadvantages: - Secondary clustering - May not probe all slots - More complex deletion</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#double-hashing","title":"Double Hashing","text":"<pre><code>def double_hash_probe(self, key):\n    hash1 = hash(key) % self.size\n    hash2 = 7 - (hash(key) % 7)  # Second hash function\n\n    index = hash1\n    i = 0\n    while self.keys[index] is not None:\n        if self.keys[index] == key:\n            return index\n        i += 1\n        index = (hash1 + i * hash2) % self.size\n    return index\n</code></pre> <p>Advantages: - Eliminates clustering - Good distribution with proper second hash function</p> <p>Disadvantages: - More complex implementation - Requires two hash functions</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#load-factor-and-resizing","title":"Load Factor and Resizing","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#load-factor","title":"Load Factor (\u03b1)","text":"<pre><code>\u03b1 = n / m\nwhere n = number of elements, m = table size\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#performance-impact","title":"Performance Impact","text":"<ul> <li>Separate Chaining: Performance degrades linearly with load factor</li> <li>Open Addressing: Performance degrades exponentially after \u03b1 &gt; 0.7</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#dynamic-resizing","title":"Dynamic Resizing","text":"<pre><code>def resize(self):\n    old_keys = self.keys\n    old_values = self.values\n\n    # Double the size\n    self.size *= 2\n    self.keys = [None] * self.size\n    self.values = [None] * self.size\n\n    # Rehash all existing elements\n    for i in range(len(old_keys)):\n        if old_keys[i] is not None:\n            self.insert(old_keys[i], old_values[i])\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#pythons-hash-implementation","title":"Python's Hash Implementation","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#python-dict","title":"Python dict","text":"<ul> <li>Uses open addressing with random probing</li> <li>Maintains insertion order (since Python 3.7)</li> <li>Automatically resizes when load factor exceeds 2/3</li> <li>Uses sophisticated hash functions for different types</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#python-set","title":"Python set","text":"<ul> <li>Similar to dict but stores only keys</li> <li>Uses dummy values internally</li> <li>Same collision resolution strategy</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#common-hash-function-pitfalls","title":"Common Hash Function Pitfalls","text":"<ol> <li>Poor Distribution: Using simple modulo with non-prime table sizes</li> <li>Predictable Patterns: Hash functions that don't handle similar keys well</li> <li>Integer Overflow: Not handling large hash values properly</li> <li>Security Issues: Hash functions vulnerable to collision attacks</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#best-practices","title":"Best Practices","text":"<ol> <li>Choose Prime Table Sizes: Better distribution with division method</li> <li>Monitor Load Factor: Resize before performance degrades</li> <li>Use Quality Hash Functions: Consider built-in functions for complex types</li> <li>Handle Collisions Appropriately: Choose strategy based on use case</li> <li>Consider Security: Use cryptographic hash functions for security-critical applications</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Functions_and_Collisions/#next-steps","title":"Next Steps","text":"<ul> <li>Hash Tables Overview - Basic concepts</li> <li>Python Dictionaries - Implementation details</li> <li>Hash Table Problems - Practice problems</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/","title":"Hash Table Problems","text":"<p>This section covers common coding problems that can be efficiently solved using hash tables. These problems frequently appear in technical interviews and demonstrate the power of hash-based data structures.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#problem-categories","title":"Problem Categories","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#1-frequency-counting","title":"1. Frequency Counting","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#2-two-sum-variants","title":"2. Two-Sum Variants","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#3-substring-problems","title":"3. Substring Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#4-set-operations","title":"4. Set Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#5-caching-and-memoization","title":"5. Caching and Memoization","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#1-frequency-counting-problems","title":"1. Frequency Counting Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#character-frequency","title":"Character Frequency","text":"<p>Problem: Count the frequency of each character in a string.</p> <pre><code>def char_frequency(s):\n    \"\"\"\n    Time: O(n), Space: O(k) where k is number of unique characters\n    \"\"\"\n    freq = {}\n    for char in s:\n        freq[char] = freq.get(char, 0) + 1\n    return freq\n\n# Example\ntext = \"hello world\"\nprint(char_frequency(text))\n# Output: {'h': 1, 'e': 1, 'l': 3, 'o': 2, ' ': 1, 'w': 1, 'r': 1, 'd': 1}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#most-frequent-element","title":"Most Frequent Element","text":"<p>Problem: Find the most frequently occurring element in an array.</p> <pre><code>def most_frequent(arr):\n    \"\"\"\n    Time: O(n), Space: O(n)\n    \"\"\"\n    if not arr:\n        return None\n\n    freq = {}\n    for num in arr:\n        freq[num] = freq.get(num, 0) + 1\n\n    return max(freq, key=freq.get)\n\n# Example\nnumbers = [1, 3, 2, 3, 4, 3, 2]\nprint(most_frequent(numbers))  # Output: 3\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#2-two-sum-variants_1","title":"2. Two-Sum Variants","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#classic-two-sum","title":"Classic Two Sum","text":"<p>Problem: Find two numbers in array that add up to target.</p> <pre><code>def two_sum(nums, target):\n    \"\"\"\n    Time: O(n), Space: O(n)\n    \"\"\"\n    seen = {}\n    for i, num in enumerate(nums):\n        complement = target - num\n        if complement in seen:\n            return [seen[complement], i]\n        seen[num] = i\n    return []\n\n# Example\nnums = [2, 7, 11, 15]\ntarget = 9\nprint(two_sum(nums, target))  # Output: [0, 1]\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#three-sum","title":"Three Sum","text":"<p>Problem: Find all unique triplets that sum to zero.</p> <pre><code>def three_sum(nums):\n    \"\"\"\n    Time: O(n\u00b2), Space: O(1) excluding output\n    \"\"\"\n    nums.sort()\n    result = []\n\n    for i in range(len(nums) - 2):\n        # Skip duplicates for first number\n        if i &gt; 0 and nums[i] == nums[i-1]:\n            continue\n\n        left, right = i + 1, len(nums) - 1\n\n        while left &lt; right:\n            total = nums[i] + nums[left] + nums[right]\n\n            if total == 0:\n                result.append([nums[i], nums[left], nums[right]])\n\n                # Skip duplicates\n                while left &lt; right and nums[left] == nums[left + 1]:\n                    left += 1\n                while left &lt; right and nums[right] == nums[right - 1]:\n                    right -= 1\n\n                left += 1\n                right -= 1\n            elif total &lt; 0:\n                left += 1\n            else:\n                right -= 1\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#3-substring-problems_1","title":"3. Substring Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#longest-substring-without-repeating-characters","title":"Longest Substring Without Repeating Characters","text":"<p>Problem: Find length of longest substring without repeating characters.</p> <pre><code>def length_of_longest_substring(s):\n    \"\"\"\n    Time: O(n), Space: O(min(m,n)) where m is character set size\n    \"\"\"\n    char_index = {}\n    left = 0\n    max_length = 0\n\n    for right, char in enumerate(s):\n        if char in char_index and char_index[char] &gt;= left:\n            left = char_index[char] + 1\n\n        char_index[char] = right\n        max_length = max(max_length, right - left + 1)\n\n    return max_length\n\n# Example\ns = \"abcabcbb\"\nprint(length_of_longest_substring(s))  # Output: 3 (\"abc\")\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#group-anagrams","title":"Group Anagrams","text":"<p>Problem: Group strings that are anagrams of each other.</p> <pre><code>def group_anagrams(strs):\n    \"\"\"\n    Time: O(n * k log k) where n is number of strings, k is max string length\n    Space: O(n * k)\n    \"\"\"\n    from collections import defaultdict\n\n    anagram_groups = defaultdict(list)\n\n    for s in strs:\n        # Sort characters to create key\n        key = ''.join(sorted(s))\n        anagram_groups[key].append(s)\n\n    return list(anagram_groups.values())\n\n# Example\nwords = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]\nprint(group_anagrams(words))\n# Output: \\[\\[['eat', 'tea', 'ate'], ['tan', 'nat'], ['bat']\\]\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#4-set-operations_1","title":"4. Set Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#intersection-of-two-arrays","title":"Intersection of Two Arrays","text":"<p>Problem: Find intersection of two arrays.</p> <pre><code>def intersection(nums1, nums2):\n    \"\"\"\n    Time: O(n + m), Space: O(min(n,m))\n    \"\"\"\n    set1 = set(nums1)\n    result = set()\n\n    for num in nums2:\n        if num in set1:\n            result.add(num)\n\n    return list(result)\n\n# Example\nnums1 = [1, 2, 2, 1]\nnums2 = [2, 2]\nprint(intersection(nums1, nums2))  # Output: [2]\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#find-missing-number","title":"Find Missing Number","text":"<p>Problem: Find missing number in array containing n distinct numbers from 0 to n.</p> <pre><code>def missing_number(nums):\n    \"\"\"\n    Multiple approaches - Hash table version\n    Time: O(n), Space: O(n)\n    \"\"\"\n    num_set = set(nums)\n    n = len(nums)\n\n    for i in range(n + 1):\n        if i not in num_set:\n            return i\n\n    return -1  # Should never reach here\n\n# More efficient approaches:\ndef missing_number_math(nums):\n    \"\"\"\n    Time: O(n), Space: O(1)\n    \"\"\"\n    n = len(nums)\n    expected_sum = n * (n + 1) // 2\n    actual_sum = sum(nums)\n    return expected_sum - actual_sum\n\ndef missing_number_xor(nums):\n    \"\"\"\n    Time: O(n), Space: O(1)\n    \"\"\"\n    missing = len(nums)\n    for i, num in enumerate(nums):\n        missing ^= i ^ num\n    return missing\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#5-caching-and-memoization_1","title":"5. Caching and Memoization","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#lru-cache","title":"LRU Cache","text":"<p>Problem: Implement Least Recently Used cache.</p> <pre><code>class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}  # key -&gt; node\n\n        # Create dummy head and tail nodes\n        self.head = Node(0, 0)\n        self.tail = Node(0, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n\n    def get(self, key):\n        if key in self.cache:\n            node = self.cache[key]\n            # Move to head (most recently used)\n            self._remove(node)\n            self._add_to_head(node)\n            return node.value\n        return -1\n\n    def put(self, key, value):\n        if key in self.cache:\n            # Update existing\n            node = self.cache[key]\n            node.value = value\n            self._remove(node)\n            self._add_to_head(node)\n        else:\n            # Add new\n            if len(self.cache) &gt;= self.capacity:\n                # Remove least recently used\n                lru = self.tail.prev\n                self._remove(lru)\n                del self.cache[lru.key]\n\n            node = Node(key, value)\n            self.cache[key] = node\n            self._add_to_head(node)\n\n    def _remove(self, node):\n        node.prev.next = node.next\n        node.next.prev = node.prev\n\n    def _add_to_head(self, node):\n        node.next = self.head.next\n        self.head.next.prev = node\n        self.head.next = node\n        node.prev = self.head\n\nclass Node:\n    def __init__(self, key, value):\n        self.key = key\n        self.value = value\n        self.prev = None\n        self.next = None\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#fibonacci-with-memoization","title":"Fibonacci with Memoization","text":"<p>Problem: Compute Fibonacci numbers efficiently.</p> <pre><code>def fibonacci_memo(n, memo={}):\n    \"\"\"\n    Time: O(n), Space: O(n)\n    \"\"\"\n    if n in memo:\n        return memo[n]\n\n    if n &lt;= 1:\n        return n\n\n    memo[n] = fibonacci_memo(n-1, memo) + fibonacci_memo(n-2, memo)\n    return memo[n]\n\n# Using functools.lru_cache decorator\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fibonacci_lru(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci_lru(n-1) + fibonacci_lru(n-2)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#problem-solving-patterns","title":"Problem-Solving Patterns","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#when-to-use-hash-tables","title":"When to Use Hash Tables","text":"<ol> <li>Fast Lookups: Need O(1) average case access</li> <li>Counting: Frequency analysis problems</li> <li>Caching: Store computed results</li> <li>Set Operations: Intersection, union, difference</li> <li>Mapping: Key-value relationships</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#common-techniques","title":"Common Techniques","text":"<ol> <li>Use as Counter: <code>collections.Counter</code> or manual counting</li> <li>Use as Set: Fast membership testing</li> <li>Use as Cache: Store expensive computations</li> <li>Two-Pointer with Hash: Combine with other techniques</li> <li>Sliding Window with Hash: Track elements in window</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#timespace-trade-offs","title":"Time/Space Trade-offs","text":"<ul> <li>Time: Usually improves from O(n\u00b2) to O(n)</li> <li>Space: Additional O(n) space for hash table</li> <li>Worth it: When lookup speed is critical</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#practice-problems","title":"Practice Problems","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#easy","title":"Easy","text":"<ol> <li>Contains Duplicate</li> <li>Valid Anagram</li> <li>Two Sum</li> <li>Intersection of Two Arrays</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#medium","title":"Medium","text":"<ol> <li>Group Anagrams</li> <li>Top K Frequent Elements</li> <li>Longest Substring Without Repeating Characters</li> <li>4Sum II</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#hard","title":"Hard","text":"<ol> <li>Substring with Concatenation of All Words</li> <li>LRU Cache</li> <li>First Missing Positive</li> <li>Longest Consecutive Sequence</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Table_Problems/#related-topics","title":"Related Topics","text":"<ul> <li>Python Dictionaries - Implementation details</li> <li>Python Sets - Set operations</li> <li>Time Complexity Guide - Analysis techniques</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/","title":"Hash Tables Overview","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#what-are-hash-tables","title":"What are Hash Tables?","text":"<p>Hash tables (also known as hash maps) are one of the most important and widely-used data structures in computer science. They provide extremely fast average-case performance for insertion, deletion, and lookup operations.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#key-concepts","title":"Key Concepts","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#basic-structure","title":"Basic Structure","text":"<ul> <li>Key-Value Pairs: Hash tables store data as key-value pairs</li> <li>Hash Function: A function that converts keys into array indices</li> <li>Buckets/Slots: Array positions where data is stored</li> <li>Load Factor: Ratio of stored elements to total capacity</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#how-hash-tables-work","title":"How Hash Tables Work","text":"<ol> <li>Hashing: Apply hash function to key to get array index</li> <li>Storage: Store the key-value pair at the calculated index</li> <li>Collision Handling: Deal with cases where multiple keys hash to the same index</li> <li>Dynamic Resizing: Grow/shrink the table to maintain performance</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#time-complexity","title":"Time Complexity","text":"Operation Average Case Worst Case Search O(1) O(n) Insert O(1) O(n) Delete O(1) O(n)"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#space-complexity","title":"Space Complexity","text":"<ul> <li>Space: O(n) where n is the number of key-value pairs</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#common-use-cases","title":"Common Use Cases","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#1-caching-and-memoization","title":"1. Caching and Memoization","text":"<pre><code># Simple cache implementation\ncache = {}\ndef expensive_function(x):\n    if x in cache:\n        return cache[x]\n    result = complex_calculation(x)\n    cache[x] = result\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#2-counting-and-frequency-analysis","title":"2. Counting and Frequency Analysis","text":"<pre><code># Count character frequencies\ntext = \"hello world\"\nfreq = {}\nfor char in text:\n    freq[char] = freq.get(char, 0) + 1\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#3-database-indexing","title":"3. Database Indexing","text":"<ul> <li>Primary keys in databases</li> <li>Creating fast lookup tables</li> <li>Join operations</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#4-symbol-tables","title":"4. Symbol Tables","text":"<ul> <li>Variable names in compilers</li> <li>Function lookup tables</li> <li>Configuration settings</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#hash-tables-in-different-languages","title":"Hash Tables in Different Languages","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#python","title":"Python","text":"<ul> <li>dict: Built-in hash table implementation</li> <li>set: Hash table storing only keys (no values)</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#java","title":"Java","text":"<ul> <li>HashMap: General-purpose hash table</li> <li>HashSet: Set implementation using hash table</li> <li>Hashtable: Thread-safe version</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#javascript","title":"JavaScript","text":"<ul> <li>Object: Properties stored as hash table</li> <li>Map: Modern hash table implementation</li> <li>Set: Collection of unique values</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#real-world-applications","title":"Real-World Applications","text":"<ol> <li>Web Browsers: URL caching, DNS lookups</li> <li>Databases: Index structures, query optimization</li> <li>Compilers: Symbol tables, keyword recognition</li> <li>Operating Systems: Process tables, file systems</li> <li>Networking: Routing tables, MAC address tables</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#advantages","title":"Advantages","text":"<ul> <li>Fast Operations: O(1) average case for basic operations</li> <li>Flexible Keys: Can use various data types as keys</li> <li>Memory Efficient: Good space utilization with proper load factor</li> <li>Versatile: Suitable for many different problems</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#disadvantages","title":"Disadvantages","text":"<ul> <li>Worst Case Performance: Can degrade to O(n) with poor hash function</li> <li>Memory Overhead: Requires extra space for hash table structure</li> <li>No Ordering: Elements are not stored in any particular order</li> <li>Hash Function Dependency: Performance heavily depends on quality of hash function</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#next-steps","title":"Next Steps","text":"<ol> <li>Hash Functions and Collisions - Learn about hash function design and collision resolution</li> <li>Python Dictionaries - Explore Python's dict implementation</li> <li>Python Sets - Understand Python's set implementation</li> <li>Hash Table Problems - Practice common coding problems</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Hash_Tables_Overview/#related-topics","title":"Related Topics","text":"<ul> <li>Array_Intersection - Using hash tables for set operations  </li> <li>Non_Repeating_Elements - Hash table applications</li> <li>Time_Complexity_Guide - Understanding Big O notation</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/","title":"Python Dictionaries Overview","text":"<p>Python dictionaries are mutable, unordered collections of key-value pairs. They provide fast O(1) average time complexity for lookups, insertions, and deletions.</p> <p>In a hash table (or Python dictionary), there isn\u2019t a concept of a fixed \u201cindex\u201d for key-value pairs like in a list\u2014the data is stored based on the hash of the key, not in a specific order. - Dictionaries are unordered (before Python 3.7) or insertion-ordered (Python 3.7+), but you still can\u2019t access by index directly. - If you really need the \u201cindex\u201d (position in the list of items), you could convert the items to a list and use\u00a0<code>.index()</code>.</p> <p>Python dictionaries can be used to tackle tasks that involve the manipulation and analysis of strings, validating password strengths, and managing personnel data.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Key-Value Pairs: Each element is a key-value pair</li> <li>Unordered: Elements are not stored in any specific order (Python 3.7+ maintains insertion order)</li> <li>Mutable: Can add, modify, or remove key-value pairs</li> <li>Hashable Keys: Keys must be hashable (immutable)</li> <li>Unique Keys: No duplicate keys allowed</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#basic-operations","title":"Basic Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#creating-dictionaries","title":"Creating Dictionaries","text":"<pre><code># Empty dictionary\nempty_dict = {}\n\n# Dictionary with initial values\nperson = {'name': 'John', 'age': 30, 'city': 'New York'}\n\n# Using dict() constructor\nnumbers = dict(one=1, two=2, three=3)\n\n# From list of tuples\npairs = [('a', 1), ('b', 2), ('c', 3)]\ndict_from_pairs = dict(pairs)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#accessing-and-modifying","title":"Accessing and Modifying","text":"<pre><code>age = person.get('age', 0)  # Returns default value if key doesn't exist\n</code></pre> <pre><code>person = {'name': 'John', 'age': 30}\n\n# Accessing values\nname = person['name']  # Raises KeyError if key doesn't exist\n\n# Adding/Modifying\nperson['city'] = 'New York'  # Add new key-value pair\nperson['age'] = 31  # Modify existing value\n\n# Removing\ndel person['age']  # Raises KeyError if key doesn't exist\ncity = person.pop('city', 'Unknown')  # Returns default if key doesn't exist\nperson.clear()  # Remove all items\n\n# Accessing keys via known values\nmatched_key = [key for key, val in book_ratings.items() if val == value]\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#common-methods","title":"Common Methods","text":"<pre><code>person = {'name': 'John', 'age': 30, 'city': 'New York'}\n\n# Keys, values, and items\nkeys = person.keys()  # dict_keys(['name', 'age', 'city'])\nvalues = person.values()  # dict_values(['John', 30, 'New York'])\nitems = person.items()  # dict_items([('name', 'John'), ('age', 30), ('city', 'New York')])\n\n# Membership testing\n'name' in person  # True\n'phone' not in person  # True\n\n# Length\nlen(person)  # 3\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#dictionary-operations","title":"Dictionary Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#merging-dictionaries","title":"Merging Dictionaries","text":"<pre><code>dict1 = {'a': 1, 'b': 2}\ndict2 = {'c': 3, 'd': 4}\n\n# Using update() method\ndict1.update(dict2)  # Modifies dict1 in-place\n\n# Using | operator (Python 3.9+)\nmerged = dict1 | dict2  # Creates new dictionary\n\n# Using ** unpacking\nmerged = {**dict1, **dict2}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#dictionary-comprehension","title":"Dictionary Comprehension","text":"<pre><code># Create dictionary from list\nnumbers = [1, 2, 3, 4, 5]\nsquares = {x: x**2 for x in numbers}\n\n# Filter dictionary\nperson = {'name': 'John', 'age': 30, 'city': 'New York', 'phone': '123-456'}\nfiltered = {k: v for k, v in person.items() if isinstance(v, str)}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#time-complexity","title":"Time Complexity","text":"<ul> <li>Access: O(1) average case</li> <li>Insert/Update: O(1) average case</li> <li>Delete: O(1) average case</li> <li>Search: O(1) average case</li> <li>Iteration: O(n)</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#common-use-cases","title":"Common Use Cases","text":"<ol> <li>Caching/Memoization: Store computed results</li> <li>Counting: Track frequency of elements</li> <li>Grouping: Organize data by categories</li> <li>Configuration: Store settings and parameters</li> <li>JSON-like Data: Represent structured data</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionaries/#related-topics","title":"Related Topics","text":"<ul> <li>Dictionary Operations - Detailed dictionary methods and techniques</li> <li>Array Intersection - Using dictionaries for counting</li> <li>Anagram Pairs - Dictionary-based anagram detection</li> <li>Unique Strings - Dictionary-based string problems</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/","title":"Dictionary Operations","text":"<p>Detailed dictionary operations and methods in Python.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#basic-dictionary-methods","title":"Basic Dictionary Methods","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#creating-and-modifying","title":"Creating and Modifying","text":"<pre><code># Create dictionary\nmy_dict = {}\n\n# Add/Update items\nmy_dict['key'] = 'value'\nmy_dict.update({'key2': 'value2', 'key3': 'value3'})\n\n# Get value with default\nvalue = my_dict.get('key', 'default_value')\n\n# Remove items\ndel my_dict['key']  # Raises KeyError if key doesn't exist\nvalue = my_dict.pop('key', 'default')  # Returns default if key doesn't exist\nmy_dict.clear()  # Remove all items\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#accessing-dictionary-data","title":"Accessing Dictionary Data","text":"<pre><code>person = {'name': 'John', 'age': 30, 'city': 'New York'}\n\n# Get keys, values, and items\nkeys = person.keys()      # dict_keys(['name', 'age', 'city'])\nvalues = person.values()  # dict_values(['John', 30, 'New York'])\nitems = person.items()    # dict_items([('name', 'John'), ('age', 30), ('city', 'New York')])\n\n# Iterate through dictionary\nfor key in person:\n    print(key, person[key])\n\nfor key, value in person.items():\n    print(key, value)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#advanced-dictionary-operations","title":"Advanced Dictionary Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#dictionary-comprehension","title":"Dictionary Comprehension","text":"<pre><code># Create dictionary from list\nnumbers = [1, 2, 3, 4, 5]\nsquares = {x: x**2 for x in numbers}  # {1: 1, 2: 4, 3: 9, 4: 16, 5: 25}\n\n# Filter dictionary\nperson = {'name': 'John', 'age': 30, 'city': 'New York', 'phone': '123-456'}\nstring_values = {k: v for k, v in person.items() if isinstance(v, str)}\n\n# Conditional comprehension\ngrades = {'Alice': 85, 'Bob': 92, 'Charlie': 78, 'David': 95}\npassed = {name: grade for name, grade in grades.items() if grade &gt;= 80}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#merging-dictionaries","title":"Merging Dictionaries","text":"<pre><code>dict1 = {'a': 1, 'b': 2}\ndict2 = {'c': 3, 'd': 4}\n\n# Using update() method (modifies dict1)\ndict1.update(dict2)\n\n# Using | operator (Python 3.9+)\nmerged = dict1 | dict2\n\n# Using ** unpacking\nmerged = {**dict1, **dict2}\n\n# Using dict() constructor\nmerged = dict(dict1, **dict2)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#nested-dictionaries","title":"Nested Dictionaries","text":"<pre><code># Create nested dictionary\nstudents = {\n    'Alice': {'age': 20, 'grade': 'A', 'courses': ['Math', 'Physics']},\n    'Bob': {'age': 22, 'grade': 'B', 'courses': ['Chemistry', 'Biology']}\n}\n\n# Access nested values\nalice_age = students['Alice']['age']\nalice_courses = students['Alice']['courses']\n\n# Modify nested values\nstudents['Alice']['grade'] = 'A+'\nstudents['Bob']['courses'].append('Math')\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#dictionary-methods","title":"Dictionary Methods","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#default-values","title":"Default Values","text":"<pre><code>from collections import defaultdict\n\n# Default dictionary with list\ndd = defaultdict(list)\ndd['fruits'].append('apple')\ndd['fruits'].append('banana')\ndd['vegetables'].append('carrot')\n\n# Default dictionary with int (for counting)\nword_count = defaultdict(int)\nfor word in ['apple', 'banana', 'apple', 'cherry']:\n    word_count[word] += 1\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#counter","title":"Counter","text":"<pre><code>from collections import Counter\n\n# Count occurrences\nwords = ['apple', 'banana', 'apple', 'cherry', 'banana', 'apple']\nword_counts = Counter(words)\nprint(word_counts)  # Counter({'apple': 3, 'banana': 2, 'cherry': 1})\n\n# Most common elements\nmost_common = word_counts.most_common(2)  # [('apple', 3), ('banana', 2)]\n\n# Arithmetic operations\ncounter1 = Counter(['a', 'b', 'c', 'a'])\ncounter2 = Counter(['a', 'b', 'd'])\ncombined = counter1 + counter2  # Counter({'a': 3, 'b': 2, 'c': 1, 'd': 1})\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#performance-considerations","title":"Performance Considerations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#time-complexity","title":"Time Complexity","text":"Operation Average Case Worst Case Access O(1) O(n) Insert/Update O(1) O(n) Delete O(1) O(n) Search O(1) O(n) Iteration O(n) O(n)"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#memory-usage","title":"Memory Usage","text":"<ul> <li>Dictionaries use more memory than lists due to hash table overhead</li> <li>Trade-off: memory for speed</li> <li>Use dictionaries when you need fast key-based lookups</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#common-patterns","title":"Common Patterns","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#grouping-data","title":"Grouping Data","text":"<pre><code># Group students by grade\nstudents = [\n    {'name': 'Alice', 'grade': 'A'},\n    {'name': 'Bob', 'grade': 'B'},\n    {'name': 'Charlie', 'grade': 'A'},\n    {'name': 'David', 'grade': 'C'}\n]\n\ngrouped = {}\nfor student in students:\n    grade = student['grade']\n    if grade not in grouped:\n        grouped[grade] = []\n    grouped[grade].append(student['name'])\n\n# Result: {'A': ['Alice', 'Charlie'], 'B': ['Bob'], 'C': ['David']}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#cachingmemoization","title":"Caching/Memoization","text":"<pre><code># Simple memoization decorator\ndef memoize(func):\n    cache = {}\n\n    def wrapper(*args):\n        if args not in cache:\n            cache[args] = func(*args)\n        return cache[args]\n\n    return wrapper\n\n@memoize\ndef fibonacci(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#configuration-management","title":"Configuration Management","text":"<pre><code># Default configuration with overrides\ndefault_config = {\n    'host': 'localhost',\n    'port': 8080,\n    'debug': False,\n    'timeout': 30\n}\n\nuser_config = {\n    'host': '192.168.1.100',\n    'debug': True\n}\n\n# Merge configurations\nconfig = default_config.copy()\nconfig.update(user_config)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#best-practices","title":"Best Practices","text":"<ol> <li>Use <code>.get()</code> for safe access: Avoid KeyError exceptions</li> <li>Use dictionary comprehension: More readable than loops</li> <li>Use <code>defaultdict</code> for counting/grouping: Avoid checking if key exists</li> <li>Use <code>Counter</code> for frequency counting: Built-in functionality</li> <li>Consider memory usage: Dictionaries use more memory than lists</li> <li>Use appropriate data structures: Lists for order, sets for uniqueness, dicts for key-value pairs</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Dictionary_Operations/#related-topics","title":"Related Topics","text":"<ul> <li>Dictionaries Overview - Basic dictionary concepts and characteristics</li> <li>Array Intersection - Using dictionaries for counting</li> <li>Anagram Pairs - Dictionary-based anagram detection</li> <li>Unique Strings - Dictionary-based string problems</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/","title":"Set Operations","text":"<p>Detailed set operations and methods in Python.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#basic-set-methods","title":"Basic Set Methods","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#adding-elements","title":"Adding Elements","text":"<pre><code>my_set = set()\nmy_set.add(1)           # Add single element\nmy_set.update([2, 3, 4]) # Add multiple elements from iterable\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#removing-elements","title":"Removing Elements","text":"<pre><code>my_set = {1, 2, 3, 4, 5}\nmy_set.remove(3)        # Raises KeyError if element doesn't exist\nmy_set.discard(6)       # No error if element doesn't exist\npopped = my_set.pop()   # Remove and return arbitrary element\nmy_set.clear()          # Remove all elements\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#mathematical-operations","title":"Mathematical Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#union","title":"Union","text":"<pre><code>set1 = {1, 2, 3}\nset2 = {3, 4, 5}\n\n# Using | operator\nunion = set1 | set2  # {1, 2, 3, 4, 5}\n\n# Using union() method\nunion = set1.union(set2)  # {1, 2, 3, 4, 5}\n\n# Union with multiple sets\nunion = set1.union(set2, {6, 7})  # {1, 2, 3, 4, 5, 6, 7}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#intersection","title":"Intersection","text":"<pre><code>set1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\n# Using &amp; operator\nintersection = set1 &amp; set2  # {3, 4}\n\n# Using intersection() method\nintersection = set1.intersection(set2)  # {3, 4}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#difference","title":"Difference","text":"<pre><code>set1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\n# Using - operator\ndifference = set1 - set2  # {1, 2}\n\n# Using difference() method\ndifference = set1.difference(set2)  # {1, 2}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#symmetric-difference","title":"Symmetric Difference","text":"<pre><code>set1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\n# Using ^ operator\nsymmetric_diff = set1 ^ set2  # {1, 2, 5, 6}\n\n# Using symmetric_difference() method\nsymmetric_diff = set1.symmetric_difference(set2)  # {1, 2, 5, 6}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#set-comparison-methods","title":"Set Comparison Methods","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#subset-and-superset","title":"Subset and Superset","text":"<pre><code>set1 = {1, 2, 3}\nset2 = {1, 2, 3, 4, 5}\n\n# Check if set1 is subset of set2\nis_subset = set1.issubset(set2)  # True\nis_subset = set1 &lt;= set2         # True\n\n# Check if set2 is superset of set1\nis_superset = set2.issuperset(set1)  # True\nis_superset = set2 &gt;= set1           # True\n\n# Proper subset/superset (excludes equality)\nproper_subset = set1 &lt; set2      # True\nproper_superset = set2 &gt; set1    # True\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#disjoint-sets","title":"Disjoint Sets","text":"<pre><code>set1 = {1, 2, 3}\nset2 = {4, 5, 6}\nset3 = {3, 4, 5}\n\n# Check if sets have no common elements\nis_disjoint = set1.isdisjoint(set2)  # True\nis_disjoint = set1.isdisjoint(set3)  # False\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#set-comprehension","title":"Set Comprehension","text":"<pre><code># Create set from list with condition\nnumbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\neven_numbers = {x for x in numbers if x % 2 == 0}  # {2, 4, 6, 8, 10}\n\n# Create set from string (unique characters)\nunique_chars = {char for char in \"hello world\"}  # {'h', 'e', 'l', 'o', ' ', 'w', 'r', 'd'}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Membership testing: O(1) average case</li> <li>Add/Remove: O(1) average case</li> <li>Union/Intersection: O(len(s1) + len(s2))</li> <li>Iteration: O(n)</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Set_Operations/#related-topics","title":"Related Topics","text":"<ul> <li>Sets Overview - Basic set concepts and characteristics</li> <li>Array Intersection - Using set intersection</li> <li>Non-Repeating Elements - Using sets for uniqueness</li> <li>Unique Elements - Using set difference operations</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/","title":"Python Sets Overview","text":"<p>A set in Python is an unordered collection of unique objects, ensuring the absence of duplicate values. Furthermore, it allows us to perform several operations on such collections, such as intersection (identifying common elements), union (combining all unique elements), and difference (detecting unique items in a set).</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Unordered: Elements are not stored in any specific order</li> <li>Unique: No duplicate elements allowed</li> <li>Mutable: Can add or remove elements</li> <li>Hashable: Elements must be hashable (immutable)</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#basic-operations","title":"Basic Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#creating-sets","title":"Creating Sets","text":"<pre><code># Empty set\nempty_set = set()\n\n# Set from list\nnumbers = set([1, 2, 3, 4, 5])\n\n# Set literal\nfruits = {'apple', 'banana', 'orange'}\n\n# Set from string (creates set of characters)\nchar_set = set('hello')  # {'h', 'e', 'l', 'o'}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#adding-elements","title":"Adding Elements","text":"<pre><code>my_set = set()\nmy_set.add(1)           # Add single element\nmy_set.update([2, 3, 4]) # Add multiple elements\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#removing-elements","title":"Removing Elements","text":"<pre><code>my_set = {1, 2, 3, 4, 5}\nmy_set.remove(3)        # Raises KeyError if element doesn't exist\nmy_set.discard(6)       # No error if element doesn't exist\npopped = my_set.pop()   # Remove and return arbitrary element\nmy_set.clear()          # Remove all elements\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#set-operations","title":"Set Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#mathematical-operations","title":"Mathematical Operations","text":"<pre><code>set1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\n# Union\nunion = set1 | set2  # or set1.union(set2)\n# Result: {1, 2, 3, 4, 5, 6}\n\n# Intersection\nintersection = set1 &amp; set2  # or set1.intersection(set2)\n# Result: {3, 4}\n\n# Difference\ndifference = set1 - set2  # or set1.difference(set2)\n# Result: {1, 2}\n\n# Symmetric Difference\nsymmetric_diff = set1 ^ set2  # or set1.symmetric_difference(set2)\n# Result: {1, 2, 5, 6}\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#membership-testing","title":"Membership Testing","text":"<pre><code>my_set = {1, 2, 3, 4, 5}\nprint(3 in my_set)      # True\nprint(6 not in my_set)  # True\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#common-use-cases","title":"Common Use Cases","text":"<ol> <li>Removing Duplicates: Convert list to set and back</li> <li>Finding Unique Elements: Set operations for uniqueness</li> <li>Membership Testing: Fast O(1) lookups</li> <li>Mathematical Operations: Union, intersection, difference</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#time-complexity","title":"Time Complexity","text":"<ul> <li>Add/Remove: O(1) average case</li> <li>Membership: O(1) average case</li> <li>Union/Intersection: O(len(s1) + len(s2))</li> <li>Iteration: O(n)</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/Python_Sets/#related-topics","title":"Related Topics","text":"<ul> <li>Set Operations - Detailed set operations and methods</li> <li>Array Intersection - Using sets for array intersection</li> <li>Non-Repeating Elements - Finding unique elements</li> <li>Unique Elements - Finding elements unique to each array</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/","title":"String Operations","text":"<p>Common string manipulation techniques and operations in Python.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#basic-string-operations","title":"Basic String Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-creation-and-access","title":"String Creation and Access","text":"<pre><code># String literals\ns1 = \"Hello, World!\"\ns2 = 'Python Programming'\ns3 = \"\"\"Multi-line\nstring\"\"\"\n\n# String indexing\nfirst_char = s1[0]      # 'H'\nlast_char = s1[-1]      # '!'\nsubstring = s1[0:5]     # 'Hello'\n\n# String length\nlength = len(s1)        # 13\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-concatenation","title":"String Concatenation","text":"<pre><code># Using + operator\nresult = \"Hello\" + \" \" + \"World\"  # \"Hello World\"\n\n# Using join() method\nwords = [\"Hello\", \"World\", \"Python\"]\nresult = \" \".join(words)  # \"Hello World Python\"\n\n# Using f-strings (Python 3.6+)\nname = \"Alice\"\nage = 30\nresult = f\"My name is {name} and I am {age} years old\"\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-methods","title":"String Methods","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#case-manipulation","title":"Case Manipulation","text":"<pre><code>text = \"Hello World\"\n\n# Convert case\nupper_text = text.upper()      # \"HELLO WORLD\"\nlower_text = text.lower()      # \"hello world\"\ntitle_text = text.title()      # \"Hello World\"\ncapitalize_text = text.capitalize()  # \"Hello world\"\nswapcase_text = text.swapcase()      # \"hELLO wORLD\"\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-searching-and-replacing","title":"String Searching and Replacing","text":"<pre><code>text = \"Hello World Hello\"\n\n# Find substring\nindex = text.find(\"World\")     # 6\nindex = text.find(\"Python\")    # -1 (not found)\n\n# Count occurrences\ncount = text.count(\"Hello\")    # 2\n\n# Replace substring\nnew_text = text.replace(\"Hello\", \"Hi\")  # \"Hi World Hi\"\n\n# Check if string starts/ends with\nstarts_with = text.startswith(\"Hello\")  # True\nends_with = text.endswith(\"World\")      # False\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-splitting-and-joining","title":"String Splitting and Joining","text":"<pre><code>text = \"apple,banana,cherry,date\"\n\n# Split by delimiter\nfruits = text.split(\",\")  # ['apple', 'banana', 'cherry', 'date']\n\n# Split with max splits\nparts = text.split(\",\", 2)  # ['apple', 'banana', 'cherry,date']\n\n# Join strings\njoined = \"-\".join(fruits)  # \"apple-banana-cherry-date\"\n\n# Split by whitespace\nsentence = \"Hello   World   Python\"\nwords = sentence.split()  # ['Hello', 'World', 'Python']\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-stripping-and-padding","title":"String Stripping and Padding","text":"<pre><code>text = \"   Hello World   \"\n\n# Remove whitespace\nstripped = text.strip()        # \"Hello World\"\nleft_stripped = text.lstrip()  # \"Hello World   \"\nright_stripped = text.rstrip() # \"   Hello World\"\n\n# Padding\npadded = text.center(20, \"*\")  # \"***Hello World****\"\nleft_padded = text.ljust(20, \"*\")  # \"Hello World********\"\nright_padded = text.rjust(20, \"*\") # \"********Hello World\"\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#advanced-string-operations","title":"Advanced String Operations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-formatting","title":"String Formatting","text":"<pre><code>name = \"Alice\"\nage = 30\nheight = 1.75\n\n# Old-style formatting\nresult = \"Name: %s, Age: %d, Height: %.2f\" % (name, age, height)\n\n# str.format() method\nresult = \"Name: {}, Age: {}, Height: {:.2f}\".format(name, age, height)\nresult = \"Name: {n}, Age: {a}, Height: {h:.2f}\".format(n=name, a=age, h=height)\n\n# f-strings (recommended)\nresult = f\"Name: {name}, Age: {age}, Height: {height:.2f}\"\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-validation","title":"String Validation","text":"<pre><code>text = \"Hello123\"\n\n# Check character types\nis_alpha = text.isalpha()      # False (contains digits)\nis_digit = text.isdigit()      # False (contains letters)\nis_alnum = text.isalnum()      # True (alphanumeric)\nis_lower = text.islower()      # False (contains uppercase)\nis_upper = text.isupper()      # False (contains lowercase)\nis_space = text.isspace()      # False (no spaces)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-encoding-and-decoding","title":"String Encoding and Decoding","text":"<pre><code>text = \"Hello, \u4e16\u754c\"\n\n# Encode to bytes\nutf8_bytes = text.encode('utf-8')\nascii_bytes = text.encode('ascii', errors='ignore')\n\n# Decode from bytes\ndecoded_text = utf8_bytes.decode('utf-8')\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#common-string-patterns","title":"Common String Patterns","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#palindrome-check","title":"Palindrome Check","text":"<pre><code>def is_palindrome(s):\n    # Remove non-alphanumeric characters and convert to lowercase\n    cleaned = ''.join(char.lower() for char in s if char.isalnum())\n    return cleaned == cleaned[::-1]\n\n# Example\nprint(is_palindrome(\"A man, a plan, a canal: Panama\"))  # True\nprint(is_palindrome(\"race a car\"))  # False\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#anagram-check","title":"Anagram Check","text":"<pre><code>def is_anagram(s1, s2):\n    # Remove spaces and convert to lowercase\n    s1_clean = ''.join(s1.lower().split())\n    s2_clean = ''.join(s2.lower().split())\n\n    # Sort and compare\n    return sorted(s1_clean) == sorted(s2_clean)\n\n# Example\nprint(is_anagram(\"listen\", \"silent\"))  # True\nprint(is_anagram(\"hello\", \"world\"))    # False\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-reversal","title":"String Reversal","text":"<pre><code>text = \"Hello World\"\n\n# Using slice\nreversed_text = text[::-1]  # \"dlroW olleH\"\n\n# Using reversed() function\nreversed_text = ''.join(reversed(text))  # \"dlroW olleH\"\n\n# Word by word reversal\nwords = text.split()\nreversed_words = ' '.join(word[::-1] for word in words)  # \"olleH dlroW\"\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#character-frequency","title":"Character Frequency","text":"<pre><code>from collections import Counter\n\ndef char_frequency(text):\n    return Counter(text.lower())\n\n# Example\nfreq = char_frequency(\"hello world\")\nprint(freq)  # Counter({'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1})\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#performance-considerations","title":"Performance Considerations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-concatenation_1","title":"String Concatenation","text":"<pre><code># Inefficient: creates new string each time\nresult = \"\"\nfor i in range(1000):\n    result += str(i)\n\n# Efficient: use list and join\nparts = []\nfor i in range(1000):\n    parts.append(str(i))\nresult = ''.join(parts)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#string-vs-list-operations","title":"String vs List Operations","text":"<pre><code># String operations create new objects\ntext = \"Hello\"\ntext += \" World\"  # Creates new string\n\n# List operations modify in place\nchars = list(\"Hello\")\nchars.append(\"!\")  # Modifies existing list\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#best-practices","title":"Best Practices","text":"<ol> <li>Use f-strings for formatting: More readable and efficient</li> <li>Use join() for concatenation: More efficient than + operator in loops</li> <li>Use appropriate string methods: Built-in methods are optimized</li> <li>Consider immutability: Strings are immutable, operations create new objects</li> <li>Use raw strings for regex: <code>r\"pattern\"</code> to avoid escaping backslashes</li> <li>Handle encoding properly: Be explicit about encoding when working with files</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Hash_Tables/String_Operations/#related-topics","title":"Related Topics","text":"<ul> <li>Unique Strings - Finding unique strings in a list</li> <li>Array Intersection - String-based intersection problems</li> <li>Anagram Pairs - String anagram detection</li> <li>Common Patterns - General problem-solving patterns</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/","title":"Common Recursive Patterns","text":"<p>This guide covers the most common recursive patterns you'll encounter in programming interviews and real-world applications. Understanding these patterns helps you recognize when and how to apply recursion effectively.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#pattern-1-linear-recursion","title":"Pattern 1: Linear Recursion","text":"<p>Process elements one by one, making a single recursive call.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#template","title":"Template:","text":"<pre><code>def linear_recursion(data, index=0):\n    # Base case\n    if index &gt;= len(data):\n        return base_value\n\n    # Process current element\n    current_result = process(data[index])\n\n    # Recursive call\n    rest_result = linear_recursion(data, index + 1)\n\n    # Combine results\n    return combine(current_result, rest_result)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#examples","title":"Examples:","text":"<p>Array Sum: <pre><code>def array_sum(arr, index=0):\n    if index &gt;= len(arr):\n        return 0\n    return arr[index] + array_sum(arr, index + 1)\n</code></pre></p> <p>String Length: <pre><code>def string_length(s, index=0):\n    if index &gt;= len(s):\n        return 0\n    return 1 + string_length(s, index + 1)\n</code></pre></p> <p>Find Maximum: <pre><code>def find_max(arr, index=0):\n    if index &gt;= len(arr):\n        return float('-inf')\n\n    current = arr[index]\n    rest_max = find_max(arr, index + 1)\n\n    return max(current, rest_max)\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#pattern-2-binary-recursion","title":"Pattern 2: Binary Recursion","text":"<p>Make two recursive calls, typically dividing the problem in half.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#template_1","title":"Template:","text":"<pre><code>def binary_recursion(data, start, end):\n    # Base case\n    if start &gt; end:\n        return base_value\n\n    # Divide\n    mid = (start + end) // 2\n\n    # Conquer\n    left_result = binary_recursion(data, start, mid)\n    right_result = binary_recursion(data, mid + 1, end)\n\n    # Combine\n    return combine(left_result, right_result)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#examples_1","title":"Examples:","text":"<p>Binary Search: <pre><code>def binary_search(arr, target, left=0, right=None):\n    if right is None:\n        right = len(arr) - 1\n\n    if left &gt; right:\n        return -1\n\n    mid = (left + right) // 2\n\n    if arr[mid] == target:\n        return mid\n    elif arr[mid] &gt; target:\n        return binary_search(arr, target, left, mid - 1)\n    else:\n        return binary_search(arr, target, mid + 1, right)\n</code></pre></p> <p>Merge Sort: <pre><code>def merge_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n\n    return merge(left, right)\n</code></pre></p> <p>Maximum Subarray (Divide &amp; Conquer): <pre><code>def max_subarray(arr, left=0, right=None):\n    if right is None:\n        right = len(arr) - 1\n\n    if left == right:\n        return arr[left]\n\n    mid = (left + right) // 2\n\n    left_max = max_subarray(arr, left, mid)\n    right_max = max_subarray(arr, mid + 1, right)\n    cross_max = max_crossing_sum(arr, left, mid, right)\n\n    return max(left_max, right_max, cross_max)\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#pattern-3-multiple-recursion","title":"Pattern 3: Multiple Recursion","text":"<p>Make multiple recursive calls (more than two), often for tree-like structures.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#template_2","title":"Template:","text":"<pre><code>def multiple_recursion(node):\n    # Base case\n    if node is None:\n        return base_value\n\n    # Process current node\n    current_result = process(node)\n\n    # Recursive calls for each child\n    child_results = []\n    for child in node.children:\n        child_results.append(multiple_recursion(child))\n\n    # Combine all results\n    return combine(current_result, child_results)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#examples_2","title":"Examples:","text":"<p>Tree Traversal: <pre><code>def preorder_traversal(root):\n    if root is None:\n        return []\n\n    result = [root.val]\n    result.extend(preorder_traversal(root.left))\n    result.extend(preorder_traversal(root.right))\n\n    return result\n</code></pre></p> <p>Directory Size Calculation: <pre><code>def calculate_directory_size(directory):\n    if directory.is_file():\n        return directory.size\n\n    total_size = 0\n    for item in directory.contents:\n        total_size += calculate_directory_size(item)\n\n    return total_size\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#pattern-4-tail-recursion","title":"Pattern 4: Tail Recursion","text":"<p>The recursive call is the last operation in the function.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#template_3","title":"Template:","text":"<pre><code>def tail_recursion(data, accumulator=initial_value):\n    # Base case\n    if termination_condition:\n        return accumulator\n\n    # Update accumulator and make recursive call\n    new_accumulator = update(accumulator, current_data)\n    return tail_recursion(remaining_data, new_accumulator)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#examples_3","title":"Examples:","text":"<p>Factorial (Tail Recursive): <pre><code>def factorial_tail(n, accumulator=1):\n    if n &lt;= 1:\n        return accumulator\n    return factorial_tail(n - 1, n * accumulator)\n</code></pre></p> <p>Sum Array (Tail Recursive): <pre><code>def sum_tail(arr, index=0, accumulator=0):\n    if index &gt;= len(arr):\n        return accumulator\n    return sum_tail(arr, index + 1, accumulator + arr[index])\n</code></pre></p> <p>List Reversal (Tail Recursive): <pre><code>def reverse_tail(arr, index=0, result=None):\n    if result is None:\n        result = []\n\n    if index &gt;= len(arr):\n        return result\n\n    return reverse_tail(arr, index + 1, [arr[index]] + result)\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#pattern-5-backtracking","title":"Pattern 5: Backtracking","text":"<p>Explore all possible solutions by trying each option and backtracking when needed.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#template_4","title":"Template:","text":"<pre><code>def backtrack(current_solution, remaining_choices):\n    # Base case: found complete solution\n    if is_complete(current_solution):\n        return [current_solution[:]]  # Return copy\n\n    solutions = []\n\n    # Try each possible choice\n    for choice in remaining_choices:\n        if is_valid(current_solution, choice):\n            # Make choice\n            current_solution.append(choice)\n\n            # Recursively explore\n            new_remaining = get_remaining_choices(remaining_choices, choice)\n            solutions.extend(backtrack(current_solution, new_remaining))\n\n            # Backtrack (undo choice)\n            current_solution.pop()\n\n    return solutions\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#examples_4","title":"Examples:","text":"<p>Generate All Permutations: <pre><code>def permutations(arr):\n    if len(arr) &lt;= 1:\n        return [arr]\n\n    result = []\n    for i in range(len(arr)):\n        current = arr[i]\n        remaining = arr[:i] + arr[i+1:]\n\n        for perm in permutations(remaining):\n            result.append([current] + perm)\n\n    return result\n</code></pre></p> <p>N-Queens Problem: <pre><code>def solve_n_queens(n):\n    def is_safe(positions, row, col):\n        for r, c in enumerate(positions):\n            if c == col or abs(r - row) == abs(c - col):\n                return False\n        return True\n\n    def backtrack(row, positions):\n        if row == n:\n            return [positions[:]]\n\n        solutions = []\n        for col in range(n):\n            if is_safe(positions, row, col):\n                positions.append(col)\n                solutions.extend(backtrack(row + 1, positions))\n                positions.pop()\n\n        return solutions\n\n    return backtrack(0, [])\n</code></pre></p> <p>Subset Generation: <pre><code>def generate_subsets(arr):\n    def backtrack(index, current_subset):\n        if index &gt;= len(arr):\n            return [current_subset[:]]\n\n        # Include current element\n        current_subset.append(arr[index])\n        with_current = backtrack(index + 1, current_subset)\n        current_subset.pop()\n\n        # Exclude current element\n        without_current = backtrack(index + 1, current_subset)\n\n        return with_current + without_current\n\n    return backtrack(0, [])\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#pattern-6-memoization-dynamic-programming","title":"Pattern 6: Memoization (Dynamic Programming)","text":"<p>Store results of subproblems to avoid redundant calculations.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#template_5","title":"Template:","text":"<pre><code>def memoized_recursion(problem, memo={}):\n    # Check if already computed\n    if problem in memo:\n        return memo[problem]\n\n    # Base case\n    if base_condition:\n        return base_value\n\n    # Recursive case\n    result = compute_result(problem)\n\n    # Store result\n    memo[problem] = result\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#examples_5","title":"Examples:","text":"<p>Fibonacci with Memoization: <pre><code>def fibonacci_memo(n, memo={}):\n    if n in memo:\n        return memo[n]\n\n    if n &lt;= 1:\n        return n\n\n    memo[n] = fibonacci_memo(n - 1, memo) + fibonacci_memo(n - 2, memo)\n    return memo[n]\n\n# Using decorator\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fibonacci_cached(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci_cached(n - 1) + fibonacci_cached(n - 2)\n</code></pre></p> <p>Longest Common Subsequence: <pre><code>def lcs(s1, s2, i=0, j=0, memo={}):\n    if (i, j) in memo:\n        return memo[(i, j)]\n\n    if i &gt;= len(s1) or j &gt;= len(s2):\n        return 0\n\n    if s1[i] == s2[j]:\n        result = 1 + lcs(s1, s2, i + 1, j + 1, memo)\n    else:\n        result = max(lcs(s1, s2, i + 1, j, memo), \n                    lcs(s1, s2, i, j + 1, memo))\n\n    memo[(i, j)] = result\n    return result\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#pattern-7-tree-recursion","title":"Pattern 7: Tree Recursion","text":"<p>Specifically for tree data structures.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#template_6","title":"Template:","text":"<pre><code>def tree_recursion(root):\n    # Base case: empty tree\n    if root is None:\n        return base_value\n\n    # Process current node\n    current_result = process(root)\n\n    # Recursive calls for children\n    left_result = tree_recursion(root.left)\n    right_result = tree_recursion(root.right)\n\n    # Combine results\n    return combine(current_result, left_result, right_result)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#examples_6","title":"Examples:","text":"<p>Tree Height: <pre><code>def tree_height(root):\n    if root is None:\n        return 0\n\n    left_height = tree_height(root.left)\n    right_height = tree_height(root.right)\n\n    return 1 + max(left_height, right_height)\n</code></pre></p> <p>Tree Sum: <pre><code>def tree_sum(root):\n    if root is None:\n        return 0\n\n    return root.val + tree_sum(root.left) + tree_sum(root.right)\n</code></pre></p> <p>Validate Binary Search Tree: <pre><code>def is_valid_bst(root, min_val=float('-inf'), max_val=float('inf')):\n    if root is None:\n        return True\n\n    if root.val &lt;= min_val or root.val &gt;= max_val:\n        return False\n\n    return (is_valid_bst(root.left, min_val, root.val) and \n            is_valid_bst(root.right, root.val, max_val))\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#pattern-8-string-recursion","title":"Pattern 8: String Recursion","text":"<p>Common patterns for string processing.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#examples_7","title":"Examples:","text":"<p>Palindrome Check: <pre><code>def is_palindrome(s, left=0, right=None):\n    if right is None:\n        right = len(s) - 1\n\n    if left &gt;= right:\n        return True\n\n    if s[left] != s[right]:\n        return False\n\n    return is_palindrome(s, left + 1, right - 1)\n</code></pre></p> <p>String Permutations: <pre><code>def string_permutations(s):\n    if len(s) &lt;= 1:\n        return [s]\n\n    result = []\n    for i, char in enumerate(s):\n        remaining = s[:i] + s[i+1:]\n        for perm in string_permutations(remaining):\n            result.append(char + perm)\n\n    return result\n</code></pre></p> <p>Edit Distance: <pre><code>def edit_distance(s1, s2, i=0, j=0, memo={}):\n    if (i, j) in memo:\n        return memo[(i, j)]\n\n    if i &gt;= len(s1):\n        return len(s2) - j\n    if j &gt;= len(s2):\n        return len(s1) - i\n\n    if s1[i] == s2[j]:\n        result = edit_distance(s1, s2, i + 1, j + 1, memo)\n    else:\n        insert = 1 + edit_distance(s1, s2, i, j + 1, memo)\n        delete = 1 + edit_distance(s1, s2, i + 1, j, memo)\n        replace = 1 + edit_distance(s1, s2, i + 1, j + 1, memo)\n        result = min(insert, delete, replace)\n\n    memo[(i, j)] = result\n    return result\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#pattern-recognition-guide","title":"Pattern Recognition Guide","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#how-to-identify-patterns","title":"How to Identify Patterns:","text":"<ol> <li>Linear Recursion: Processing elements sequentially, one recursive call</li> <li>Binary Recursion: Dividing problem in half, two recursive calls</li> <li>Multiple Recursion: Tree-like structure, multiple recursive calls</li> <li>Tail Recursion: Accumulating result, recursive call is last operation</li> <li>Backtracking: Exploring all possibilities, need to undo choices</li> <li>Memoization: Overlapping subproblems, repeated calculations</li> <li>Tree Recursion: Working with tree data structures</li> <li>String Recursion: Character-by-character or substring processing</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#decision-framework","title":"Decision Framework:","text":"<pre><code># Ask these questions:\n# 1. Can the problem be broken into smaller similar problems?\n# 2. Is there a natural base case?\n# 3. Are there overlapping subproblems? (use memoization)\n# 4. Do I need to explore all possibilities? (use backtracking)\n# 5. Am I working with tree/graph structures? (use tree recursion)\n# 6. Can I accumulate the result? (use tail recursion)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#common-mistakes-to-avoid","title":"Common Mistakes to Avoid","text":"<ol> <li> <p>Missing Base Case: <pre><code># Wrong\ndef factorial(n):\n    return n * factorial(n - 1)  # No base case\n\n# Correct\ndef factorial(n):\n    if n &lt;= 1:\n        return 1\n    return n * factorial(n - 1)\n</code></pre></p> </li> <li> <p>Incorrect Progress: <pre><code># Wrong - infinite recursion\ndef countdown(n):\n    print(n)\n    countdown(n)  # n doesn't change\n\n# Correct\ndef countdown(n):\n    if n &lt;= 0:\n        return\n    print(n)\n    countdown(n - 1)\n</code></pre></p> </li> <li> <p>Inefficient Recursion: <pre><code># Inefficient - exponential time\ndef fibonacci(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci(n - 1) + fibonacci(n - 2)\n\n# Better - with memoization\n@lru_cache(maxsize=None)\ndef fibonacci(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci(n - 1) + fibonacci(n - 2)\n</code></pre></p> </li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#practice-problems-by-pattern","title":"Practice Problems by Pattern","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#linear-recursion","title":"Linear Recursion:","text":"<ul> <li>Array sum, product, maximum</li> <li>String reversal, character counting</li> <li>Linked list operations</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#binary-recursion","title":"Binary Recursion:","text":"<ul> <li>Binary search</li> <li>Merge sort, quick sort</li> <li>Tree height, tree sum</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#backtracking","title":"Backtracking:","text":"<ul> <li>N-Queens, Sudoku solver</li> <li>Generate permutations, combinations</li> <li>Path finding in mazes</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#memoization","title":"Memoization:","text":"<ul> <li>Fibonacci, climbing stairs</li> <li>Longest common subsequence</li> <li>Coin change problem</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#tree-recursion","title":"Tree Recursion:","text":"<ul> <li>Tree traversals</li> <li>Binary search tree validation</li> <li>Path sum problems</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Common_Recursive_Patterns/#related-topics","title":"Related Topics","text":"<ul> <li>Recursion Fundamentals - Basic recursion concepts</li> <li>Recursive Algorithms - Common recursive algorithms</li> <li>Recursion vs Iteration - When to choose each approach</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/","title":"Recursion Fundamentals","text":"<p>Recursion is a programming technique where a function calls itself to solve a problem by breaking it down into smaller, similar subproblems.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#core-concepts","title":"Core Concepts","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#what-is-recursion","title":"What is Recursion?","text":"<p>Recursion occurs when a function calls itself with modified parameters until it reaches a base case. It's a fundamental problem-solving approach that mirrors mathematical induction.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#essential-components","title":"Essential Components","text":"<p>Every recursive function must have:</p> <ol> <li>Base Case: A condition that stops the recursion</li> <li>Recursive Case: The function calling itself with modified parameters</li> <li>Progress Toward Base Case: Each recursive call must move closer to the base case</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#basic-structure","title":"Basic Structure","text":"<pre><code>def recursive_function(parameters):\n    # Base case\n    if base_condition:\n        return base_value\n\n    # Recursive case\n    return recursive_function(modified_parameters)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#simple-examples","title":"Simple Examples","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#example-1-factorial","title":"Example 1: Factorial","text":"<pre><code>def factorial(n):\n    # Base case\n    if n &lt;= 1:\n        return 1\n\n    # Recursive case\n    return n * factorial(n - 1)\n\n# Usage\nprint(factorial(5))  # Output: 120\n</code></pre> <p>How it works: - factorial(5) = 5 * factorial(4) - factorial(4) = 4 * factorial(3) - factorial(3) = 3 * factorial(2) - factorial(2) = 2 * factorial(1) - factorial(1) = 1 (base case)</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#example-2","title":"Example 2:","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#fibonacci-sequence-naive-approach","title":"Fibonacci Sequence: Naive approach","text":"<pre><code>def fibonacci(n):\n    # Base cases\n    if n &lt;= 1:\n        return n\n\n    # Recursive case\n    return fibonacci(n - 1) + fibonacci(n - 2)\n\n# Usage\nprint(fibonacci(6))  # Output: 8\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#fibonacci-sequence-efficient-implementation-using-memoization","title":"Fibonacci Sequence: Efficient Implementation using memoization","text":"<pre><code>def fibonacci(n, computed = {0: 0, 1: 1}):\n    if n not in computed:\n        computed[n] = fib(n-1, computed) + fib(n-2, computed)\n    return computed[n]\n</code></pre> <p>This computes the n-th Fibonacci number in linear time, O(n)</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#example-3-sum-of-array","title":"Example 3: Sum of Array","text":"<pre><code>def array_sum(arr, index=0):\n    # Base case\n    if index &gt;= len(arr):\n        return 0\n    # Recursive case\n    return arr[index] + array_sum(arr, index + 1)\n# Usage\nnumbers = [1, 2, 3, 4, 5]\nprint(array_sum(numbers))  # Output: 15\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#types-of-recursion","title":"Types of Recursion","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#1-linear-recursion","title":"1. Linear Recursion","text":"<p>Function makes one recursive call per execution.</p> <pre><code>def countdown(n):\n    if n &lt;= 0:\n        print(\"Done!\")\n        return\n    print(n)\n    countdown(n - 1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#2-binary-recursion","title":"2. Binary Recursion","text":"<p>Function makes two recursive calls per execution.</p> <pre><code>def fibonacci(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci(n - 1) + fibonacci(n - 2)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#3-tail-recursion","title":"3. Tail Recursion","text":"<p>Recursive call is the last operation in the function.</p> <pre><code>def factorial_tail(n, accumulator=1):\n    if n &lt;= 1:\n        return accumulator\n    return factorial_tail(n - 1, n * accumulator)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#4-multiple-recursion","title":"4. Multiple Recursion","text":"<p>Function makes more than two recursive calls.</p> <pre><code>def tree_traversal(node):\n    if node is None:\n        return\n\n    # Process current node\n    process(node)\n\n    # Recursive calls for each child\n    for child in node.children:\n        tree_traversal(child)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#recursion-vs-mathematical-induction","title":"Recursion vs Mathematical Induction","text":"<p>Recursion closely follows the principle of mathematical induction:</p> <ol> <li>Base Case = Prove for the smallest case</li> <li>Inductive Step = If true for k, prove for k+1</li> <li>Recursive Step = Assume solution works for smaller problems</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#memory-and-stack","title":"Memory and Stack","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#call-stack","title":"Call Stack","text":"<p>Each recursive call adds a new frame to the call stack:</p> <pre><code>def print_stack_depth(n, depth=0):\n    print(f\"Depth {depth}: n = {n}\")\n    if n &lt;= 0:\n        return\n    print_stack_depth(n - 1, depth + 1)\n\nprint_stack_depth(3)\n</code></pre> <p>Output: <pre><code>Depth 0: n = 3\nDepth 1: n = 2\nDepth 2: n = 1\nDepth 3: n = 0\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#stack-overflow","title":"Stack Overflow","text":"<p>Too many recursive calls can cause stack overflow:</p> <pre><code># This will cause stack overflow for large n\ndef bad_recursion(n):\n    if n == 0:\n        return 0\n    return 1 + bad_recursion(n - 1)\n\n# Python's default recursion limit is around 1000\nimport sys\nprint(sys.getrecursionlimit())  # Usually 1000\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#best-practices","title":"Best Practices","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#1-always-define-base-case","title":"1. Always Define Base Case","text":"<pre><code># Good\ndef power(base, exp):\n    if exp == 0:\n        return 1\n    return base * power(base, exp - 1)\n\n# Bad - no base case leads to infinite recursion\ndef bad_power(base, exp):\n    return base * bad_power(base, exp - 1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#2-ensure-progress-toward-base-case","title":"2. Ensure Progress Toward Base Case","text":"<pre><code># Good - exp decreases each call\ndef power(base, exp):\n    if exp == 0:\n        return 1\n    return base * power(base, exp - 1)\n\n# Bad - exp never changes\ndef bad_power(base, exp):\n    if exp == 0:\n        return 1\n    return base * bad_power(base, exp)  # exp never decreases\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#3-consider-iterative-alternatives","title":"3. Consider Iterative Alternatives","text":"<pre><code># Recursive (can cause stack overflow)\ndef fibonacci_recursive(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2)\n\n# Iterative (more efficient)\ndef fibonacci_iterative(n):\n    if n &lt;= 1:\n        return n\n    a, b = 0, 1\n    for _ in range(2, n + 1):\n        a, b = b, a + b\n    return b\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#when-to-use-recursion","title":"When to Use Recursion","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#good-use-cases","title":"Good Use Cases:","text":"<ul> <li>Tree and graph traversal</li> <li>Divide and conquer algorithms</li> <li>Problems with recursive structure (fractals, nested data)</li> <li>Backtracking problems</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#avoid-recursion-when","title":"Avoid Recursion When:","text":"<ul> <li>Simple iterative solution exists</li> <li>Deep recursion expected (stack overflow risk)</li> <li>Performance is critical (iterative often faster)</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#1-missing-base-case","title":"1. Missing Base Case","text":"<pre><code># Will run forever\ndef infinite_recursion(n):\n    return infinite_recursion(n - 1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#2-incorrect-base-case","title":"2. Incorrect Base Case","text":"<pre><code># Base case never reached for negative numbers\ndef factorial(n):\n    if n == 1:  # Should be n &lt;= 1\n        return 1\n    return n * factorial(n - 1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#3-no-progress-toward-base-case","title":"3. No Progress Toward Base Case","text":"<pre><code># n never decreases\ndef no_progress(n):\n    if n == 0:\n        return 0\n    return no_progress(n)  # Should be no_progress(n - 1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_Fundamentals/#related-topics","title":"Related Topics","text":"<ul> <li>Recursive Algorithms - Common recursive algorithms</li> <li>Recursion vs Iteration - When to choose each approach</li> <li>Common Recursive Patterns - Problem-solving patterns</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/","title":"Recursion vs Iteration","text":"<p>Understanding when to use recursion versus iteration is crucial for writing efficient and maintainable code. This guide compares both approaches and provides decision-making criteria.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#fundamental-differences","title":"Fundamental Differences","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#recursion","title":"Recursion","text":"<ul> <li>Function calls itself with modified parameters</li> <li>Uses the call stack to maintain state</li> <li>Natural for problems with recursive structure</li> <li>Can be more elegant and readable</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#iteration","title":"Iteration","text":"<ul> <li>Uses loops (for, while) to repeat operations</li> <li>Uses variables to maintain state</li> <li>Generally more memory efficient</li> <li>Often faster due to no function call overhead</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#side-by-side-comparisons","title":"Side-by-Side Comparisons","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#example-1-factorial","title":"Example 1: Factorial","text":"<p>Recursive Implementation: <pre><code>def factorial_recursive(n):\n    if n &lt;= 1:\n        return 1\n    return n * factorial_recursive(n - 1)\n\n# Time: O(n), Space: O(n) - due to call stack\n</code></pre></p> <p>Iterative Implementation: <pre><code>def factorial_iterative(n):\n    result = 1\n    for i in range(2, n + 1):\n        result *= i\n    return result\n\n# Time: O(n), Space: O(1) - constant space\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#example-2-fibonacci-sequence","title":"Example 2: Fibonacci Sequence","text":"<p>Naive Recursive (Inefficient): <pre><code>def fibonacci_recursive(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2)\n\n# Time: O(2^n), Space: O(n) - exponential time!\n</code></pre></p> <p>Iterative Implementation: <pre><code>def fibonacci_iterative(n):\n    if n &lt;= 1:\n        return n\n\n    a, b = 0, 1\n    for _ in range(2, n + 1):\n        a, b = b, a + b\n    return b\n\n# Time: O(n), Space: O(1) - much more efficient\n</code></pre></p> <p>Optimized Recursive (with memoization): <pre><code>def fibonacci_memo(n, memo={}):\n    if n in memo:\n        return memo[n]\n    if n &lt;= 1:\n        return n\n\n    memo[n] = fibonacci_memo(n - 1, memo) + fibonacci_memo(n - 2, memo)\n    return memo[n]\n\n# Time: O(n), Space: O(n) - efficient but uses more memory\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#example-3-array-sum","title":"Example 3: Array Sum","text":"<p>Recursive Implementation: <pre><code>def sum_recursive(arr, index=0):\n    if index &gt;= len(arr):\n        return 0\n    return arr[index] + sum_recursive(arr, index + 1)\n\n# Time: O(n), Space: O(n)\n</code></pre></p> <p>Iterative Implementation: <pre><code>def sum_iterative(arr):\n    total = 0\n    for num in arr:\n        total += num\n    return total\n\n# Time: O(n), Space: O(1)\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#example-4-binary-tree-traversal","title":"Example 4: Binary Tree Traversal","text":"<p>Recursive Implementation (Natural): <pre><code>def inorder_recursive(root):\n    if root is None:\n        return []\n\n    result = []\n    result.extend(inorder_recursive(root.left))\n    result.append(root.val)\n    result.extend(inorder_recursive(root.right))\n    return result\n\n# Time: O(n), Space: O(h) where h is tree height\n</code></pre></p> <p>Iterative Implementation (Using Stack): <pre><code>def inorder_iterative(root):\n    result = []\n    stack = []\n    current = root\n\n    while stack or current:\n        # Go to leftmost node\n        while current:\n            stack.append(current)\n            current = current.left\n\n        # Process current node\n        current = stack.pop()\n        result.append(current.val)\n\n        # Move to right subtree\n        current = current.right\n\n    return result\n\n# Time: O(n), Space: O(h) - similar space complexity\n</code></pre></p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#performance-comparison","title":"Performance Comparison","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#time-complexity","title":"Time Complexity","text":"Problem Recursive Iterative Factorial O(n) O(n) Fibonacci (naive) O(2\u207f) O(n) Fibonacci (memo) O(n) O(n) Array Sum O(n) O(n) Binary Search O(log n) O(log n) Tree Traversal O(n) O(n)"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#space-complexity","title":"Space Complexity","text":"Problem Recursive Iterative Factorial O(n) O(1) Fibonacci (naive) O(n) O(1) Fibonacci (memo) O(n) O(1) Array Sum O(n) O(1) Binary Search O(log n) O(1) Tree Traversal O(h) O(h)"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#when-to-use-recursion","title":"When to Use Recursion","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#ideal-use-cases","title":"Ideal Use Cases:","text":"<ol> <li> <p>Tree and Graph Problems <pre><code>def tree_height(root):\n    if root is None:\n        return 0\n    return 1 + max(tree_height(root.left), tree_height(root.right))\n</code></pre></p> </li> <li> <p>Divide and Conquer Algorithms <pre><code>def merge_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n\n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n    return merge(left, right)\n</code></pre></p> </li> <li> <p>Backtracking Problems <pre><code>def solve_n_queens(n, row=0, positions=[]):\n    if row == n:\n        return [positions[:]]\n\n    solutions = []\n    for col in range(n):\n        if is_safe(positions, row, col):\n            positions.append(col)\n            solutions.extend(solve_n_queens(n, row + 1, positions))\n            positions.pop()\n\n    return solutions\n</code></pre></p> </li> <li> <p>Mathematical Definitions <pre><code>def gcd(a, b):\n    if b == 0:\n        return a\n    return gcd(b, a % b)\n</code></pre></p> </li> <li> <p>Nested Data Structures <pre><code>def flatten_nested_list(nested_list):\n    result = []\n    for item in nested_list:\n        if isinstance(item, list):\n            result.extend(flatten_nested_list(item))\n        else:\n            result.append(item)\n    return result\n</code></pre></p> </li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#when-to-use-iteration","title":"When to Use Iteration","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#ideal-use-cases_1","title":"Ideal Use Cases:","text":"<ol> <li> <p>Simple Counting/Accumulation <pre><code>def count_even_numbers(arr):\n    count = 0\n    for num in arr:\n        if num % 2 == 0:\n            count += 1\n    return count\n</code></pre></p> </li> <li> <p>Linear Data Processing <pre><code>def find_max(arr):\n    if not arr:\n        return None\n\n    max_val = arr[0]\n    for num in arr[1:]:\n        if num &gt; max_val:\n            max_val = num\n    return max_val\n</code></pre></p> </li> <li> <p>Performance-Critical Code <pre><code>def fibonacci_fast(n):\n    if n &lt;= 1:\n        return n\n\n    a, b = 0, 1\n    for _ in range(2, n + 1):\n        a, b = b, a + b\n    return b\n</code></pre></p> </li> <li> <p>Memory-Constrained Environments <pre><code>def sum_large_array(arr):\n    total = 0\n    for num in arr:\n        total += num\n    return total\n</code></pre></p> </li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#converting-between-approaches","title":"Converting Between Approaches","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#recursion-to-iteration","title":"Recursion to Iteration","text":"<p>Many recursive algorithms can be converted to iterative using a stack:</p> <pre><code># Recursive factorial\ndef factorial_recursive(n):\n    if n &lt;= 1:\n        return 1\n    return n * factorial_recursive(n - 1)\n\n# Convert to iterative using explicit stack\ndef factorial_with_stack(n):\n    if n &lt;= 1:\n        return 1\n\n    stack = []\n    while n &gt; 1:\n        stack.append(n)\n        n -= 1\n\n    result = 1\n    while stack:\n        result *= stack.pop()\n\n    return result\n\n# Or simple iterative version\ndef factorial_iterative(n):\n    result = 1\n    for i in range(2, n + 1):\n        result *= i\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#iteration-to-recursion","title":"Iteration to Recursion","text":"<p>Sometimes iterative solutions can be made recursive (though not always beneficial):</p> <pre><code># Iterative array search\ndef find_iterative(arr, target):\n    for i, val in enumerate(arr):\n        if val == target:\n            return i\n    return -1\n\n# Convert to recursive\ndef find_recursive(arr, target, index=0):\n    if index &gt;= len(arr):\n        return -1\n    if arr[index] == target:\n        return index\n    return find_recursive(arr, target, index + 1)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#decision-framework","title":"Decision Framework","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#choose-recursion-when","title":"Choose Recursion When:","text":"<ul> <li>Problem has natural recursive structure (trees, graphs)</li> <li>Divide and conquer approach fits well</li> <li>Backtracking is needed</li> <li>Mathematical definition is recursive</li> <li>Code clarity is more important than performance</li> <li>Working with nested/hierarchical data</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#choose-iteration-when","title":"Choose Iteration When:","text":"<ul> <li>Simple linear processing is needed</li> <li>Performance is critical</li> <li>Memory usage must be minimized</li> <li>Working with large datasets</li> <li>Stack overflow is a concern</li> <li>The iterative solution is simpler</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#hybrid-approach","title":"Hybrid Approach:","text":"<p>Sometimes combining both approaches works best:</p> <pre><code>def tree_paths_iterative(root):\n    \"\"\"Find all root-to-leaf paths using iteration with stack\"\"\"\n    if not root:\n        return []\n\n    paths = []\n    stack = [(root, [root.val])]\n\n    while stack:\n        node, path = stack.pop()\n\n        # If leaf node, add path to results\n        if not node.left and not node.right:\n            paths.append(path)\n\n        # Add children to stack\n        if node.right:\n            stack.append((node.right, path + [node.right.val]))\n        if node.left:\n            stack.append((node.left, path + [node.left.val]))\n\n    return paths\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#best-practices","title":"Best Practices","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#for-recursion","title":"For Recursion:","text":"<ol> <li>Always define clear base cases</li> <li>Ensure progress toward base case</li> <li>Consider memoization for overlapping subproblems</li> <li>Be aware of stack depth limitations</li> <li>Test with edge cases (empty inputs, single elements)</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#for-iteration","title":"For Iteration:","text":"<ol> <li>Initialize variables properly</li> <li>Ensure loop termination conditions</li> <li>Handle edge cases explicitly</li> <li>Use descriptive variable names</li> <li>Consider loop invariants</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#general-guidelines","title":"General Guidelines:","text":"<ol> <li>Profile your code when performance matters</li> <li>Consider readability and maintainability</li> <li>Document complex algorithms</li> <li>Use the approach that best fits the problem domain</li> <li>Don't convert just for the sake of converting</li> </ol>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#recursion-pitfalls","title":"Recursion Pitfalls:","text":"<pre><code># Missing base case\ndef infinite_recursion(n):\n    return infinite_recursion(n - 1)  # Will crash\n\n# Incorrect base case\ndef factorial_wrong(n):\n    if n == 1:  # Fails for n &lt;= 0\n        return 1\n    return n * factorial_wrong(n - 1)\n\n# No progress toward base case\ndef no_progress(n):\n    if n == 0:\n        return 0\n    return no_progress(n)  # n never changes\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#iteration-pitfalls","title":"Iteration Pitfalls:","text":"<pre><code># Off-by-one errors\ndef sum_array_wrong(arr):\n    total = 0\n    for i in range(len(arr) - 1):  # Misses last element\n        total += arr[i]\n    return total\n\n# Infinite loops\ndef infinite_loop():\n    i = 0\n    while i &lt; 10:\n        print(i)\n        # Forgot to increment i\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursion_vs_Iteration/#related-topics","title":"Related Topics","text":"<ul> <li>Recursion Fundamentals - Basic recursion concepts</li> <li>Recursive Algorithms - Common recursive algorithms</li> <li>Common Recursive Patterns - Problem-solving patterns</li> </ul>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/","title":"Recursive Algorithms","text":"<p>This section covers common algorithms that are naturally implemented using recursion, including searching, sorting, and mathematical computations.</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#searching-algorithms","title":"Searching Algorithms","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#binary-search","title":"Binary Search","text":"<p>Efficiently search a sorted array by repeatedly dividing the search space in half.</p> <pre><code>def binary_search(arr, target, left=0, right=None):\n    if right is None:\n        right = len(arr) - 1\n\n    # Base case: element not found\n    if left &gt; right:\n        return -1\n\n    mid = (left + right) // 2\n\n    # Base case: element found\n    if arr[mid] == target:\n        return mid\n\n    # Recursive cases\n    if arr[mid] &gt; target:\n        return binary_search(arr, target, left, mid - 1)\n    else:\n        return binary_search(arr, target, mid + 1, right)\n\n# Usage\nsorted_array = [1, 3, 5, 7, 9, 11, 13, 15]\nprint(binary_search(sorted_array, 7))  # Output: 3\nprint(binary_search(sorted_array, 4))  # Output: -1\n</code></pre> <p>Time Complexity: O(log n) Space Complexity: O(log n) due to recursion stack</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#linear-search-in-linked-list","title":"Linear Search in Linked List","text":"<pre><code>class ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\ndef search_linked_list(head, target):\n    # Base case: reached end of list\n    if head is None:\n        return False\n\n    # Base case: found target\n    if head.val == target:\n        return True\n\n    # Recursive case\n    return search_linked_list(head.next, target)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#sorting-algorithms","title":"Sorting Algorithms","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#merge-sort","title":"Merge Sort","text":"<p>Divide and conquer sorting algorithm that recursively divides the array and merges sorted subarrays.</p> <pre><code>def merge_sort(arr):\n    # Base case: array with 0 or 1 element is already sorted\n    if len(arr) &lt;= 1:\n        return arr\n\n    # Divide\n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n\n    # Conquer (merge)\n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i = j = 0\n\n    # Merge the two sorted arrays\n    while i &lt; len(left) and j &lt; len(right):\n        if left[i] &lt;= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n\n    # Add remaining elements\n    result.extend(left[i:])\n    result.extend(right[j:])\n\n    return result\n\n# Usage\nnumbers = [64, 34, 25, 12, 22, 11, 90]\nsorted_numbers = merge_sort(numbers)\nprint(sorted_numbers)  # Output: [11, 12, 22, 25, 34, 64, 90]\n</code></pre> <p>Time Complexity: O(n log n) Space Complexity: O(n)</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#quick-sort","title":"Quick Sort","text":"<p>Another divide and conquer sorting algorithm using a pivot element.</p> <pre><code>def quick_sort(arr, low=0, high=None):\n    if high is None:\n        high = len(arr) - 1\n\n    # Base case\n    if low &lt; high:\n        # Partition the array\n        pivot_index = partition(arr, low, high)\n\n        # Recursively sort elements before and after partition\n        quick_sort(arr, low, pivot_index - 1)\n        quick_sort(arr, pivot_index + 1, high)\n\n    return arr\n\ndef partition(arr, low, high):\n    pivot = arr[high]\n    i = low - 1\n\n    for j in range(low, high):\n        if arr[j] &lt;= pivot:\n            i += 1\n            arr[i], arr[j] = arr[j], arr[i]\n\n    arr[i + 1], arr[high] = arr[high], arr[i + 1]\n    return i + 1\n\n# Usage\nnumbers = [64, 34, 25, 12, 22, 11, 90]\nsorted_numbers = quick_sort(numbers.copy())\nprint(sorted_numbers)  # Output: [11, 12, 22, 25, 34, 64, 90]\n</code></pre> <p>Average Time Complexity: O(n log n) Worst Case Time Complexity: O(n\u00b2) Space Complexity: O(log n)</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#mathematical-algorithms","title":"Mathematical Algorithms","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#greatest-common-divisor-gcd","title":"Greatest Common Divisor (GCD)","text":"<p>Using Euclidean algorithm:</p> <pre><code>def gcd(a, b):\n    # Base case\n    if b == 0:\n        return a\n\n    # Recursive case\n    return gcd(b, a % b)\n\n# Usage\nprint(gcd(48, 18))  # Output: 6\nprint(gcd(17, 13))  # Output: 1\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#power-function","title":"Power Function","text":"<pre><code>def power(base, exp):\n    # Base cases\n    if exp == 0:\n        return 1\n    if exp == 1:\n        return base\n\n    # Recursive case for even exponent (optimization)\n    if exp % 2 == 0:\n        half_power = power(base, exp // 2)\n        return half_power * half_power\n    else:\n        return base * power(base, exp - 1)\n\n# Usage\nprint(power(2, 10))  # Output: 1024\nprint(power(3, 4))   # Output: 81\n</code></pre> <p>Time Complexity: O(log n) with optimization, O(n) without</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#tower-of-hanoi","title":"Tower of Hanoi","text":"<p>Classic recursive problem:</p> <pre><code>def hanoi(n, source, destination, auxiliary):\n    if n == 1:\n        print(f\"Move disk 1 from {source} to {destination}\")\n        return\n\n    # Move n-1 disks from source to auxiliary\n    hanoi(n - 1, source, auxiliary, destination)\n\n    # Move the largest disk from source to destination\n    print(f\"Move disk {n} from {source} to {destination}\")\n\n    # Move n-1 disks from auxiliary to destination\n    hanoi(n - 1, auxiliary, destination, source)\n\n# Usage\nhanoi(3, 'A', 'C', 'B')\n</code></pre> <p>Time Complexity: O(2\u207f)</p>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#tree-algorithms","title":"Tree Algorithms","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#tree-traversals","title":"Tree Traversals","text":"<pre><code>class TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\ndef inorder_traversal(root):\n    if root is None:\n        return []\n\n    result = []\n    result.extend(inorder_traversal(root.left))\n    result.append(root.val)\n    result.extend(inorder_traversal(root.right))\n\n    return result\n\ndef preorder_traversal(root):\n    if root is None:\n        return []\n\n    result = [root.val]\n    result.extend(preorder_traversal(root.left))\n    result.extend(preorder_traversal(root.right))\n\n    return result\n\ndef postorder_traversal(root):\n    if root is None:\n        return []\n\n    result = []\n    result.extend(postorder_traversal(root.left))\n    result.extend(postorder_traversal(root.right))\n    result.append(root.val)\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#tree-height","title":"Tree Height","text":"<pre><code>def tree_height(root):\n    # Base case: empty tree\n    if root is None:\n        return 0\n\n    # Recursive case\n    left_height = tree_height(root.left)\n    right_height = tree_height(root.right)\n\n    return 1 + max(left_height, right_height)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#tree-size-node-count","title":"Tree Size (Node Count)","text":"<pre><code>def tree_size(root):\n    # Base case: empty tree\n    if root is None:\n        return 0\n\n    # Recursive case\n    return 1 + tree_size(root.left) + tree_size(root.right)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#string-algorithms","title":"String Algorithms","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#palindrome-check","title":"Palindrome Check","text":"<pre><code>def is_palindrome(s, start=0, end=None):\n    if end is None:\n        end = len(s) - 1\n\n    # Base cases\n    if start &gt;= end:\n        return True\n\n    if s[start] != s[end]:\n        return False\n\n    # Recursive case\n    return is_palindrome(s, start + 1, end - 1)\n\n# Usage\nprint(is_palindrome(\"racecar\"))  # Output: True\nprint(is_palindrome(\"hello\"))    # Output: False\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#string-reversal","title":"String Reversal","text":"<pre><code>def reverse_string(s):\n    # Base case\n    if len(s) &lt;= 1:\n        return s\n\n    # Recursive case\n    return s[-1] + reverse_string(s[:-1])\n\n# Alternative implementation\ndef reverse_string_alt(s, index=0):\n    # Base case\n    if index &gt;= len(s):\n        return \"\"\n\n    # Recursive case\n    return reverse_string_alt(s, index + 1) + s[index]\n\n# Usage\nprint(reverse_string(\"hello\"))  # Output: \"olleh\"\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#backtracking-algorithms","title":"Backtracking Algorithms","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#generate-all-permutations","title":"Generate All Permutations","text":"<pre><code>def permutations(arr):\n    # Base case\n    if len(arr) &lt;= 1:\n        return [arr]\n\n    result = []\n    for i in range(len(arr)):\n        # Choose current element\n        current = arr[i]\n        remaining = arr[:i] + arr[i+1:]\n\n        # Generate permutations of remaining elements\n        for perm in permutations(remaining):\n            result.append([current] + perm)\n\n    return result\n\n# Usage\nprint(permutations([1, 2, 3]))\n# Output: All permutations of [1, 2, 3]\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#generate-all-subsets","title":"Generate All Subsets","text":"<pre><code>def subsets(arr, index=0):\n    # Base case\n    if index &gt;= len(arr):\n        return [](&lt;#&gt;)  # Return list containing empty subset\n\n    # Get subsets without current element\n    subsets_without_current = subsets(arr, index + 1)\n\n    # Get subsets with current element\n    subsets_with_current = []\n    for subset in subsets_without_current:\n        subsets_with_current.append([arr[index]] + subset)\n\n    return subsets_without_current + subsets_with_current\n\n# Usage\nprint(subsets([1, 2, 3]))\n# Output: All possible subsets of [1, 2, 3]\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#performance-considerations","title":"Performance Considerations","text":""},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#memoization-for-optimization","title":"Memoization for Optimization","text":"<p>Many recursive algorithms can be optimized using memoization:</p> <pre><code># Inefficient recursive Fibonacci\ndef fibonacci_slow(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci_slow(n - 1) + fibonacci_slow(n - 2)\n\n# Optimized with memoization\ndef fibonacci_memo(n, memo={}):\n    if n in memo:\n        return memo[n]\n\n    if n &lt;= 1:\n        return n\n\n    memo[n] = fibonacci_memo(n - 1, memo) + fibonacci_memo(n - 2, memo)\n    return memo[n]\n\n# Using Python's lru_cache decorator\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fibonacci_cached(n):\n    if n &lt;= 1:\n        return n\n    return fibonacci_cached(n - 1) + fibonacci_cached(n - 2)\n</code></pre>"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#algorithm-complexity-summary","title":"Algorithm Complexity Summary","text":"Algorithm Time Complexity Space Complexity Binary Search O(log n) O(log n) Merge Sort O(n log n) O(n) Quick Sort O(n log n) avg O(log n) Tree Traversal O(n) O(h) where h is height Fibonacci (naive) O(2\u207f) O(n) Fibonacci (memo) O(n) O(n) Tower of Hanoi O(2\u207f) O(n)"},{"location":"engineering_and_data_structure/Data_Structures/Recursion/Recursive_Algorithms/#related-topics","title":"Related Topics","text":"<ul> <li>Recursion Fundamentals - Basic recursion concepts</li> <li>Recursion vs Iteration - When to choose each approach</li> <li>Common Recursive Patterns - Problem-solving patterns</li> </ul>"},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/","title":"Engineering &amp; Data Structure Overview","text":"<p>Welcome to the Engineering &amp; Data Structure section! This comprehensive guide covers fundamental data structures, algorithms, and problem-solving techniques essential for software engineering and technical interviews.</p>"},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#learning-path","title":"Learning Path","text":""},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#1-data-structures","title":"1. Data Structures","text":""},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#hash-tables","title":"Hash Tables","text":"<ul> <li>Hash Tables Overview - Fundamental concepts and applications</li> <li>Hash Functions &amp; Collisions - Implementation details and collision resolution</li> <li>Python Dictionaries - Key-value pair data structures</li> <li>Python Sets - Unordered collections of unique elements</li> <li>Hash Table Problems - Common coding problems and solutions</li> </ul>"},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#recursion","title":"Recursion","text":"<ul> <li>Recursion Fundamentals - Basic concepts and structure</li> <li>Recursive Algorithms - Common recursive algorithms</li> <li>Recursion vs Iteration - When to choose each approach</li> <li>Common Recursive Patterns - Problem-solving patterns</li> </ul>"},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#2-problem-solving","title":"2. Problem Solving","text":"<ul> <li>Set &amp; Dictionary Problems - Set operations and dictionary applications</li> <li>String Problems - String manipulation and pattern matching</li> </ul>"},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#3-resources","title":"3. Resources","text":"<ul> <li>Time Complexity Guide - Understanding algorithm efficiency</li> <li>Common Patterns - Frequently used problem-solving patterns</li> <li>Interview Strategies - Tips for technical interviews</li> </ul>"},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#key-concepts-covered","title":"Key Concepts Covered","text":""},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#data-structures","title":"Data Structures","text":"<ul> <li>Hash Tables: Fundamental data structure providing O(1) average case operations</li> <li>Hash Functions: Converting keys to array indices with collision resolution strategies</li> <li>Python Dictionaries: Key-value mappings for efficient lookups and counting</li> <li>Python Sets: Unordered collections with unique elements, O(1) lookups</li> <li>Hash Table Applications: Caching, frequency counting, fast lookups, and data indexing</li> <li>Recursion: Problem-solving technique where functions call themselves with modified parameters</li> <li>Recursive Algorithms: Divide and conquer, tree traversal, backtracking, and mathematical computations</li> <li>Recursion Patterns: Linear, binary, multiple, tail recursion, and memoization techniques</li> </ul>"},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#problem-solving-patterns","title":"Problem-Solving Patterns","text":"<ul> <li>Set-based Solutions: Removing duplicates, finding intersections, uniqueness</li> <li>Dictionary-based Solutions: Counting frequencies, grouping data, anagram detection</li> <li>String Processing: Pattern matching, character analysis, case handling</li> </ul>"},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#problem-solving-strategies","title":"Problem-Solving Strategies","text":"<ul> <li>Time Complexity Analysis: Understanding algorithm efficiency</li> <li>Space Complexity: Memory usage optimization</li> <li>Edge Case Handling: Robust solution design</li> <li>Code Optimization: Performance improvements</li> </ul>"},{"location":"engineering_and_data_structure/Overview/Engineering_and_Data_Structure_Overview/#getting-started","title":"Getting Started","text":"<ol> <li>Begin with Fundamentals: Start with Hash Tables Overview and Recursion Fundamentals to understand core concepts</li> <li>Explore Data Structures: Study hash tables for efficient lookups and recursion for algorithmic thinking</li> <li>Practice with Problems: Work through the problem-solving sections to see practical applications</li> <li>Study Patterns: Learn common patterns, recursive techniques, and time complexity analysis</li> <li>Prepare for Interviews: Use the interview strategies and practice problems</li> </ol> <p>Each section includes practical examples, code implementations, and common interview questions to help you master these concepts.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/","title":"Anagram Pairs","text":"<p>Find all anagram pairs between two lists using Python sets and dictionaries.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#problem-description","title":"Problem Description","text":"<p>Given two lists of strings, find all pairs of words that are anagrams of each other (words that can be formed by rearranging the letters of another word).</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#solution-using-tuples-and-sets","title":"Solution Using Tuples and Sets","text":"<pre><code>def anagram(list_1, list_2):\n    # convert every word from both lists to a sorted tuple of its characters to have a unified form for all anagram words\n    sorted_tuples_1 = set(tuple(sorted(word)) for word in list_1)\n    sorted_tuples_2 = set(tuple(sorted(word)) for word in list_2)\n\n    # find the common tuples between the two\n    common_tuples = sorted_tuples_1 &amp; sorted_tuples_2\n\n    # iterate over the words in the original lists to filter for the words that are anagram\n    list_1_output = [word for word in list_1 if tuple(sorted(word)) in common_tuples] # contains anagrams from the first list\n    list_2_output = [word for word in list_2 if tuple(sorted(word)) in common_tuples] # contains anagrams from the second list\n\n    # check for the words pairs in the filtered list\n    output = []\n    for word1 in list_1_output:\n        for word2 in list_2_output:\n            # traversing every pair of words in filtered lists\n            if tuple(sorted(word1)) == tuple(sorted(word2)):\n                # If words in the pair are anagrams, add them to the output list\n                output.append((word1, word2))\n    return output\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#solution-using-dictionary","title":"Solution Using Dictionary","text":"<pre><code>from collections import defaultdict\n\ndef anagram_dict(list_1, list_2):\n    # Create mapping for `list_1`\n    mapping_1 = defaultdict(list)\n    # mapping_1 stores (sorted anagram) -&gt; list[anagrams] mapping for `list_1`\n    for word in list_1:\n        sorted_tuple = tuple(sorted(word)) # unique identifier of the anagram\n        mapping_1[sorted_tuple].append(word)\n        # `mapping_1[sorted_tuple]` stores all anagrams under the same identifier for `list_1`\n\n    # Create mapping for `list_2`\n    mapping_2 = defaultdict(list)\n    # mapping_2 stores (sorted anagram) -&gt; list[anagrams] mapping for `list_2`\n    for word in list_2:\n        sorted_tuple = tuple(sorted(word)) # unique identifier of the anagram\n        mapping_2[sorted_tuple].append(word)\n        # `mapping_2[sorted_tuple]` stores all anagrams under the same identifier for `list_2`\n\n    # Intersect keys from mapping_1 and mapping_2 to get common sorted tuples\n    # Every element in `common_tuples` is an anagram identifier that exists in both lists\n    common_tuples = set(mapping_1.keys()) &amp; set(mapping_2.keys())\n\n    output = []\n    for anagram_tuple in common_tuples:\n        for word1 in mapping_1[anagram_tuple]:\n            for word2 in mapping_2[anagram_tuple]:\n                # Both word1 and word2 have the same anagram identifier, so are anagrams\n                output.append((word1, word2))\n\n    return output\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#how-it-works","title":"How It Works","text":""},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#set-approach","title":"Set Approach","text":"<ol> <li>Create Sorted Tuples: Convert each word to a sorted tuple of characters</li> <li>Find Common Anagrams: Use set intersection to find common anagram identifiers</li> <li>Filter Words: Get words from both lists that match the common anagrams</li> <li>Generate Pairs: Create all possible pairs between the filtered words</li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#dictionary-approach","title":"Dictionary Approach","text":"<ol> <li>Create Mappings: Build dictionaries mapping sorted tuples to lists of anagrams</li> <li>Find Common Keys: Use set intersection to find common anagram identifiers</li> <li>Generate Pairs: Create all pairs between words with the same anagram identifier</li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#time-complexity-analysis","title":"Time Complexity Analysis","text":"<ul> <li>Set Approach: O(n\u00b2) - Due to nested loops for generating pairs</li> <li>Dictionary Approach: O(n\u00b2) - Due to nested loops for generating pairs</li> <li>Space Complexity: O(n) - We need to store the sets/dictionaries and result</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#example-usage","title":"Example Usage","text":"<pre><code># Example 1\nlist_1 = [\"cat\", \"dog\", \"tac\"]\nlist_2 = [\"act\", \"god\", \"dog\"]\nresult = anagram(list_1, list_2)\nprint(result)  # [('cat', 'act'), ('cat', 'tac'), ('dog', 'god')]\n\n# Example 2\nlist_1 = [\"hello\", \"world\"]\nlist_2 = [\"olleh\", \"dlrow\"]\nresult = anagram(list_1, list_2)\nprint(result)  # [('hello', 'olleh'), ('world', 'dlrow')]\n\n# Example 3\nlist_1 = [\"a\", \"b\", \"c\"]\nlist_2 = [\"d\", \"e\", \"f\"]\nresult = anagram(list_1, list_2)\nprint(result)  # []\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#key-insights","title":"Key Insights","text":"<ol> <li>Anagram Identifier: Sorted tuple of characters serves as a unique identifier for anagrams</li> <li>Set Operations: Using set intersection to find common anagram identifiers</li> <li>Dictionary Mapping: Efficiently grouping anagrams by their sorted representation</li> <li>Pair Generation: Creating all possible pairs between matching anagrams</li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#edge-cases","title":"Edge Cases","text":"<ul> <li>Empty Lists: Returns empty list</li> <li>No Anagrams: Returns empty list</li> <li>Single Anagrams: Returns single pair</li> <li>Multiple Anagrams: Returns all possible pairs</li> <li>Case Sensitivity: \"Cat\" and \"cat\" are considered different</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Anagram_Pairs/#related-problems","title":"Related Problems","text":"<ul> <li>Array Intersection - Finding common elements</li> <li>String Operations - String manipulation techniques</li> <li>Dictionary Operations - Dictionary usage patterns</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/","title":"Array Intersection","text":"<p>Find the intersection of two arrays using Python sets.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#problem-description","title":"Problem Description","text":"<p>Given two arrays, find all elements that appear in both arrays. The result should be sorted.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#solution-using-sets","title":"Solution Using Sets","text":"<pre><code>def array_intersection(list1, list2):\n    set1 = set(list1)\n    set2 = set(list2)\n    intersection = set1 &amp; set2\n    return sorted(list(intersection))\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#time-complexity-analysis","title":"Time Complexity Analysis","text":"<p>The set operations run at a time complexity of O(n), but the sorting step has a time complexity of O(n log n). Therefore, the overall time complexity of the solution is O(n log n), dominated by the sorting step.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#space-complexity","title":"Space Complexity","text":"<ul> <li>Space Complexity: O(n) - We need to store the sets and the result list</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#example-usage","title":"Example Usage","text":"<pre><code># Example 1\nlist1 = [1, 2, 2, 1]\nlist2 = [2, 2]\nresult = array_intersection(list1, list2)\nprint(result)  # [2]\n\n# Example 2\nlist1 = [4, 9, 5]\nlist2 = [9, 4, 9, 8, 4]\nresult = array_intersection(list1, list2)\nprint(result)  # [4, 9]\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#alternative-approaches","title":"Alternative Approaches","text":""},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#using-list-comprehension-less-efficient","title":"Using List Comprehension (Less Efficient)","text":"<pre><code>def array_intersection_list(list1, list2):\n    return sorted([x for x in list1 if x in list2])\n</code></pre> <p>Time Complexity: O(n\u00b2) - For each element in list1, we check if it's in list2 Space Complexity: O(n)</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#using-dictionary-for-counting","title":"Using Dictionary for Counting","text":"<pre><code>from collections import Counter\n\ndef array_intersection_counter(list1, list2):\n    counter1 = Counter(list1)\n    counter2 = Counter(list2)\n    intersection = counter1 &amp; counter2\n    return sorted(list(intersection.elements()))\n</code></pre> <p>Time Complexity: O(n log n) - Due to sorting Space Complexity: O(n)</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#key-insights","title":"Key Insights","text":"<ol> <li>Set Operations: Using sets provides O(1) average time complexity for membership testing</li> <li>Sorting Requirement: The final result needs to be sorted, which adds O(n log n) complexity</li> <li>Duplicate Handling: Sets automatically handle duplicates, making the solution clean and efficient</li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Array_Intersection/#related-problems","title":"Related Problems","text":"<ul> <li>Non-Repeating Elements - Finding elements that appear only once</li> <li>Unique Elements - Finding elements unique to each array</li> <li>Set Operations - Understanding set operations in detail</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Bonus_Calculator/","title":"Bonus Calculator","text":"<ul> <li>You are given a list of employee dictionaries.</li> <li>Each dictionary has at least a\u00a0<code>'role'</code>\u00a0and a\u00a0<code>'salary'</code>\u00a0key.</li> <li>For every employee whose\u00a0<code>'role'</code>\u00a0is\u00a0<code>'developer'</code>, add a new key\u00a0<code>'bonus'</code>\u00a0to their dictionary, with a value equal to 10% of their salary.</li> <li>For all other employees, set their\u00a0<code>'bonus'</code>\u00a0to\u00a0<code>0</code>.</li> <li>Return the updated list of employee dictionaries.</li> </ul> <pre><code>def bonus_calculator(employees):\n    for employee in employees:\n        bonus = 0\n        if employee['role'] == 'developer':\n            bonus = employee['salary'] * 0.1\n        employee['bonus'] = bonus\n    return employees\n</code></pre> <pre><code>def salary_increment(employees):\n\u00a0 \u00a0 employees_bonus = copy.deepcopy(employees)\n\u00a0 \u00a0 for i in range(len(employees_bonus)):\n\u00a0 \u00a0 \u00a0 \u00a0 if employees_bonus[i][\"role\"] == \"developer\":\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 employees_bonus[i][\"salary\"] = employees_bonus[i][\"salary\"] * 1.15\n\u00a0 \u00a0 return employees_bonus\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Frequent_Words_Find/","title":"Frequent Words Find","text":"<p>Given a large body of text, we need to identify the three most frequently occurring words. Imagine working with large documents, such as news articles, thesis manuscripts, or even books. Identifying the most common words could give us an overview of the main themes or topics in the text.</p> <p>A Python dictionary allows us to store data in key-value pairs. In this case, we can use each unique word in the text as a key and the frequency of the word as its corresponding value. As we traverse the document once, we can record the count of each word on the go, avoiding the need for multiple full-document checks. Hence, using a dictionary would drastically reduce our algorithm's time complexity and boost its efficiency.</p> <pre><code>def frequent_words_finder(text):\n    from collections import defaultdict\n\n    text = text.lower()\n    word_list = text.split()\n\n    word_counts = defaultdict(int)\n\n    for word in word_list:\n        word_counts[word] += 1\n    top_three = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n    return top_three\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Implement_a_Keyword_Index/","title":"Implement a Keyword Index","text":"<p>In this situation, we are given a list of strings, with each string representing a document. Our task is to generate an index of all the distinct words in the documents for quick reference. We need to create a dictionary where each unique word is a key, and the corresponding value is a list of indices pointing to the documents where the word can be found.</p> <pre><code>def keyword_index(docs):\n    index = {}\n    for doc_idx, doc in enumerate(docs):\n        for word in doc.split():\n            if word in index:\n                index[word].append(doc_idx)\n            else:\n                index[word] = [doc_idx]\n    return index\n</code></pre> <pre><code>def keyword_index(docs):\n\u00a0 \u00a0 clean_text_list = [text.split() for text in docs]\n\u00a0 \u00a0 dict_search = {}\n\u00a0 \u00a0 for index, text in enumerate(clean_text_list):\n\u00a0 \u00a0 \u00a0 \u00a0 for position, string in enumerate(text):\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if string not in dict_search:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dict_search[string] = {}\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dict_search[string][index] = 1\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 else:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dict_search[string][index] = dict_search[string].get(index, 0) + 1\n\u00a0 \u00a0 return dict_search\n\ndocs = [\"Hello world\", \"world of python\", \"python is a snake\"]\nprint(keyword_index(docs)) \u00a0# Expected output: {'Hello': {0: 1}, 'world': {0: 1, 1: 1}, 'of': {1: 1}, 'python': {1: 1, 2: 1}, 'is': {2: 1}, 'a': {2: 1}, 'snake': {2: 1}}\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Majority_Vote_Problem/","title":"Majority Vote Problem","text":"<p>Our first problem is about identifying the \"majority\" element in a list. The \"majority element\" in a list is an element that appears more than\u00a0<code>n / 2</code>\u00a0times. Given a list of integers, our aim is to identify the majority element.</p> <pre><code>def majority_vote(listA):\n    count_dict = {}\n    for element in listA:\n        count_dict[element] = count_dict.get(element, 0) + 1\n        if count_dict[element] &gt; len(listA) // 2:\n            return element\n    return -1\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/","title":"Non-Repeating Elements","text":"<p>Find elements that appear only once in an array using Python sets.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#problem-description","title":"Problem Description","text":"<p>Given an array of integers, find all elements that appear only once (non-repeating elements).</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#solution-using-sets","title":"Solution Using Sets","text":"<pre><code>def find_non_repeating_elements(nums):\n    seen, repeated = set(), set()\n    for num in nums:\n        if num in seen:\n            repeated.add(num)\n        else: \n            seen.add(num)\n    return list(seen - repeated)\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#how-it-works","title":"How It Works","text":"<ol> <li>First Pass: Iterate through the array</li> <li>If we see a number for the first time, add it to <code>seen</code></li> <li>If we see a number again, add it to <code>repeated</code></li> <li>Result: Return elements that are in <code>seen</code> but not in <code>repeated</code></li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#time-complexity-analysis","title":"Time Complexity Analysis","text":"<p>This approach results in a time complexity of O(n) and a memory complexity of O(n) due to the constant time operations provided by the Python <code>set</code>.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#space-complexity","title":"Space Complexity","text":"<ul> <li>Space Complexity: O(n) - We need to store the seen and repeated sets</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#example-usage","title":"Example Usage","text":"<pre><code># Example 1\nnums = [1, 2, 3, 1, 4, 2]\nresult = find_non_repeating_elements(nums)\nprint(result)  # [3, 4]\n\n# Example 2\nnums = [1, 1, 2, 2, 3, 3]\nresult = find_non_repeating_elements(nums)\nprint(result)  # []\n\n# Example 3\nnums = [1, 2, 3, 4, 5]\nresult = find_non_repeating_elements(nums)\nprint(result)  # [1, 2, 3, 4, 5]\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#alternative-approaches","title":"Alternative Approaches","text":""},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#using-dictionary-for-counting","title":"Using Dictionary for Counting","text":"<pre><code>from collections import Counter\n\ndef find_non_repeating_elements_counter(nums):\n    counter = Counter(nums)\n    return [num for num, count in counter.items() if count == 1]\n</code></pre> <p>Time Complexity: O(n) Space Complexity: O(n)</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#using-list-comprehension-less-efficient","title":"Using List Comprehension (Less Efficient)","text":"<pre><code>def find_non_repeating_elements_list(nums):\n    return [num for num in nums if nums.count(num) == 1]\n</code></pre> <p>Time Complexity: O(n\u00b2) - <code>count()</code> method is O(n) for each element Space Complexity: O(n)</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#key-insights","title":"Key Insights","text":"<ol> <li>Two-Set Approach: Using two sets to track seen and repeated elements</li> <li>Set Difference: Using <code>seen - repeated</code> to find elements that appear only once</li> <li>Single Pass: The solution requires only one pass through the array</li> <li>Efficient Lookups: Set operations provide O(1) average time complexity</li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#edge-cases","title":"Edge Cases","text":"<ul> <li>Empty Array: Returns empty list</li> <li>All Repeating: Returns empty list</li> <li>All Unique: Returns all elements</li> <li>Single Element: Returns the element if it appears only once</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Non_Repeating_Elements/#related-problems","title":"Related Problems","text":"<ul> <li>Array Intersection - Finding common elements between arrays</li> <li>Unique Elements - Finding elements unique to each array</li> <li>Unique Strings - Finding unique strings in a list</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Password_Strength_Counter/","title":"Password Strength Counter","text":"<p>A common measure to ensure robust security is testing the strength of passwords. A 'strong' password is usually defined as one that is long (at least 8 characters) and includes a mix of uppercase characters, lowercase characters, and digits.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Password_Strength_Counter/#skeleton-of-the-code","title":"Skeleton of the code","text":"<pre><code>if len(password) &gt;= 8: \n    continue \nelse: \n    return false \n\ndict_check = {\"upper\": false, \"lower\": false, \"digit\": false} \n\nfor character in password: # password is a list, no need for .items()\n    if character.isnumeric(): \n        dict_check[\"digit\"] = true \n    elif character.isupper(): \n        dict_check[\"upper\"] = true \n    elif character.islower(): \n        dict_check[\"lower\"] = true \n    else: \n        continue \n\nfor _, value in dict_check.items(): \n    if value == false: \n        return false \n\nreturn true\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Password_Strength_Counter/#implementation-of-the-code","title":"Implementation of the code","text":"<pre><code>def password_strength_counter(password):\n    strength = {\n        'length': False,\n        'digit': False,\n        'lowercase': False,\n        'uppercase': False,\n    }\n    if len(password) &gt;= 8:\n        strength['length'] = True\n    for char in password:\n        if char.isdigit():\n            strength['digit'] = True\n        elif char.islower():\n            strength['lowercase'] = True\n        elif char.isupper():\n            strength['uppercase'] = True\n    return strength\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/","title":"Unique Elements","text":"<p>Find elements that are unique to each of two arrays using Python sets.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#problem-description","title":"Problem Description","text":"<p>Given two arrays, find elements that are unique to each array (elements that appear in one array but not in the other).</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#solution-using-sets","title":"Solution Using Sets","text":"<pre><code>def unique_elements(list1, list2):\n    set1 = set(list1)\n    set2 = set(list2)\n    unique_to_1 = sorted(list(set1 - set2))\n    unique_to_2 = sorted(list(set2 - set1))\n    return (unique_to_1, unique_to_2)\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#how-it-works","title":"How It Works","text":"<ol> <li>Convert to Sets: Convert both lists to sets for efficient operations</li> <li>Set Difference: </li> <li><code>set1 - set2</code> gives elements unique to list1</li> <li><code>set2 - set1</code> gives elements unique to list2</li> <li>Sort Results: Convert back to sorted lists for consistent output</li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#time-complexity-analysis","title":"Time Complexity Analysis","text":"<p>This solution is considerably more efficient than the naive approach, operating at a time complexity of O(n), or O(max(len(list1), len(list2))) to be more precise.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#space-complexity","title":"Space Complexity","text":"<ul> <li>Space Complexity: O(n) - We need to store the sets and result lists</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#example-usage","title":"Example Usage","text":"<pre><code># Example 1\nlist1 = [1, 2, 3, 4]\nlist2 = [3, 4, 5, 6]\nunique_1, unique_2 = unique_elements(list1, list2)\nprint(unique_1)  # [1, 2]\nprint(unique_2)  # [5, 6]\n\n# Example 2\nlist1 = [1, 2, 3]\nlist2 = [1, 2, 3]\nunique_1, unique_2 = unique_elements(list1, list2)\nprint(unique_1)  # []\nprint(unique_2)  # []\n\n# Example 3\nlist1 = [1, 2, 3, 4, 5]\nlist2 = [6, 7, 8, 9, 10]\nunique_1, unique_2 = unique_elements(list1, list2)\nprint(unique_1)  # [1, 2, 3, 4, 5]\nprint(unique_2)  # [6, 7, 8, 9, 10]\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#alternative-approaches","title":"Alternative Approaches","text":""},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#using-list-comprehension-less-efficient","title":"Using List Comprehension (Less Efficient)","text":"<pre><code>def unique_elements_list(list1, list2):\n    unique_to_1 = sorted([x for x in list1 if x not in list2])\n    unique_to_2 = sorted([x for x in list2 if x not in list1])\n    return (unique_to_1, unique_to_2)\n</code></pre> <p>Time Complexity: O(n\u00b2) - <code>not in</code> operation is O(n) for each element Space Complexity: O(n)</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#using-dictionary-for-counting","title":"Using Dictionary for Counting","text":"<pre><code>from collections import Counter\n\ndef unique_elements_counter(list1, list2):\n    counter1 = Counter(list1)\n    counter2 = Counter(list2)\n\n    unique_to_1 = sorted([num for num in counter1 if num not in counter2])\n    unique_to_2 = sorted([num for num in counter2 if num not in counter1])\n\n    return (unique_to_1, unique_to_2)\n</code></pre> <p>Time Complexity: O(n log n) - Due to sorting Space Complexity: O(n)</p>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#key-insights","title":"Key Insights","text":"<ol> <li>Set Difference: Using set difference operations (<code>-</code>) for efficient uniqueness checking</li> <li>Symmetric Operation: The operation is symmetric - we check both directions</li> <li>Sorting: Results are sorted for consistent output</li> <li>Efficient Lookups: Set operations provide O(1) average time complexity</li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#edge-cases","title":"Edge Cases","text":"<ul> <li>Empty Arrays: Returns empty lists for both</li> <li>Identical Arrays: Returns empty lists for both</li> <li>Completely Different: Returns all elements from each array</li> <li>One Empty: Returns all elements from the non-empty array</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/Set_Dictionary_Problems/Unique_Elements/#related-problems","title":"Related Problems","text":"<ul> <li>Array Intersection - Finding common elements between arrays</li> <li>Non-Repeating Elements - Finding elements that appear only once</li> <li>Set Operations - Understanding set difference operations</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/","title":"Unique Strings","text":"<p>Find the first unique string in a list using Python sets and dictionaries.</p>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#problem-description","title":"Problem Description","text":"<p>Given a list of strings, find the first string that appears only once (is unique).</p>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#solution-using-two-sets","title":"Solution Using Two Sets","text":"<pre><code>def find_unique_string(words):\n    seen = set()\n    duplicates = set()\n    for word in words:\n        if word in seen:\n            duplicates.add(word)\n        seen.add(word)\n    for word in words:\n        if word not in duplicates:\n            return word\n    return \"\"\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#how-it-works","title":"How It Works","text":"<ol> <li>First Pass: Track seen words and duplicates</li> <li>If we see a word for the first time, add it to <code>seen</code></li> <li>If we see a word again, add it to <code>duplicates</code></li> <li>Second Pass: Find the first word not in duplicates</li> <li>Return the first word that appears only once</li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#solution-using-dictionary","title":"Solution Using Dictionary","text":"<pre><code>def find_unique_string_dict(words):\n    count_dict = {}\n    for word in words:\n        if word in count_dict:\n            count_dict[word] = count_dict[word] + 1\n        else:\n            count_dict[word] = 1\n    for word in words:\n        if count_dict[word] == 1:\n            return word\n    return \"\"\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#time-complexity-analysis","title":"Time Complexity Analysis","text":"<ul> <li>Two Sets Approach: O(n) - Two passes through the array</li> <li>Dictionary Approach: O(n) - Two passes through the array</li> <li>Space Complexity: O(n) - We need to store the sets/dictionary</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#example-usage","title":"Example Usage","text":"<pre><code># Example 1\nwords = [\"hello\", \"world\", \"hello\", \"python\"]\nresult = find_unique_string(words)\nprint(result)  # \"world\"\n\n# Example 2\nwords = [\"a\", \"b\", \"a\", \"b\", \"c\"]\nresult = find_unique_string(words)\nprint(result)  # \"c\"\n\n# Example 3\nwords = [\"a\", \"a\", \"b\", \"b\"]\nresult = find_unique_string(words)\nprint(result)  # \"\"\n\n# Example 4\nwords = [\"unique\"]\nresult = find_unique_string(words)\nprint(result)  # \"unique\"\n</code></pre>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#comparison-of-approaches","title":"Comparison of Approaches","text":""},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#two-sets-approach","title":"Two Sets Approach","text":"<ul> <li>Pros: Simple logic, easy to understand</li> <li>Cons: Requires two passes through the array</li> <li>Best for: When you need to track both seen and duplicate elements</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#dictionary-approach","title":"Dictionary Approach","text":"<ul> <li>Pros: More explicit counting, can be extended for other counting problems</li> <li>Cons: Slightly more complex logic</li> <li>Best for: When you need exact counts or might need to extend the solution</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#key-insights","title":"Key Insights","text":"<ol> <li>Two-Pass Solution: First pass to identify duplicates, second pass to find first unique</li> <li>Order Preservation: The second pass maintains the original order to find the \"first\" unique</li> <li>Efficient Lookups: Set/dictionary operations provide O(1) average time complexity</li> <li>Edge Case Handling: Returns empty string if no unique element exists</li> </ol>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#edge-cases","title":"Edge Cases","text":"<ul> <li>Empty List: Returns empty string</li> <li>All Duplicates: Returns empty string</li> <li>All Unique: Returns the first element</li> <li>Single Element: Returns the element</li> <li>Case Sensitivity: \"Hello\" and \"hello\" are considered different</li> </ul>"},{"location":"engineering_and_data_structure/Problem_Solving/String_Problems/Unique_Strings/#related-problems","title":"Related Problems","text":"<ul> <li>Non-Repeating Elements - Finding non-repeating numbers</li> <li>Array Intersection - Finding common elements</li> <li>String Operations - Other string manipulation techniques</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/","title":"Common Patterns","text":"<p>Common patterns and techniques used in data structure and algorithm problems.</p>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#dictionary-operations","title":"Dictionary Operations","text":""},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#how-to-initiate-a-set-and-add-elements","title":"How to Initiate a Set and Add Elements","text":"<pre><code>set_sample = set()\nset_sample.add(1)\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#how-to-convert-a-string-of-digits-in-dictionary-to-a-number","title":"How to Convert a String of Digits in Dictionary to a Number","text":"<pre><code>int(\"\".join([value for _, value in dictionary.items()]))\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#how-to-sort-a-dictionary-in-python","title":"How to Sort a Dictionary in Python","text":""},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#based-on-key","title":"Based on Key","text":"<pre><code>my_dict = {'apple': 3, 'orange': 1, 'banana': 2}  \nsorted_by_key = dict(sorted(my_dict.items()))  \nprint(sorted_by_key)  \n# Output: {'apple': 3, 'banana': 2, 'orange': 1}\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#based-on-value","title":"Based on Value","text":"<pre><code>my_dict = {'apple': 3, 'orange': 1, 'banana': 2}  \nsorted_by_value = dict(sorted(my_dict.items(), key=lambda item: item[1]))  \nprint(sorted_by_value)  \n# Output: {'orange': 1, 'banana': 2, 'apple': 3}\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#string-operations","title":"String Operations","text":""},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#how-to-ignore-capital-vs-lower-cases-in-python","title":"How to Ignore Capital vs Lower Cases in Python","text":"<pre><code>inventory1 = [string.upper() for string in inventory1] # .lower() for lower \ninventory2 = [string.upper() for string in inventory2] # .lower() for lower \n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#set-operations","title":"Set Operations","text":""},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#basic-set-creation-and-manipulation","title":"Basic Set Creation and Manipulation","text":"<pre><code># Create empty set\nempty_set = set()\n\n# Create set from list\nnumbers = set([1, 2, 3, 4, 5])\n\n# Add elements\nmy_set = set()\nmy_set.add(1)\nmy_set.update([2, 3, 4])\n\n# Remove elements\nmy_set.remove(3)        # Raises KeyError if not found\nmy_set.discard(6)       # No error if not found\npopped = my_set.pop()   # Remove and return arbitrary element\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#set-mathematical-operations","title":"Set Mathematical Operations","text":"<pre><code>set1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\n# Union\nunion = set1 | set2  # or set1.union(set2)\n\n# Intersection\nintersection = set1 &amp; set2  # or set1.intersection(set2)\n\n# Difference\ndifference = set1 - set2  # or set1.difference(set2)\n\n# Symmetric Difference\nsymmetric_diff = set1 ^ set2  # or set1.symmetric_difference(set2)\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#list-operations","title":"List Operations","text":""},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#list-comprehension-patterns","title":"List Comprehension Patterns","text":"<pre><code># Basic list comprehension\nsquares = [x**2 for x in range(10)]\n\n# List comprehension with condition\neven_squares = [x**2 for x in range(10) if x % 2 == 0]\n\n# Nested list comprehension\nmatrix = [[i+j for j in range(3)] for i in range(3)]\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#list-manipulation","title":"List Manipulation","text":"<pre><code># Remove duplicates while preserving order\ndef remove_duplicates_preserve_order(lst):\n    seen = set()\n    return [x for x in lst if not (x in seen or seen.add(x))]\n\n# Flatten nested list\ndef flatten(lst):\n    return [item for sublist in lst for item in sublist]\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#algorithmic-patterns","title":"Algorithmic Patterns","text":""},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#two-pointers-technique","title":"Two Pointers Technique","text":"<pre><code>def two_pointers_example(arr):\n    left, right = 0, len(arr) - 1\n    while left &lt; right:\n        # Process elements at left and right pointers\n        if some_condition:\n            left += 1\n        else:\n            right -= 1\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#sliding-window-technique","title":"Sliding Window Technique","text":"<pre><code>def sliding_window_example(arr, k):\n    window_sum = sum(arr[:k])\n    result = [window_sum]\n\n    for i in range(k, len(arr)):\n        window_sum = window_sum - arr[i-k] + arr[i]\n        result.append(window_sum)\n\n    return result\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#prefix-sum-technique","title":"Prefix Sum Technique","text":"<pre><code>def prefix_sum_example(arr):\n    prefix = [0] * (len(arr) + 1)\n    for i in range(len(arr)):\n        prefix[i + 1] = prefix[i] + arr[i]\n    return prefix\n\ndef range_sum(prefix, left, right):\n    return prefix[right + 1] - prefix[left]\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#time-complexity-cheat-sheet","title":"Time Complexity Cheat Sheet","text":""},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#common-operations","title":"Common Operations","text":"Operation List Set Dictionary Access O(1) N/A O(1) Search O(n) O(1) O(1) Insert O(1) O(1) O(1) Delete O(n) O(1) O(1)"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#sorting-algorithms","title":"Sorting Algorithms","text":"Algorithm Time Complexity Space Complexity Stable Bubble Sort O(n\u00b2) O(1) Yes Selection Sort O(n\u00b2) O(1) No Insertion Sort O(n\u00b2) O(1) Yes Merge Sort O(n log n) O(n) Yes Quick Sort O(n log n) O(log n) No Heap Sort O(n log n) O(1) No"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#space-complexity-guidelines","title":"Space Complexity Guidelines","text":"<ul> <li>O(1): Constant space - no extra space needed</li> <li>O(n): Linear space - space grows with input size</li> <li>O(n\u00b2): Quadratic space - space grows with square of input size</li> <li>O(log n): Logarithmic space - space grows with log of input size</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Common_Patterns/#related-topics","title":"Related Topics","text":"<ul> <li>Time Complexity Guide - Detailed complexity analysis</li> <li>Interview Strategies - Tips for technical interviews</li> <li>Set Operations - Detailed set operations</li> <li>Dictionary Operations - Dictionary usage patterns</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/","title":"Interview Strategies","text":"<p>Tips and strategies for technical interviews focusing on data structures and algorithms.</p>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#preparation-strategy","title":"Preparation Strategy","text":""},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#1-master-the-fundamentals","title":"1. Master the Fundamentals","text":"<ul> <li>Data Structures: Arrays, linked lists, stacks, queues, trees, graphs, heaps, hash tables</li> <li>Algorithms: Sorting, searching, recursion, dynamic programming, greedy algorithms</li> <li>Time/Space Complexity: Big O notation and analysis</li> <li>Problem-Solving Patterns: Two pointers, sliding window, binary search, etc.</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#2-practice-problem-types","title":"2. Practice Problem Types","text":"<ul> <li>Array/String Problems: Two pointers, sliding window, prefix sum</li> <li>Tree/Graph Problems: DFS, BFS, traversal algorithms</li> <li>Dynamic Programming: Memoization, tabulation, optimization</li> <li>System Design: Scalability, trade-offs, architecture decisions</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#problem-solving-framework","title":"Problem-Solving Framework","text":""},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#1-understand-the-problem","title":"1. Understand the Problem","text":"<ul> <li>Clarify requirements: Ask clarifying questions</li> <li>Identify constraints: Time, space, input size</li> <li>Consider edge cases: Empty input, single element, duplicates</li> <li>Understand the output: What should the function return?</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#2-plan-your-approach","title":"2. Plan Your Approach","text":"<ul> <li>Think out loud: Explain your thought process</li> <li>Consider multiple approaches: Brute force, optimized, trade-offs</li> <li>Estimate complexity: Time and space complexity upfront</li> <li>Choose the best approach: Based on constraints and requirements</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#3-implement-the-solution","title":"3. Implement the Solution","text":"<ul> <li>Write clean code: Use meaningful variable names</li> <li>Handle edge cases: Check for null, empty, invalid input</li> <li>Test as you go: Walk through examples step by step</li> <li>Optimize if needed: Look for improvements</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#4-test-and-verify","title":"4. Test and Verify","text":"<ul> <li>Walk through examples: Use the provided test cases</li> <li>Check edge cases: Empty input, single element, large input</li> <li>Verify correctness: Ensure the solution works as expected</li> <li>Analyze complexity: Confirm time and space complexity</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#common-interview-patterns","title":"Common Interview Patterns","text":""},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#1-two-pointers-technique","title":"1. Two Pointers Technique","text":"<pre><code>def two_sum_sorted(arr, target):\n    left, right = 0, len(arr) - 1\n    while left &lt; right:\n        current_sum = arr[left] + arr[right]\n        if current_sum == target:\n            return [left, right]\n        elif current_sum &lt; target:\n            left += 1\n        else:\n            right -= 1\n    return [-1, -1]\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#2-sliding-window","title":"2. Sliding Window","text":"<pre><code>def max_sum_subarray(arr, k):\n    if len(arr) &lt; k:\n        return 0\n\n    window_sum = sum(arr[:k])\n    max_sum = window_sum\n\n    for i in range(k, len(arr)):\n        window_sum = window_sum - arr[i-k] + arr[i]\n        max_sum = max(max_sum, window_sum)\n\n    return max_sum\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#3-binary-search","title":"3. Binary Search","text":"<pre><code>def binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    return -1\n</code></pre>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#communication-tips","title":"Communication Tips","text":""},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#1-think-out-loud","title":"1. Think Out Loud","text":"<ul> <li>Explain your reasoning: Why you chose a particular approach</li> <li>Discuss trade-offs: Time vs space complexity</li> <li>Consider alternatives: What other approaches could work?</li> <li>Ask questions: Clarify requirements when needed</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#2-handle-mistakes-gracefully","title":"2. Handle Mistakes Gracefully","text":"<ul> <li>Acknowledge errors: Don't try to hide mistakes</li> <li>Correct yourself: Show you can identify and fix issues</li> <li>Learn from feedback: Use interviewer suggestions</li> <li>Stay positive: Maintain confidence throughout</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#3-show-your-work","title":"3. Show Your Work","text":"<ul> <li>Write clear code: Use meaningful variable names</li> <li>Add comments: Explain complex logic</li> <li>Test your code: Walk through examples</li> <li>Consider edge cases: Show thorough thinking</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#common-mistakes-to-avoid","title":"Common Mistakes to Avoid","text":""},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#1-rushing-to-code","title":"1. Rushing to Code","text":"<ul> <li>Take time to understand: Don't start coding immediately</li> <li>Plan your approach: Think before implementing</li> <li>Consider edge cases: Plan for all scenarios</li> <li>Estimate complexity: Know your solution's efficiency</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#2-ignoring-constraints","title":"2. Ignoring Constraints","text":"<ul> <li>Check input size: Consider memory limitations</li> <li>Verify requirements: Ensure you understand the problem</li> <li>Test assumptions: Don't assume input format</li> <li>Consider performance: Think about scalability</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#3-poor-communication","title":"3. Poor Communication","text":"<ul> <li>Stay silent: Don't explain your thinking</li> <li>Ignore feedback: Don't listen to interviewer suggestions</li> <li>Give up easily: Don't show persistence</li> <li>Be defensive: Don't accept criticism</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#sample-interview-questions","title":"Sample Interview Questions","text":""},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#easy-level","title":"Easy Level","text":"<ol> <li>Two Sum: Find two numbers that add up to target</li> <li>Valid Parentheses: Check if parentheses are balanced</li> <li>Reverse String: Reverse a string in-place</li> <li>Valid Palindrome: Check if string is palindrome</li> </ol>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#medium-level","title":"Medium Level","text":"<ol> <li>Longest Substring Without Repeating Characters: Sliding window</li> <li>Container With Most Water: Two pointers</li> <li>3Sum: Array manipulation with sorting</li> <li>Binary Tree Level Order Traversal: BFS</li> </ol>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#hard-level","title":"Hard Level","text":"<ol> <li>Median of Two Sorted Arrays: Binary search</li> <li>Regular Expression Matching: Dynamic programming</li> <li>Merge k Sorted Lists: Heap/priority queue</li> <li>Word Ladder: BFS with optimization</li> </ol>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#resources-for-practice","title":"Resources for Practice","text":""},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#online-platforms","title":"Online Platforms","text":"<ul> <li>LeetCode: Comprehensive problem database</li> <li>HackerRank: Practice problems and contests</li> <li>CodeSignal: Interview preparation platform</li> <li>TopCoder: Competitive programming</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#books","title":"Books","text":"<ul> <li>\"Cracking the Coding Interview\": Gayle McDowell</li> <li>\"Introduction to Algorithms\": CLRS</li> <li>\"Algorithm Design Manual\": Steven Skiena</li> <li>\"Programming Interviews Exposed\": John Mongan</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#mock-interviews","title":"Mock Interviews","text":"<ul> <li>Pramp: Free peer-to-peer mock interviews</li> <li>Interviewing.io: Practice with real engineers</li> <li>LeetCode Mock Interviews: Simulated interview environment</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Interview_Strategies/#related-topics","title":"Related Topics","text":"<ul> <li>Time Complexity Guide - Understanding algorithm efficiency</li> <li>Common Patterns - Frequently used problem-solving patterns</li> <li>Set Operations - Set-based interview problems</li> <li>Dictionary Operations - Dictionary-based interview problems</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/","title":"Time Complexity Guide","text":"<p>Understanding algorithm efficiency and time complexity analysis.</p>"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#big-o-notation","title":"Big O Notation","text":"<p>Big O notation describes the performance or complexity of an algorithm by showing how the runtime grows as the input size increases.</p>"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#common-time-complexities","title":"Common Time Complexities","text":"Complexity Name Description Example O(1) Constant Runtime doesn't change with input size Array access, Hash table operations O(log n) Logarithmic Runtime grows logarithmically Binary search, Balanced tree operations O(n) Linear Runtime grows linearly with input size Linear search, Array traversal O(n log n) Linearithmic Runtime grows as n times log n Merge sort, Quick sort O(n\u00b2) Quadratic Runtime grows as square of input size Bubble sort, Nested loops O(2\u207f) Exponential Runtime grows exponentially Recursive Fibonacci, Subset generation O(n!) Factorial Runtime grows as factorial of input size Traveling salesman (brute force)"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#data-structure-complexities","title":"Data Structure Complexities","text":""},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#arraylist-operations","title":"Array/List Operations","text":"Operation Time Complexity Space Complexity Access O(1) O(1) Search O(n) O(1) Insert (end) O(1) O(1) Insert (beginning) O(n) O(1) Delete (end) O(1) O(1) Delete (beginning) O(n) O(1)"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#set-operations","title":"Set Operations","text":"Operation Time Complexity Space Complexity Access N/A N/A Search O(1) O(1) Insert O(1) O(1) Delete O(1) O(1) Union O(n) O(n) Intersection O(n) O(n)"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#dictionary-operations","title":"Dictionary Operations","text":"Operation Time Complexity Space Complexity Access O(1) O(1) Search O(1) O(1) Insert O(1) O(1) Delete O(1) O(1)"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#algorithm-complexities","title":"Algorithm Complexities","text":""},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#sorting-algorithms","title":"Sorting Algorithms","text":"Algorithm Time Complexity Space Complexity Stable Bubble Sort O(n\u00b2) O(1) Yes Selection Sort O(n\u00b2) O(1) No Insertion Sort O(n\u00b2) O(1) Yes Merge Sort O(n log n) O(n) Yes Quick Sort O(n log n) O(log n) No Heap Sort O(n log n) O(1) No"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#search-algorithms","title":"Search Algorithms","text":"Algorithm Time Complexity Space Complexity Linear Search O(n) O(1) Binary Search O(log n) O(1) Depth-First Search O(V + E) O(V) Breadth-First Search O(V + E) O(V)"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#space-complexity-guidelines","title":"Space Complexity Guidelines","text":"<ul> <li>O(1): Constant space - no extra space needed</li> <li>O(n): Linear space - space grows with input size</li> <li>O(n\u00b2): Quadratic space - space grows with square of input size</li> <li>O(log n): Logarithmic space - space grows with log of input size</li> </ul>"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#best-practices","title":"Best Practices","text":"<ol> <li>Choose appropriate data structures: Use sets for membership testing, dictionaries for key-value pairs</li> <li>Consider trade-offs: Time vs space complexity</li> <li>Profile your code: Measure actual performance, not just theoretical complexity</li> <li>Optimize bottlenecks: Focus on the most time-consuming parts of your algorithm</li> <li>Use built-in functions: They're often optimized</li> </ol>"},{"location":"engineering_and_data_structure/Resources/Time_Complexity_Guide/#related-topics","title":"Related Topics","text":"<ul> <li>Common Patterns - Frequently used patterns and their complexities</li> <li>Interview Strategies - Tips for analyzing complexity in interviews</li> <li>Set Operations - Set operation complexities</li> <li>Dictionary Operations - Dictionary operation complexities</li> </ul>"},{"location":"language_model/Ngram_Language_Modeling/","title":"Week3_Ngram_Language_Modeling","text":""},{"location":"language_model/Ngram_Language_Modeling/#n-gram-models-language-modeling","title":"N-gram Models &amp; Language Modeling","text":""},{"location":"language_model/Ngram_Language_Modeling/#introduction","title":"Introduction","text":"<p>N-gram language models are the classical approach to predicting words based on fixed-length context. They remain a great entry point for understanding how language modeling works, how to evaluate models with perplexity, and why data sparsity motivates neural approaches.</p>"},{"location":"language_model/Ngram_Language_Modeling/#knowledge-points","title":"Knowledge Points","text":"<ul> <li>Textual Descriptive Models</li> <li>What is an n-gram?</li> <li>Building and training an n-gram language model</li> <li>Perplexity: definition &amp; interpretation</li> <li>Limitations of n-gram models (data sparsity, context window)</li> <li>Implementing bigram or trigram models on a toy corpus</li> </ul>"},{"location":"ml_fundamentals/ML_Fundamentals_Overview/","title":"Machine Learning Fundamentals","text":"<p>Welcome to the Machine Learning Fundamentals section! This comprehensive guide covers the essential concepts and techniques that form the foundation of machine learning.</p>"},{"location":"ml_fundamentals/ML_Fundamentals_Overview/#learning-path","title":"\ud83d\udcda Learning Path","text":""},{"location":"ml_fundamentals/ML_Fundamentals_Overview/#1-feature-engineering","title":"1. Feature Engineering","text":"<p>The foundation of any successful ML project starts with proper data preparation and feature engineering.</p> <ul> <li>Data Types &amp; Normalization - Understanding structured vs unstructured data, normalization techniques (min-max scaling, z-score)</li> <li>Categorical Encoding - Ordinal, one-hot, and binary encoding methods</li> <li>Feature Crosses - High-dimensional feature combinations and dimensionality reduction</li> </ul>"},{"location":"ml_fundamentals/ML_Fundamentals_Overview/#2-model-evaluation-validation","title":"2. Model Evaluation &amp; Validation","text":"<p>Learn how to properly evaluate and validate your machine learning models.</p> <ul> <li>Evaluation Methods - Holdout, cross-validation, and bootstrap methods</li> <li>Metrics &amp; Validation - Accuracy, precision, recall, F1-score, and ROC curves</li> <li>Hyperparameter Tuning - Grid search, random search, and Bayesian optimization</li> </ul>"},{"location":"ml_fundamentals/ML_Fundamentals_Overview/#3-regularization-overfitting","title":"3. Regularization &amp; Overfitting","text":"<p>Master techniques to prevent overfitting and improve model generalization.</p> <ul> <li>Overfitting &amp; Underfitting - Detection and mitigation strategies</li> <li>L1/L2 Regularization - Mathematical foundations and implementation</li> <li>Early Stopping - Training control and data augmentation techniques</li> </ul>"},{"location":"ml_fundamentals/ML_Fundamentals_Overview/#4-classical-supervised-algorithms","title":"4. Classical Supervised Algorithms","text":"<p>Explore fundamental supervised learning algorithms.</p> <ul> <li>Linear Regression - Simple and multiple linear regression with implementation</li> <li>Logistic Regression - Binary classification with sigmoid function and maximum likelihood</li> <li>Decision Trees - Gini impurity, information gain, and tree construction</li> </ul>"},{"location":"ml_fundamentals/ML_Fundamentals_Overview/#5-unsupervised-learning","title":"5. Unsupervised Learning","text":"<p>Discover algorithms for finding patterns in unlabeled data.</p> <ul> <li>K-Nearest Neighbors - Distance metrics and classification algorithm</li> <li>K-Means Clustering - Clustering algorithm and implementation</li> </ul>"},{"location":"ml_fundamentals/ML_Fundamentals_Overview/#related-topics","title":"\ud83d\udd17 Related Topics","text":"<ul> <li>Probability &amp; Markov - Probability foundations and Bayesian methods</li> <li>Language Models - Text processing and NLP techniques</li> <li>Information Theory - Entropy, cross-entropy, and KL divergence</li> <li>Linear Algebra - Mathematical foundations for ML</li> <li>Calculus &amp; Gradient Descent - Optimization techniques</li> </ul>"},{"location":"ml_fundamentals/ML_Fundamentals_Overview/#key-learning-objectives","title":"\ud83c\udfaf Key Learning Objectives","text":"<p>By the end of this section, you will understand:</p> <ul> <li>How to preprocess and engineer features for ML models</li> <li>Methods for evaluating and validating model performance</li> <li>Techniques to prevent overfitting and improve generalization</li> <li>Implementation of fundamental supervised and unsupervised algorithms</li> <li>Best practices for hyperparameter tuning and model selection</li> </ul>"},{"location":"ml_fundamentals/ML_Fundamentals_Overview/#prerequisites","title":"\ud83d\udcd6 Prerequisites","text":"<ul> <li>Basic understanding of Python programming</li> <li>Familiarity with probability concepts (see Probability &amp; Markov section)</li> <li>Knowledge of linear algebra fundamentals (see Linear Algebra for ML)</li> </ul> <p>Start with Feature Engineering to build a solid foundation, then progress through the sections in order for the best learning experience.</p>"},{"location":"ml_fundamentals/ML_fundamentals/","title":"ML Fundamentals","text":""},{"location":"ml_fundamentals/ML_fundamentals/#feature-engineering","title":"Feature Engineering","text":"<p>Two types of data: - Structured / Tabular data: Could be viewed as a data table from the relational database, which every columns has their clear definition, including numerical and categorial data types. - Unstructured data: Includes text, image, audio, video data, and the information that this type of data contains cannot be represented easily as a numerical value, and also they do not have clear categorical definition, furthermore, the size of these data are not identical.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#normalization-of-features","title":"Normalization of Features","text":""},{"location":"ml_fundamentals/ML_fundamentals/#why-does-one-need-to-do-normalization-on-numerical-features","title":"Why does one need to do normalization on numerical features?","text":"<p>In order to eliminate the magnitude impact between features, we should always do normalization to the features that we use, i.e. to uniformly normalize all the features to a similar range, so that it could help compare between different metrics. There are two different types of normalization that people most commonly use: - min-max scaling: It linearly changes the original data so that the data could be projected to [0, 1] range so that it is an equal ratio transformation of the original data: \\(\\(X_{\\text{norm}} = \\frac{X-X_{\\text{min}}}{X_{\\text{max}-X_{\\text{min}}}}\\)\\) - Z-Score normalization: It would project the original data to a mean of 0 and variance = 1 distribution. Specifically, assume that the original feature has mean \\(\\mu\\) and variance \\(\\sigma\\) , then the normalization equation would be defined as: \\(\\(Z = \\frac{x-\\mu}{\\sigma}\\)\\)  Using stochastic gradient descent (SGD) as an example, when two numerical features, \\(x_1\\) of range [0,10] and \\(x_2\\) of range [0,3], then when the \\(x_1\\) and \\(x_2\\) are not normalized, the  gradient descent would not be as efficient as when one does the normalization of the features. However, feature normalization is not always working. In real life,  whenever a model utilizes SGD, it is suggested to use the normalization, including linear regression, logistic regression, support vector machine, neural networks, whereas decision tress it does not help.  As for decision tree models, the node split usually is determined by the data and how much <sup>1</sup>information gain ratio that data contains about X. This information gain ratio is not impacted by whether the feature has been normalized, rather it would not change the information gain of the specific feature X.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#categorical-features","title":"Categorical Features","text":"<p>Categorical features include male / female, blood type (A,B,AB,O) and etc, which can only select values from a finite set of choices. Categorical features original input are mostly strings. Despite that decision trees and some other numbers of models can directly take in the strings, for logistic regression or SVM models, the categorical features need to be translated to numerical form so that they could properly work.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#how-to-do-feature-engineering-on-categorical-features","title":"How to do feature engineering on categorical features?","text":"<p>One would need to encode the features to a higher dimensional vector to represent them in the model. - ordinal encoding: usually used to treat those data that has ordinal sequence, for example when scoring we have high &gt; middle &gt; low, then the ordinal encoder would help to describe this type of sequence via giving it a numerical ID. For example, we could represent high as 3, middle as 2 and low as 1 in this case, which helps retain the high to low relationship. - one-hot encoding: usually used to treat features that do not have ordinal relationships, for example, for blood type, one could directly use the [1,0,0,0], [0,1,0,0], [0,0,1,0] and [0,0,0,1] to represent the different types. Note:     - use of sparse vector for saving space     - high-dimensional features can be difficult in following scenarios: 1) K-nearest neighbors, the distance between two high-dimensional vectors can be hard to measure, 2) logistic regression, the parameters can increase with higher dimensions, thus causing overfitting problems and 3) only some of the dimensions could be helpful when doing clustering or predictions, so one could think to reduce dimensions with feature selections. - binary encoding: using binary to do a hash mapping on the original category ID, this can help save space when comparing with the one-hot encoding as it is usually of fewer dimensions.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#high-dimensional-feature-crosses","title":"High Dimensional Feature Crosses","text":""},{"location":"ml_fundamentals/ML_fundamentals/#what-are-feature-crosses-and-how-to-deal-with-high-dimensional-feature-crosses","title":"What are feature crosses? And how to deal with high-dimensional feature crosses?","text":"<p>Using single features to combine them together via dot-product or inner-product, one can get a combination of two features to help represent nonlinear relationships.</p> <p>Using logistic regression as an example, when a data set contains feature vector \\(X=(x_1, x_2, ..., x_k)\\) then one would have \\(Y = \\text{sigmoid}(\\sum_i \\sum_j w_{ij} \\langle x_i, x_j \\rangle)\\) . \\(w_{ij}\\) is of dimension \\(n_{x_i} \\cdot n_{x_j}\\) . But when \\(n_{x_i} \\times n_{x_j}\\) is huge, especially in use cases of website customers and number of goods, this can be really huge dimension. So **one way to get around this is to use a k-dimensional low-dimension vector (k &lt;&lt; m, k &lt;&lt; n). Now,  \\(w_{ij} = x_i' \\cdot x_j'\\) and now the number of parameters one needs to tune is \\(m \\times k + n \\times k\\) . This can also be viewed as the <sup>2</sup>matrix vectorization, that has been widely used in the recommendation systems. **</p> <p>We have understood how to use dimension reduction to reduce the number of parameters that the model needs to learn given a feature cross of two high-dimensional features.  But in reality, we are facing a variety of high-dimensional features. So a single feature crosses of all the different pairs would induce 1) too many parameters and 2) overfitting issues. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#how-to-effectively-select-the-feature-combinations","title":"How to effectively select the feature combinations?","text":"<p>We introduce a feature cross selection based on decision tree models. Taking CTR prediction as an example, assume that the input includes age, gender, user type (free vs paid), searched item type (skincare vs foods), etc. We could thus make a decision tree from the original input and their labels.  We could then view the feature crosses from the tree, that contains four different type of pairs: 1. age + gender 2. age + searched item type 3. paid user + search item type 4. paid user + age How to best construct the decision trees? One can use the Gradient Boosting Decision Tree\u00ef\u00bc\u0152GBDT or use the link to get a better idea of the algorithm. The idea behind is that whenever before constructing a decision tree, we first calculate the error from the true value and iteratively construct the tree from the error.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#textual-descriptive-models","title":"Textual Descriptive Models","text":"<p>Related Content: Ngram_Language_Modeling</p> <p>Text is a category of unstructured data. How to work with textual data has always been one of the most important research directions.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#what-are-some-of-the-textual-descriptive-models-what-pros-and-cons-each-have","title":"What are some of the textual descriptive models what pros and cons each have?","text":"<ul> <li>Bag of words: Consider each article as a bag of words, ignoring the sequence of how each word appears. Specifically, it separates the entire paragraph of texts at word unit and represent each paragraph as a long vector. Each dimension in the vector is a word, and the weight represents how important the word is in the original article. </li> <li>TF-IDF (Term Frequency-Inverse Document Frequency): Is often used to calculate the weight of the words, \\(\\text{TF-IDF}(t,d)=\\text{TF}(t,d) \\times \\text{IDF}(t)\\) , where \\(\\text{TF}(t,d)\\) represents the frequency of word t in document d, whereas \\(\\text{IDF}(t)\\) is the reverse document frequency to measure word t's importance in grammar, corresponds to equation \\(\\(\\text{IDF}(t) = log^{\\frac{\\text{total article}}{\\text{total article that contains word} t +1}}\\)\\) the general meaning behind is that if a word appears so in various articles, then it means that it is a commonly used word, hence it would not contribute much in differentiating the specific meaning behind each articles, hence it should be penalized when weighting.</li> <li>N-gram: when \"natural language processing\" being separated into 3 words as word unit, the meaning of this phrase is totally different from it is now, hence usually we could add n words as a feature unit into the vector to form the N-gram model. </li> <li>Topic Model</li> <li>Word Embedding: word embedding is a family of word vector models, the main idea is to project each word to a low-dimensional space (K = 50 -300 dimensions) using a dense vector. Each dimension in K-dimension would be viewed as a implicit topic.  In general, in shallow learning models (traditional ML models), a good feature engineering step can help extremely good performance. Deep learning on the other hand, could help us with an automated feature engineering way via hidden layers. Hence, it makes sense for the deep learning model to beat the shallow learning model in general. Recurrent neural network and convolutional neural network are both good at capture the characteristics of the text while lowering the number of parameters that the model needs to learn, which can expedite the speed of training and also lower the risk of overfitting. </li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#word2vec","title":"Word2Vec","text":"<p>One of the most common word embedding models, it is actually a shallow neural network. It can be of two different types of structures:  1. Continuous Bag of Words 2. Skip-gram</p>"},{"location":"ml_fundamentals/ML_fundamentals/#how-does-word2vec-work-what-is-the-difference-between-word2vec-and-lda-latent-dirichlet-allocation","title":"How does word2vec work? what is the difference between word2vec and LDA (Latent Dirichlet allocation)","text":"<ul> <li>Continuous Bag of Words<ul> <li>Goal is to use contextual words that predict the probability of the current word to appear.</li> <li>Structure: <ul> <li>input layer: w(t-2), w(t-1), ..., w(t+1), w(t+2) using one-hot encoding</li> <li>projection/hidden layer: sum(probability)</li> <li>output layer: w(t) using softmax</li> </ul> </li> </ul> </li> <li>Skip-gram<ul> <li>Goal is to use the current word to predict the probability of each contextual word.</li> <li>Structure:<ul> <li>input layer: w(t) using one-hot encoding</li> <li>projection/hidden layer</li> <li>output layer: w(t-2), w(t-1), ..., w(t+1), w(t+2) using softmax</li> </ul> </li> </ul> </li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#image-data-not-sufficient-cold-start","title":"Image Data not sufficient - Cold Start","text":"<p>When doing machine learning modeling, one very big problem that everyone may face would be not sufficient training data. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#what-would-you-do-if-the-training-data-is-not-sufficient-how-to-mitigate-this-issue","title":"What would you do if the training data is not sufficient? How to mitigate this issue?","text":"<p>Information that a model can provide include 1) information from training and 2) heuristic information that people provide from model formation (including design / learn / deduct). When training data not enough, it means that the model lacks information from training data, but need more a priori. a priori can be effective on models, including certain internal structure of the model, assumption or constraints. a priori can also be applied to datasets, for example using certain assumption to change / tune or expand the training data so it contains more effective information, which can facilitate model training and learning.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#overfitting","title":"Overfitting","text":"<p>One big problem that comes from not enough data is overfitting, which is that the model performs well on training set but the evaluation / prediction set is not good. The treatment can come from two different categories: - methods based on models that decrease the risk of overfitting     - simplify model - downgrade from non-linear to linear model     - apply constraints to shrink hypothesis space - L1 / L2 regularization     - integrated training     - dropout hyperparameters - data augmentation: manipulating data to expand the data set     - image space manipulation         - rotation / shrinkage / expansion / crop of the original image when working with image data         - addition of noise to the image         - color change of image         - hue / contract / brightness of image     - image feature engineering / extraction         - data expansion or #over-sampling via SMOTE (Synthetic Minority Over-sampling Technique)         - using GAN or other generative methods for good samples     - transfer learning from other models and data         - using pre-trained general model from big dataset, we could fine-tune specifically using the small datasets</p>"},{"location":"ml_fundamentals/ML_fundamentals/#model-evaluation","title":"Model Evaluation","text":""},{"location":"ml_fundamentals/ML_fundamentals/#evaluation-metrics-and-their-limitations","title":"Evaluation metrics and their limitations","text":"<p>When doing model evaluation, the classification / sort / regression problems seems to always use different metrics for evaluation. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#accuracy-and-its-limitations","title":"Accuracy and its limitations","text":"<p>The accuracy only measures the number of correct labels divided by the number of total labels. This can potentially lead to a issue when the number of labels are limited in the dataset. When negative samples composed 99% of the data, if every label is a negative one, we still get 99% accuracy. So, if we use more effective mean accuracy that quantifies the mean accuracy under each category, it would be a better metrics to work with.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#precision-recall-and-their-balance","title":"Precision &amp; Recall and their balance","text":""},{"location":"ml_fundamentals/ML_fundamentals/#concept-of-precision-recall","title":"Concept of Precision &amp; Recall","text":"<p>Now we need to introduce the concept of precision and recall.  Precision cares about the correctness of positive predictions, whereas recall cares about coverage of actual positives.  Precision and recall trade off via the decision threshold. In a binary classification problem: $$\\text{Precision} = \\frac{N_{\\text{true positive}}}{N_{\\text{true positive}} + N_{\\text{false positive}}} = \\frac{N_{\\text{true positive}}}{N_{\\text{positive predictions}}} $$</p> <p>$$\\text{Recall} = \\frac{N_{\\text{true positive}}}{N_{\\text{true positive}} + N_{\\text{false negative}}} = \\frac{N_{\\text{true positive}}}{N_{\\text{actual positives}}} $$ The F1 score is their harmonic mean: $$\\text{F1} = \\frac{2(\\text{Precision})(\\text{Recall})}{\\text{Precision} + \\text{Recall}} = \\frac{2N_{\\text{true positive}}}{2N_{\\text{true positive}}+N_{\\text{false positive}}+N_{\\text{false negative}}} $$ this value ranges from 0 to 1 and penalizes imbalance, thus when either precision or recall is low, F1 drops sharply.  F1 should be used when false positives and false negatives matter about equally, especially with imbalanced classes. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#confusion-matrix-implementation","title":"Confusion Matrix Implementation","text":"<pre><code>import numpy as np\n\ntrue_labels = np.array([0, 0, 1, 1, 0, 1, 0, 1, 1, 1])\npredicted_labels = np.array([0, 1, 0, 1, 0, 1, 1, 1, 1, 0])\n\nTP = np.sum((predicted_labels == 1) &amp; (true_labels == 1))\nTN = np.sum((predicted_labels == 0) &amp; (true_labels == 0))\nFP = np.sum((predicted_labels == 1) &amp; (true_labels == 0))\nFN = np.sum((predicted_labels == 0) &amp; (true_labels == 1))\n\nprint(\"Confusion Matrix:\\n TP: \", TP, \"\\tFP: \", FP, \"\\n FN: \", FN, \"\\tTN: \", TN)\n\n'''Output:\nConfusion Matrix:\n TP:  4     FP:  2 \n FN:  2     TN:  2\n'''\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#precision-recall-in-ranking-retrieval-variants","title":"Precision &amp; Recall in Ranking / retrieval variants","text":"<pre><code>def precision_at_k(ground_truth_set, ranked_list, k):\n    return len(set(ranked_list[:k]) &amp; ground_truth_set) / k\n</code></pre> <p><pre><code># when there are more than one query / user / example that we would like to test on our predictions, we use the weighted average of the precision_at_k.\ndef mean_precision_at_k(ground_truth_sets, ranked_lists, k):\n    # ground_truth_sets and ranked_lists are aligned lists\n    return sum(precision_at_k(g, r, k) for g, r in zip(ground_truth_sets, ranked_lists)) / len(ground_truth_sets)\n</code></pre> - Precision@k for one case \\(q\\) (one list). - Mean Precision@k average of those values over all cases \\(q \\in Q\\).</p> <p>Example: when dealing with video vague search functionality, it seems that the search ranking model can return the top 5 precision pretty high, however, the user in reality still cannot find the videos they want, especially those unpopular ones. Where does this problem coming from?</p> <p>Root cause analysis: Coming back to the example above, the top 5 precision being really high, meaning that the model can get the true positive results on a pretty good level with a certain set of positive predictions; however, when it comes down to cases where users would like to find not so popular videos, the precision of ranks can be rather no so useful as the user is looking for not so well-defined labels, hence the good precision of popular videos would not be helpful for this case as model is not providing all the relevant videos to the user and this is a problem of not so good recall rate.  Let's say for the top 5 results, the precision@5 to be 100%, meaning that the correctness of the positive results is pretty higher, however, the recall@5 can still be 5%, meaning that only predicted 5 true positives although there are 100 actual positives involved. When doing model evaluation, it means that we should be focusing on both precision and recall, and also using different top N values for observations. </p> <p>Hence, in general, when people evaluate the goodness of a sort algorithm, they also look at the P-R curve, where in this curve, the x-axis corresponds to recall rate whereas the y-axis corresponds to precision rate. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#use-of-p-r-curve-for-model-evaluation-and-threshold-choice","title":"Use of P-R Curve for model evaluation and threshold choice","text":"<p> Each data point on the curve corresponds to a precision-recall combination at a certain threshold for True samples of choice, for example 0.95 / 0.9, etc. The closer to the origin (0,0) point, the bigger the threshold is.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#how-to-pick-the-threshold-in-practice","title":"How to pick the threshold in practice","text":"<ul> <li>Capacity-constrained: If reviewers can handle 300 cases/day, pick the smallest threshold that yields \u00e2\u2030\u02c6300 flags/day; report the resulting (Precision, Recall).</li> <li>Recall target: If policy demands \u00e2\u2030\u00a595% recall, choose the lowest threshold achieving that, then report precision (and expected review load).</li> <li>Cost-based: Minimize \\(\\text{Cost}_{\\text{false positives}}\\cdot{\\text{False Positives}}+\\text{Cost}_{\\text{false negatives}}\\cdot{\\text{False Negatives}}\\) over thresholds. Also report AUPRC to compare models independent of a single threshold (higher is better, especially with class imbalance).</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#root-mean-squared-errors-rmse","title":"Root-mean Squared Errors (RMSE)","text":"\\[ RMSE = \\sqrt{\\frac{\\sum_{i=1}^{n}{(y_i - \\hat y_i)^2}}{n}} \\] <p>Root-mean squared error has long been used as the metric for evaluating the regression model.</p> <p>Example: as a streaming company, one would say that prediction of traffic for each series can be really important when it comes down to ads bidding and user expansion. One would like to use a regression model to predict the traffic trend of a certain series, but whatever regression model that one uses, the RMSE metric ends up being really high. But, in reality, the model 95% of the time predict error is less than 1%, with really good prediction results. What might be the reason of this extraordinarily good results?</p> <p>Root cause analysis: From what the example, says there are two possible ways for the RMSE to be ineffective: 1) n being really small hence at this moment, the calculated error cannot be measurable anymore, 2) all the errors between actual value and predicted value are over- / under-predicting that the summation at the end being really high, however, in reality it is not the case and 3) one outlier being really off when comparing with other data points, it is contaminating the RMSE to be really big.  Coming back to the question, as 95% of the time to model has really good prediction error hence it means the other 5% of the time the model can be really off with big outliers and it could happen when a series with small traffic / newly come-out / newly accoladed could produce this big error.</p> <p>How to solve: 1) When we think these outliers are noises, then we need to filter them out at the early stage when doing data cleaning, 2) If we do not think they are noises, then we need to further improve the prediction capability of our algorithm so that we could somehow model the formation of these outliers. and 3) We could also use a better metric for the model evaluation. There are indeed better evaluation metrics that are of better robustness than RMSE, for example, Mean Absolute Percentage Error (MAPE):</p>"},{"location":"ml_fundamentals/ML_fundamentals/#mean-absolute-percentage-error","title":"Mean Absolute Percentage Error","text":"\\[MAPE = \\sum_{i=1}^n{|\\frac{(y_i - \\hat y_i)}{y_i}|\\cdot\\frac{100}{n}}\\] <p>When comparing with RMSE, MAPE normalizes the error rate of each data point to mitigate the outlier impact from the absolute error.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#expanding-on-the-regression-evaluation-metrics","title":"Expanding on the regression evaluation metrics","text":""},{"location":"ml_fundamentals/ML_fundamentals/#quick-definitions","title":"Quick definitions","text":"<p>Let \\(y\\) be the true value and \\(\\hat y\\)\u00e2\u20ac\u2039 the prediction.   sMAPE (common form):  \\(\\(\\frac{100}{n}\\sum\\frac{2|y-\\hat y|}{|y|+|\\hat y|}\\)\\)</p>"},{"location":"ml_fundamentals/ML_fundamentals/#when-to-use-which","title":"When to use which","text":"<ul> <li>Use RMSE when:<ul> <li>Big errors are much worse than small ones (squared penalty).</li> <li>The target never hits zero/near-zero and units are meaningful (e.g., dollars, \u00c2\u00b0C).</li> <li>You care about calibration and smooth optimization (differentiable).</li> </ul> </li> <li>Use MAPE when:<ul> <li>Stakeholders want an average percentage error that is easy to read.</li> <li>True values are strictly positive and not near zero (e.g., revenue, demand &gt; 0).</li> <li>You're okay that over-forecasts and under-forecasts are weighted differently (MAPE tends to penalize under-forecasting less when \\(y\\) is small).</li> </ul> </li> <li>Use sMAPE when:<ul> <li>You want a percentage-like metric that is less explosive near zero than MAPE.</li> <li>You have occasional zeros or tiny values.</li> <li>You accept that sMAPE has its own quirks (bounded but not perfectly symmetric in practice).</li> </ul> </li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#strengths-gotchas-tldr","title":"Strengths &amp; gotchas (TL;DR)","text":"<ul> <li>RMSE<ul> <li>Sensitive to large mistakes (good if that matches cost).</li> <li>Outlier-heavy data can dominate the score.</li> <li>Scale-dependent hard to compare across series with different scales.</li> </ul> </li> <li>MAPE<ul> <li>Intuitive (%).</li> <li>Undefined at y=0; huge when y ~ 0.</li> <li>Can favor under-forecasting for small y.</li> </ul> </li> <li>sMAPE<ul> <li>Handles zeros better; bounded.        </li> <li>Still quirky near zero and not a true solution for optimization.</li> <li>Different papers/tools use slightly different variants</li> </ul> </li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#other-basic-metrics-you-should-know","title":"Other basic metrics you should know","text":"<ul> <li>MAE: Robust to outliers vs RMSE; easy to explain (units).</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#simple-decision-guide","title":"Simple decision guide","text":"<ol> <li>Zeros or tiny targets?<ul> <li>Avoid plain MAPE. Prefer sMAPE</li> </ul> </li> <li>Large errors are very costly?<ul> <li>Use RMSE (or set a business-weighted loss).</li> </ul> </li> <li>Need % interpretability across series?<ul> <li>Use sMAPE, or MASE (if comparing to a baseline).</li> </ul> </li> <li>Care about relative ratios?<ul> <li>Use RMSLE/MSLE (with positive targets).</li> </ul> </li> <li>Mixed scales or many series?<ul> <li>WAPE or MASE are safe, comparable choices.</li> </ul> </li> </ol>"},{"location":"ml_fundamentals/ML_fundamentals/#practical-tips","title":"Practical tips","text":"<ul> <li>If you must report a % and have zeros, say: We use sMAPE (formula shown) instead of MAPE to handle zeros; we also report WAPE for scale-free comparability.</li> <li>Always state the exact formula you use (especially for sMAPE) to avoid confusion.</li> <li>Consider reporting two metrics: one business-facing (% like WAPE/sMAPE) + one technical (MAE/RMSE).</li> </ul> <p>Overall, one should always report a pair / set of MECE metrics to evaluate their algorithms to better understand &amp; discover the problems in the model, to better solve cases in real business settings.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#roc-curves","title":"ROC Curves","text":"<p>Binary classifiers are the mostly used and applied classifier in the ML industry. There are a lot of different metrics that one could use for evaluate the binary classifiers, including precision, recall, F1 score and P-R curve. But these metrics are only reflecting one aspect of the model. Hence, ROC curves can be of really good use. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#what-is-a-roc-curve","title":"What is a ROC curve","text":"<p>ROC curves are called receiver Operating Characteristic Curves, which established from the military field and are often used in the medical industry as well. This curve's x-axis is the false positive rate, whereas the y-axis is the true-positive rate. </p> <p>\\(\\(\\text{False Positive Rate} = \\frac{\\text{False Positive}}{\\text{Negative}}\\)\\) \\(\\(\\text{True Positive Rate} = \\frac{\\text{True Positive}}{\\text{Positive}}\\)\\) Example: There are 10 patients, where in there are 3 positive cancer patients, and the rest are negative patients. The hospital decides to do diagnosis on these customers and figured that 2 are true positive cancer patients. In this case:</p> \\[\\text{False Positive Rate} = \\frac{\\text{False Positive}}{\\text{Negative}} = \\frac{1}{7}$$ $$\\text{True Positive Rate} = \\frac{\\text{True Positive}}{\\text{Positive}}=\\frac{2}{3}\\]"},{"location":"ml_fundamentals/ML_fundamentals/#how-to-draw-a-roc-curve","title":"How to draw a ROC curve","text":"<ul> <li>What is needed<ul> <li>True labels \\(y \\in \\{0,1\\}\\)</li> <li>A score for the positive class per item (probability or decision score).  </li> </ul> </li> </ul> Sample Number True Label Model Output Probability as Positive 1 Positive 0.9 2 Positive 0.8 3 Negative 0.7 <p>From this example, we could then plot out the true positive rate (TPR) as the x-axis and false positive rate (FPR) as the y-axis for the curve, hence getting the ROC curve. There is a more direct way to plot the ROC curve as well:</p> <ul> <li>Getting the number of Positive &amp; Negative samples, i.e. assuming number of positive samples to be P and negative to be N.</li> <li>Getting the x-axis labels to be the count of negative samples, and y-axis labels to be the count of positive samples, then use the model output probability to do sorting of the samples</li> <li>Now draw the ROC curve from origin, whenever seeing a positive sample to draw a vertical line segment of +1 increment on y-axis, whenever seeing a negative sample then we draw a horizontal line segment along the x-axis until we reach the final sample with curve ending at (1,1).</li> </ul> <pre><code>from matplotlib import pyplot as plt\nfrom numpy import random\n\ntruth_labels = [1 if random.rand() &gt; 0.6 else 0 for _ in range(500)]\n# we generate some random predictions that would normally be obtained from the model\n# If a predicted probability is higher than the threshold, it is considered to be a positive outcome \npredicted_probs = [max(0, min(1, random.normal(loc=label, scale=0.3))) for label in truth_labels]\n\ndef roc_curve(truth_labels, predicted_probs):\n    thresholds = [0.1 * i for i in range(11)]\n    tprs, fprs = [], []\n    for threshold in thresholds:\n        tp = fp = tn = fn = 0  # initialize confusion matrix counts\n        # for each prediction\n        for i in range(len(truth_labels)):\n            # calculate confusion matrix counts\n            if predicted_probs[i] &gt;= threshold:\n                if truth_labels[i] == 1:\n                    tp += 1\n                else:\n                    fp += 1\n            else:\n                if truth_labels[i] == 1:\n                    fn += 1\n                else:\n                    tn += 1\n        # track the TPR and FPR for this threshold\n        tprs.append(tp / (tp + fn))  # True Positive Rate (TPR)\n        fprs.append(fp / (tn + fp))  # False Positive Rate (FPR)\n    return tprs, fprs\n\n\ntprs, fprs = roc_curve(truth_labels, predicted_probs)\nplt.plot(fprs, tprs, marker='.')\nplt.show()\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#how-to-calculate-the-auc-area-under-curve","title":"How to calculate the AUC (area under curve)?","text":"<p>As simple as it could be, AUC is the area under the ROC curve, which can quantitatively reflect the model performance based on ROC curve. It is simple to calculate AUC along RUC x-axis. Due to that ROC curve tends to be above y=x, AUC values are usually between 0.5-1. The bigger the AUC is, the better the classifier is as the more likely that the classifier put the true positive samples at the front. </p> <pre><code>def compute_aucroc(tprs, fprs):\n    aucroc = 0\n    for i in range(1, len(tprs)):\n        aucroc += 0.5 * abs(fprs[i] - fprs[i - 1]) * (tprs[i] + tprs[i - 1])\n    return aucroc\n\naucroc = compute_aucroc(tprs, fprs)\nprint(f\"The AUC-ROC value is: {aucroc}\")  # The AUC-ROC value is: 0.9827272125066242\n</code></pre> <p>We have touched on the P-R curve for evaluating classification or sort algorithms. Comparing with P-R curve, there is one important character of ROC curve, which is that when positive / negative sample distribution change significant, the ROC curve shape could stay rather consistently whereas the P-R curve shape would be changing. This makes the ROC curve to mitigate the interference from diverse test sets and could more objectively evaluate the algorithm. In reality, when positive counts are much less than the negative counts, when switching dataset the data can be of big change, so a stable and robust evaluation would be important. Hence, usually ROC can be used in more variety of scenarios and could be utilized in sort / recommendation / ads. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#what-each-curve-shows","title":"What each curve shows","text":"<ul> <li>ROC: y = True Positive Rate (recall), x = False Positive Rate. \"How well do I separate positives from negatives overall?\"     _\"If I take the items my model flags as positive, how many are actually positive?</li> <li>PR: y = Precision, x = Recall. \"When I go after positives, how clean are my catches?\"     _\"As I move the threshold, how well do I trade off catching positives vs accidentally flagging negatives?\"</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#when-to-use-which_1","title":"When to use which","text":"<ul> <li>Use PR (Precision &amp; Recall) when positives are rare or review capacity is limited.     Examples: fraud, disease screening, anomaly detection, search/retrieval, human-in-the-loop queues.     Why: PR focuses on the quality of retrieved positives. Baseline matters: random AUPRC prevalence (e.g., 1% positives random AUPRC = 0.01).</li> <li>Use ROC when classes are roughly balanced or you care about both error types evenly.     Examples: many general classifiers, spam vs ham with moderate prevalence, A/B classifiers in balanced datasets.     Why: ROC is insensitive to class imbalance and summarizes ranking quality across thresholds. Random AUC-ROC = 0.5.</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#intuition-about-imbalance","title":"Intuition about imbalance","text":"<ul> <li>With 1,000,000 negatives and 1,000 positives, an FPR of 0.5% looks tiny on ROC, but it's 5,000 false alarms precision will be poor.     PR makes this visible; ROC can look deceptively great.</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#how-to-choose-in-practice","title":"How to choose in practice","text":"<ul> <li>Rare positives or ops-constrained? Prefer PR (and report Precision/Recall at your operating threshold or Precision@k).</li> <li>Balanced costs/distribution? ROC is fine (and stable).</li> <li>Comparing models broadly? Report both AUC-ROC and AUPRC, plus a point metric at your intended threshold.</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#reading-the-curves","title":"Reading the curves","text":"<ul> <li>ROC: closer to top-left is better; AUC near 1 is strong.</li> <li>PR: higher curve is better; sustaining high precision as recall grows is ideal.</li> <li>Curves can cross. Pick the model that\u00e2\u20ac\u2122s better in the recall region you care about (e.g., recall \u00e2\u2030\u00a5 0.9). Consider partial AUC (ROC) or AUPRC over a recall range.</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#what-to-report-good-default","title":"What to report (good default)","text":"<ul> <li>AUPRC + AUC-ROC (global picture)</li> <li>(Precision, Recall) (or \\(F_\\beta\\)) at the chosen threshold</li> <li>If capacity-limited: Precision@k (and expected volume flagged)</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#use-of-cosine-distance","title":"Use of cosine distance","text":"<p>How to evaluate the distance between samples can also define the optimization target and training method. In ML problems, we usually take the features to be of vector form, so when analyzing the two feature vector similarity, we could use cosine similarity. The cosine similarity can range from -1 to 1, where when two vectors are exactly the same, the cosine similarity becomes 1. Hence, when looking at distances, 1-cosine similarity becomes the cosine distance. Overall, the cosine distance is [0,2] and the same two vectors their cosine distance becomes 0.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#definition-of-euclidean-distance-cosine-distance","title":"Definition of Euclidean Distance &amp; Cosine Distance","text":"<p>Euclidean Distance For vectors \\(x,y\\in\\mathbb{R}^d\\):</p> \\[d_{\\text{Euc}}(x,y)=\\sqrt{\\sum_{i=1}^{d}(x_i-y_i)^2} \\in [0,\\infty) \\] <ul> <li>What it measures: straight-line (L2) distance in space.</li> <li>Sensitive to scale/magnitude: doubling a vector doubles distances.</li> <li>Squared form: sometimes use \\(\\|x-y\\|^2\\) (no square root) for speed/convexity.~</li> </ul> <p>Cosine Distance Start with cosine similarity:</p> \\[\\text{cos\\_sim}(x,y)=\\frac{x\\cdot y}{\\|x\\|\\,\\|y\\|}\\in[-1,1]\\] <p>Cosine distance (common definition): \\(\\(d_{\\text{cos}}(x,y)=1-\\text{cos\\_sim}(x,y)\\in[0,2]\\)\\)</p> <ul> <li>What it measures: difference in direction (angle) only.</li> <li>Scale-invariant: multiplying a vector by a positive constant doesn\u00e2\u20ac\u2122t change it.</li> </ul> <p>Overall, on unit vectors, Euclidean and cosine distances are monotonic transforms. Also, on a unit circle, one would see: \\(\\(\\|A-B\\|=\\sqrt{2(1-cos(A,B))}\\)\\) - When to use which     - Use Euclidean when magnitude matters (e.g., real spatial distances, continuous features with meaningful scales).     - Use Cosine when orientation matters more than length (e.g., text/image embeddings, TF-IDF vectors).</p>"},{"location":"ml_fundamentals/ML_fundamentals/#when-to-use-cosine-similarity-but-not-euclidean-distance","title":"When to use cosine similarity but not Euclidean distance?","text":"<p>For two vectors A and B, when their cosine similarity are being defined as \\(cos(A,B)=\\frac{A\\cdot B}{\\|A\\|_2 \\|B\\|_2}\\) , i.e. the cosine of angle between two vectors, we thus measure the angular distance between them, rather than the absolute magnitude, with the range being [-1,1]. When a pair of text being very different in length, but with similar content, if using Euclidean distance, one can think their distance being pretty big whereas when using cosine similarity, the angle between the two can be rather small, hence giving high similarity. In text, visual, video, image industries, when the objective has high dimensions, cosine can still retain its character of [-1,1] whereas the Euclidean distance number can be really big. </p> <p>Overall, Euclidean distance measures the absolute difference between numbers whereas the cosine distance measures the directional relative difference.  </p> <p>Taking an example of measuring user behavior of watching two different TV series:     - user A's watch vector = (0,1)     - user B's watch vector = (1,0) It is obvious that the cosine distance between the two can be really big whereas their Euclidean distance is small. </p> <p>When measuring user A/B preference, we focus more on relative difference, hence we should be using the cosine distance whereas when we are analyzing user login frequency or activity, we should be using Euclidean distance instead as the cosine distance would think two users of vector (1,10) and (10,100) are more similar to each other.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#is-cosine-distance-a-strictly-defined-distance","title":"Is cosine distance a strictly defined distance?","text":"<p>No, it is not strictly defined as it satisfies the Non-negativity &amp; identity (strictness), symmetry but does not satisfy the triangle inequality. A use case of this question is that when reading the word vector of <code>comedy</code> and <code>funny</code> and also <code>happy</code> and <code>funny</code>, their cosine distance is &lt; 0.3, whereas the distance between <code>comedy</code>and <code>happy</code> is 0.7. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#model-evaluation-methods","title":"Model Evaluation Methods","text":"<p>In ML algorithm design, we usually split the samples into training and test data set, where the training set is used to training the model and the test set is used to evaluate the model. In sample split and model evaluation process, we could use different sampling or evaluation methods. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#in-model-evaluation-what-are-the-main-evaluation-methods-what-are-their-pros-and-cons","title":"In model evaluation, what are the main evaluation methods, what are their pros and cons?","text":"<ul> <li>Holdout evaluation: Holdout evaluation is the easiest way as it randomly split the original sample set into training and evaluation. For example, for a clickthrough rate prediction algorithm, we split the samples into 70 - 30%. We use the 70% data for model training and the 30% for evaluation, including ROC curve, accuracy calculation and recall rate metric evaluation. This has significant downside: the calculated final evaluation metric is highly correlated with the original data split. In order to eliminate this randomness, researchers started to use the \"cross validation\" idea.</li> <li>cross-validation: k-fold cross validation would always split the data set into k different sets that are of same counts. The method goes through all the k sample sets and always use the current subset as the evaluation set whereas the other ones are training set. usually we use k = 10.</li> <li>Bootstrap: <ul> <li>Make a fake test set by randomly picking the same number of rows from your real test set with replacement (so rows can repeat and some are left out).<ul> <li>Suppose the test set has n rows.</li> <li>Pick n indices at random WITH replacement from <code>0..n-1</code>. (Duplicates allowed; some rows won't be picked.)</li> <li>Those picked rows form one fake test set. </li> </ul> </li> <li>On that fake set, compute your metric (accuracy, F1, AUC, RMSE whatever you care about).</li> <li>Repeat steps 1-2 a lot (like 1,000 times).</li> <li>Now you have 1,000 metric values.<ul> <li>The average is your central estimate.</li> <li>The middle 95% range (ignore the lowest 2.5% and highest 2.5%) is your 95% confidence interval. As \\(n\\) gets large, about 36.8% of items are not in the set (never selected) and 63.2% appear at least once. This is the source of the bootstrap terminology</li> </ul> </li> </ul> </li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#hyperparameter-tuning","title":"Hyperparameter tuning","text":"<p>For a lot of algorithm engineers, hyperparameter tuning can be really of headache, as there is no other way other than empirically tune the parameters to a reasonable range, while it is really important for the algorithm to be effective.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#what-are-some-of-the-common-ways-of-hyperparameter-tuning","title":"What are some of the common ways of hyperparameter tuning?","text":"<ul> <li>grid search: Exhaustive on a small, low-dimensional space. Deterministic but expensive; scales poorly. In reality, it tend to be used as a bigger search space and larger step size to find the possible range of optimal results, then to shrink the search space and find more accurate optimal solution.</li> <li>random search: Sample hyperparams at random (often log-uniform for learning rates). Much better than grid when only a few dims matter but cannot guarantee for a optimal solution.</li> <li>Bayesian optimization: Model config -&gt;score to pick promising next trials. Unlike random/grid search do not learn from past trials, BO uses what you have learned so far to place the next (expensive) trial where it is most likely to pay off.</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#overfit-and-underfit","title":"Overfit and Underfit","text":"<p>This section tells how one could efficiently recognize overfit and underfit scenarios and do model improvements based on what has been identified. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#what-is-overfit-and-what-is-underfit","title":"What is overfit and what is underfit?","text":"<ul> <li>Overfit means that a model can be overfitting on its training data whereas on the test and new data sets, it's performing worse. </li> <li>Underfit means that the model is performing illy on both training and test data sets. </li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#what-are-some-ways-to-mitigate-the-overfit-and-underfit","title":"What are some ways to mitigate the overfit and underfit?","text":"<ul> <li>Avoid overfit: <ul> <li>Data: obtaining more data is one primitive way of solving overfit problem as more data can help the model to learn more efficient features to mitigate the impact from noise. Using rotation or expansion for image or GAN for getting more new training data.</li> <li>Model: one could use less complicated / complex model to avoid overfitting. For example, in NN one could reduce the number of layers or neurons in each layer; or in decision tree, one could reduce the depth of the tree or cut the tree.</li> <li>Regularization: one could use L2 regularization in model parameters to constraint the model. </li> <li>ensemble method: ensemble method is to integrate multiple models together to avoid a single model overfitting issue, such as bagging methods.</li> </ul> </li> <li>Avoid underfit:<ul> <li>add more features: when there is not enough features or the features are not relevant with the sample labels, there would be a underfit. We could dig into contextual features / ID features / combination of features to obtain better results. In deep learning, factor decomposition / gradient-boosted decision tree / deep-crossing can all be used for get more features.</li> <li>increase the complexity of model. </li> <li>decrease regularization parameters. </li> </ul> </li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#early-stoppings","title":"Early Stoppings","text":"<ul> <li>Early stopping watches validation loss/metric and halts training when it stops improving, and is a stopping rule driven by the validation metric\u2019s change, not a pre-fixed iteration count</li> <li>It reduces overfitting (lower variance) by not letting the model memorize noise; acts like implicit L2 regularization. Train while checking performance on a validation set. Whenever the validation score improves, remember those weights. If it doesn\u2019t improve for a while (patience), stop and roll back to the best checkpoint. This caps model complexity at the point where it generalized best, preventing the later epochs from fitting noise</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#l2-l1-regularization","title":"L2 / L1 Regularization","text":""},{"location":"ml_fundamentals/ML_fundamentals/#setup","title":"Setup","text":"<p>Model (no intercept for simplicity):</p> \\[\\hat y_i = w\\,x_i\\] <p>Data loss (sum of squared errors):</p> <p>\\(\\(\\sum_i (y_i - w x_i)^2\\)\\) L2-regularized loss (ridge): \\(\\(\\underbrace{\\sum_i (y_i - w x_i)^2}_{\\text{fit the data}} \\;+\\; \\underbrace{\\lambda\\, w^2}_{\\text{penalize big weights}}\\)\\) - \\(\\lambda&gt;0\\) controls the strength of the penalty (larger \\(\\lambda\\) stronger shrinkage). - In practice, we usually don't penalize the bias/intercept.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#how-l2-penalizes-the-parameter","title":"How L2 Penalizes the Parameter","text":"<p>Take derivative w.r.t. \\(w\\) and set to 0:</p> \\[\\frac{\\partial}{\\partial w}\\Big[\\sum_i (y_i - w x_i)^2 + \\lambda w^2\\Big] = -2\\sum_i x_i(y_i - w x_i) + 2\\lambda w = 0\\] <p>Rearrange: \\(\\(w\\big(\\sum_i x_i^2 + \\lambda\\big) = \\sum_i x_i y_i \\quad\\Rightarrow\\quad \\boxed{\\,w_{\\text{ridge}} = \\dfrac{\\sum_i x_i y_i}{\\sum_i x_i^2 + \\lambda}\\,}\\)\\) Compare to unregularized OLS: \\(\\(w_{\\text{OLS}} = \\dfrac{\\sum_i x_i y_i}{\\sum_i x_i^2}\\)\\) L2 adds \\(\\lambda\\) to the denominator and shrinks \\(w\\) toward 0.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#why-l2-decrease-variance-and-increase-bias","title":"Why L2 decrease variance and increase bias?","text":"<p>L2 regularization constrains how large the parameters can get. Constraining parameters makes the fitted function smoother/less wiggly, so predictions don\u2019t swing wildly when the training sample changes\u2014this cuts variance. The tradeoff is that the constrained model can\u2019t perfectly adapt to the true signal, so estimates are pulled toward zero (or toward simpler shapes), which introduces bias.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#tiny-numeric-example","title":"Tiny Numeric Example","text":"<p>Data: \\(x=[0,1,2,3]\\), \\(y=[0,1,2,60]\\) (last point is an outlier) - \\(\\sum x_i^2 = 14, \\sum x_i y_i = 185\\) Weights: - OLS (no L2): \\(185/14 \\approx 13.214\\) - L2, \\(\\lambda=10\\): \\(185/(14+10) = 185/24 \\approx 7.708185\\) - L2, \\(\\lambda=100\\): \\(185/(14+100) = 185/114 \\approx 1.623\\) As \\(\\lambda\\) grows, \\(w\\) is pulled toward 0, limiting the impact of the outlier.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#gradient-descent-view-weight-decay","title":"Gradient-Descent View (Weight Decay)","text":"<p>With learning rate \\(\\eta\\): \\(\\(w_{\\text{new}} = w_{\\text{old}} - \\eta\\Big(\\underbrace{-2\\sum_i x_i(y_i - w_{\\text{old}} x_i)}_{\\text{data gradient}} \\;+\\; \\underbrace{2\\lambda w_{\\text{old}}}_{\\text{L2 shrink}}\\Big)\\)\\)</p> <p>The \\(+2\\lambda w\\) term is the shrinkage that steadily decays weights.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#multi-feature-form-for-reference","title":"Multi-Feature Form (for reference)","text":"<p>For features \\(X\\in \\mathbb{R}^{n\\times d}\\), target \\(\\mathbf{y}\\):</p> \\[\\mathbf{w}_{\\text{ridge}} = (X^\\top X + \\lambda I)^{-1} X^\\top \\mathbf{y}\\]"},{"location":"ml_fundamentals/ML_fundamentals/#copy-paste-python","title":"Copy-Paste Python","text":"<pre><code>import numpy as np\n\nx = np.array([0,1,2,3], dtype=float)\ny = np.array([0,1,2,60], dtype=float)\n\nSxx = np.sum(x**2)\nSxy = np.sum(x*y)\n\ndef ridge_weight(lmbda):\n    return Sxy / (Sxx + lmbda)\n\nprint(\"w_OLS        =\", Sxy / Sxx)\nfor lmbda in [10, 100]:\n    print(f\"w_ridge\", ridge_weight(lmbda))\n</code></pre> <p>Notes - Standardize features before using L2/L1 (esp. linear/logistic). - Tune \\(\\lambda\\) via cross-validation. - Do not penalize the bias term.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#classical-algorithms","title":"Classical Algorithms","text":""},{"location":"ml_fundamentals/ML_fundamentals/#linear-regression","title":"Linear Regression","text":"<p>There are two central provinces in the world of regression: simple linear regression and multiple linear regression. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#formula-of-simple-linear-regression","title":"Formula of Simple Linear Regression","text":"<p>The formula of linear regression can be represented as \\(\\(y=c+m\\cdot x\\)\\) The formula revolves around minimizing residuals. Imagine residuals as the distance between the actual and predicted values of the dependent variable \\(y\\): \\(\\(m = \\frac{\\sum_{i=1}^N{(x_i-\\bar x)(y_i-\\bar y)}}{\\sum_{i=1}^N(x_i-\\bar x)^2}\\)\\) and the constant corresponds to \\(c=\\bar y - m \\cdot\\bar x\\). </p> <pre><code>import numpy as np\n\n# Step 1: Get the data set\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 5, 4, 5])\n\n# Step 2: Compute the mean of the X and y\nmean_x = np.mean(x)\nmean_y = np.mean(y)\n\n# Step 3: Calculate the coefficients\nm = np.sum((x - mean_x) * (y - mean_y)) / np.sum((x - mean_x) ** 2)\nc = mean_y - m * mean_x\n\n# Voila! We have our model\nprint(f\"Model: y = {c} + {m}*x\") \u00a0# Output: Model: y= 2.2 + 0.6*x\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#formula-of-multiple-linear-regression","title":"Formula of Multiple Linear Regression","text":"<p>For simple linear regression formula, we have \\(y=\\beta_0 + \\beta_1x\\), for multiple linear regression, we add multiple independent variables \\(x_1, x_2, ... , x_m\\). Suppose we had n data points, each with m features, then X would be like: \\(\\(\\mathbf{X}=\\begin{bmatrix}   1 &amp; x_{1,1} &amp; x_{1,2} &amp; ... &amp; x_{1,m} \\\\   1 &amp; x_{2,1} &amp; x_{2,2} &amp; ... &amp; x_{2,m} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_{n,1} &amp; x_{n,2} &amp; ... &amp; x_{n,m} \\\\ \\end{bmatrix} \\in \\mathbb{R^{n\\times (m+1)}}, \\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} \\in \\mathbb{R^{n\\times 1}}, \\mathbf{\\beta} = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_m \\end{bmatrix} \\in  \\mathbb{R^{(m+1)\\times 1}}\\)\\) Each row represents the m features for a single data point. The first column with \\(\\mathbf{1}\\)s are the bias / intercept of each equation. The normal equation would be of form \\(\\(\\beta = (X^T X)^{-1}X^Ty\\)\\) The predicted \\(\\hat y\\) values can be represented as \\(\\(\\hat y = (1 \\cdot \\beta_0)+(\\beta_1 \\cdot x_1) + (\\beta_2 \\cdot x_2) + \\dots + (\\beta_m \\cdot x_m)\\)\\) To calculate all the predictions at once, we take the dot product of \\(X\\) and \\(\\beta\\): $$\\mathbf{y} = \\begin{bmatrix} y_1 \\ y_2 \\ \\vdots \\ y_n \\end{bmatrix} = X\\cdot \\beta =\\begin{bmatrix} 1 &amp; x_{1,1} &amp; x_{1,2} &amp; ... &amp; x_{1,m} \\ 1 &amp; x_{2,1} &amp; x_{2,2} &amp; ... &amp; x_{2,m} \\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\ 1 &amp; x_{n,1} &amp; x_{n,2} &amp; ... &amp; x_{n,m} \\ \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\ \\beta_1 \\ \\vdots \\ \\beta_m \\end{bmatrix} $$</p>"},{"location":"ml_fundamentals/ML_fundamentals/#linear-regression-model-evaluation","title":"Linear Regression Model Evaluation","text":""},{"location":"ml_fundamentals/ML_fundamentals/#coefficient-of-determination-r2-score","title":"coefficient of determination (\\(R^2\\) score)","text":"<p>\\(\\(R^2=1-\\frac{SS_\\text{residuals}}{SS_\\text{total}} = 1 - \\frac{\\sum_{i=1}^n(y_i - \\hat y_i)^2}{\\sum_{i=1}^n(y_i - \\bar y_i)^2}\\)\\) Where \\(SS_\\text{residuals}\\) denotes the residual sum of squares for predictions and \\(SS_\\text{total}\\) denotes the total sum of squares from actual values. A higher R-squared value / closer to 1 indicates a good model fit.</p> <pre><code>import numpy as np\n# given data\nhousing_data = np.array(\\[\\[1800, 3\\], \\[2400, 4\\],\\[1416, 2\\], \\[3000, 5\\]\\])\nprices = np.array([350000, 475000, 230000, 640000])\n\n# adding 1s to our matrix\n# ones = np.ones(shape=(len(housing_data), 1))\n# X = np.append(ones, housing_data, axis=1)\nX = np.c_[np.ones((len(housing_data),1)),X] # add bias parameter to X\n\n# calculating coefficients\ncoefficients = np.linalg.inv(X.T @ X) @ X.T @ prices\n\n# predicting prices\npredicted_prices = X @ coefficients\n\n# calculating residuals\nresiduals = prices - predicted_prices\n\n# calculating total sum of squares\nsst = np.sum((prices - np.mean(prices)) ** 2)\n\n# calculating residual sum of squares\nssr = np.sum(residuals ** 2)\n\n# calculating R^2\nr2 = 1 - (ssr/sst)\n\nprint(\"Coefficients:\", coefficients)\nprint(\"Predicted prices:\", predicted_prices)\nprint(\"R^2:\", r2)\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#gradient-descent","title":"Gradient Descent","text":"<p>Gradient descent\u00a0is an iterative optimization algorithm for minimizing a function, usually a loss function, quantifying the disparity between predicted and actual results. The goal of gradient descent is to find the parameters that minimize the value of the loss function.</p> <p>Gradient descent derives its name from its working mechanism: taking\u00a0descents\u00a0along the\u00a0gradient. It operates in several iterative steps as follows:</p> <ol> <li>Choose random values for initial parameters.</li> <li>Calculate the cost (the difference between actual and predicted value).</li> <li>Compute the gradient (the steepest slope of the function around that point).</li> <li>Update the parameters using the gradient.</li> <li>Repeat steps 2 to 4 until we reach an acceptable error rate or exhaust the maximum iterations.</li> </ol> <p>A vital component of gradient descent is the learning rate, which determines the size of the descent towards the optimum solution.</p> <p>The first step is to calculate the cost function, which takes the form of \\(\\(J(X, y, \\theta) = \\frac{1}{m}\\sum_{i=1}^m(X\\cdot \\theta - y_i)^2\\)\\) where J is the cost, X is the data, y is the actual values and \\(\\theta\\) is the parameters, \\(m\\) is the length of \\(y\\). It is calculating the mean square error. </p> <pre><code>import numpy as np\n\ndef cost(X, y, theta):\n    m = len(y)\n    predictions = X @ theta\n    cost = (1/m) * np.sum((predictions - y) ** 2)\n    return cost\n</code></pre> <p>The second step is to compute the gradient descent function, which will be updated in the iterative loop: \\(\\(\\theta:=\\theta-\\alpha\\frac{1}{m}X^T\\cdot(X\\cdot \\theta - y)\\)\\) Here \\(\\alpha\\) is the learning rate, which determines the size of steps in the descent and \\(X^T\\) is the transpose of data, which should have been multiplied by 2 but as we take the derivative of the mean squared error we could also consider it to be included as part of the learning rate \\(\\alpha\\). </p> <pre><code>def gradient_descent(X, y, theta, alpha, threshold=0.01):\n\u00a0 \u00a0 m = len(y)\n\u00a0 \u00a0 cost_history = []\n\u00a0 \u00a0 prev_cost = float('inf')\n\u00a0 \u00a0 iterations = 0\n\u00a0 \u00a0 while True:\n\u00a0  \u00a0 \u00a0  prediction = X.dot(theta)\n\u00a0 \u00a0 \u00a0 \u00a0 theta = theta - (alpha / m) * X.T.dot(prediction - y)\n\u00a0 \u00a0 \u00a0 \u00a0 cost = (1/(2*m)) * np.sum((prediction - y) ** 2)\n\u00a0 \u00a0 \u00a0 \u00a0 cost_history.append(cost)\n\u00a0 \u00a0 \u00a0 \u00a0 if abs(prev_cost - cost) &lt; threshold:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 break\n\u00a0 \u00a0 \u00a0 \u00a0 prev_cost = cost\n\u00a0 \u00a0 \u00a0 \u00a0 iterations += 1\n\u00a0 \u00a0 return theta, cost_history, iterations\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#support-vector-machine-svm","title":"Support Vector Machine (SVM)","text":""},{"location":"ml_fundamentals/ML_fundamentals/#additional-resources","title":"Additional Resources","text":"<p>StatQuest Part1 SVM Main Idea StatQuest Part2 The Polynomial Kernel</p>"},{"location":"ml_fundamentals/ML_fundamentals/#main-idea-behind-svm","title":"Main Idea behind SVM","text":"<ul> <li> <p>Soft Margin Classifier (Support Vector Classifier)     When data are 3-dimensional, the Support Vector Classifier is a 2-dimensional plane in a 3-dimensional space. In mathematical world, a plane is a \"flat affine 2-dimensional subspace (hyperplane)\".</p> <p>But it only works well on data that are perfectly separated into two groups, when it comes down to data that are within certain range versus out-of-range, it cannot handle that well. - Support Vector Machine In order to make the mathematics possible, SVM use something called kernel functions to systematically find support vector classifiers in higher dimensions. - Kernel Functions When d = 1, the polynomial kernel computes the relationships between each pair of observations in 1-dimension, and these relationships are used to find a support vector classifier. In summary, the polynomial kernel systematically increases dimensions by setting d, the degree of the polynomial.  - Polynomial Kernel \\((a\\times b + r)^d\\) is the polynomial kernel format, where d sets the dimension of the kernel. Using \\((a\\times b + \\frac{1}{2})^2\\) as an example: \\(\\((a\\times b + \\frac{1}{2})^2 = (a\\times b + \\frac{1}{2})(a\\times b + \\frac{1}{2}) = ab + a^2b^2+\\frac{1}{4} = (a,a^2,\\frac{1}{2})\\cdot (b,b^2,\\frac{1}{2})\\)\\)     where \\((a,a^2,\\frac{1}{2})\\) and \\((b,b^2,\\frac{1}{2})\\) are the coordinates of the data points x-y-z dimensions. \\(r\\) and \\(d\\) are determined via cross validation. Once we determines the parameters, then we plug in all the pairs of data points and do the math to get the high-dimensional relationships. - Radial Function Kernel      Radial function kernel finds support vector classifiers in infinite dimensions but in one / two dimensional data, it behaves like weighted nearest neighborhood model.     The equation looks like this \\(e^{-\\gamma(a-b)^2}\\) where \\(a\\) and \\(b\\) are the x-axis coordinates of two different data points. \\(\\gamma\\) is the parameter that determines how much influence the pair of data points have on each other.</p> </li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#logistic-regression","title":"Logistic Regression","text":"<p>Logistic regression are the most widely used and most fundamental model that one could use in the ML industry. One should always understand the deduction of logistic regression and application of it, as it is used in medical diagnosis, credit evaluation, email junk categorization, etc. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#formulation-behind-logistic-regression","title":"Formulation behind Logistic Regression","text":"<p>Logistic Regression calculates a raw model output, then transforms it using the sigmoid function, mapping it to a range between 0 and 1, thus making it a probability. The sigmoid function can be defined as \\(S(x) = \\frac{1}{1+e^{-x}}\\). This can thus be implemented as:</p> <pre><code>def sigmoid(z):\n    return 1 / (1+np.exp(-z))\n</code></pre> <p>The mathematical form of logistic regression can be expressed as follows: \\(\\(P(Y=1|x) = \\frac{1}{1+e^{-(\\beta_0+\\beta_1x)}}\\)\\) where \\(P(Y=1|x)\\) is the probability of event \\(Y=1\\) given \\(x\\), \\(\\beta_0\\) and \\(\\beta_1\\) are parameters of the model, \\(x\\) is the input variable and \\(\\beta_0+\\beta_1x\\) is the linear combination of parameters and features. </p> <p>Log-Likelihood\u00a0in Logistic Regression plays a similar role to the\u00a0Least Squares method\u00a0in Linear Regression. A maximum likelihood estimation method estimates parameters that maximize the likelihood of making the observations we collected. In Logistic Regression, we seek to maximize the log-likelihood.</p> <p>The cost function for a single training instance in logistic regression can be expressed as \\(-[y\\log{(\\hat p)+(1-y)\\log{(1-\\hat p)}}]\\) where \\(\\hat p\\) denotes the predicted probability.</p> <pre><code>def cost_function(h, y): # h = sigmoid(z) where z = X @ theta\n    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n\ndef logistic_regression(X, y, num_iterations, learning_rate): \n    # Add intercept to X \n    intercept = np.ones((X.shape[0], 1)) \n    X = np.concatenate((intercept, X), axis=1) \n\n    # Weights initialization \n    theta = np.zeros(X.shape[1]) \n    for i in range(num_iterations): \n        z = np.dot(X, theta) \n        h = sigmoid(z) \n        gradient = np.dot(X.T, (h - y)) / y.size \n        theta -= learning_rate * gradient \n\n        z = np.dot(X, theta) \n        h = sigmoid(z) \n        loss = cost_function(h, y) \n\n        if i % 10000 == 0:\n            print(f'Loss: {loss}\\t') \n\n    return theta\n\ndef predict_prob(X, theta):\n    # Add intercept to X\n    intercept = np.ones((X.shape[0], 1))\n    X = np.concatenate((intercept, X), axis=1)\n    return sigmoid(np.dot(X, theta))\n\ndef predict(X, theta, threshold=0.5):\n    return predict_prob(X, theta) &gt;= threshold\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#what-is-the-difference-between-logistic-regression-and-linear-regression","title":"What is the difference between logistic regression and linear regression?","text":"<ul> <li>logistic regression is used for categorization whereas linear regression is used for regression problems. This is the most significant difference between the two. In logistic regression, when given x and hyperparameter \\(\\theta\\), we could get the expectation value of the \\(y\\) values to predict the categorization of the values. On the other hand, in linear regression, one is solving \\(y' = \\theta^Tx\\) , which is the approximate of the real relationship of \\(y = \\theta^Tx+\\epsilon\\) where \\(\\epsilon\\) corresponds to the system error.</li> <li>The actual logistic regression equation can be formulated via \\(\\log{\\frac{p}{1-p}}=\\theta^Tx\\), where \\(p=P(y=1|x)\\) , corresponding to given x the probability of y being positive. Thus the most important difference between logistic regression and linear regression would be that the logistic regression \\(y\\)s are discretized whereas the linear regression \\(y\\)s are continuous. When \\(x\\) and \\(\\theta\\) are given, logistic regression can also be seen as generalized linear models where \\(y\\) follows the binary distribution, whereas  when using least-squares for linear regression we view \\(y\\) follows the normal distribution. </li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#what-is-the-same-between-logistic-regression-and-linear-regression","title":"What is the same between logistic regression and linear regression?","text":"<ul> <li>They both used maximum likelihood estimation for modeling the training data. </li> <li>They both could use gradient descent for getting the hyperparameters, and it is also a common strategy that all the supervised learning methods use.</li> </ul>"},{"location":"ml_fundamentals/ML_fundamentals/#the-general-logic-behind-regression","title":"The general logic behind regression","text":"<pre><code>Inputs: X (N\u00d7d), y (N,), model \u2208 {\"linear\",\"logistic\"}\nHyperparams: learning_rate (lr), lambda (L2), max_iters, tol, patience\nPrep:\n  Xb = concat([ones(N,1), X])        # add bias column\n  w = zeros(d+1)                     # includes bias at index 0\n  mask = [0, 1, 1, ..., 1]           # no L2 on bias\n\nFor t in 1..max_iters:\n  z = Xb @ w\n  if model == \"linear\":\n      pred = z\n      loss_data = (1/(2N)) * sum((pred - y)^2)\n  else:  # logistic\n      pred = sigmoid(z)              # clip to [eps, 1-eps] for stability\n      loss_data = -(1/N) * sum(y*log(pred) + (1-y)*log(1-pred))\n\n  loss = loss_data + lambda * sum((w*mask)^2)\n  grad = (1/N) * (Xb.T @ (pred - y)) + 2*lambda*(w*mask)\n  w = w - learning_rate * grad\n  if norm(grad) &lt; tol or early_stopping_on_val(loss): break\n\nReturn w\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#note-for-binomial-distribution-vs-normal-distribution","title":"Note for binomial distribution vs normal distribution","text":"<p>The main difference between a binomial distribution and a normal distribution lies in the type of data they describe:\u00a0==binomial distributions deal with discrete data from a fixed number of trials, while normal distributions describe continuous data that tends to cluster around a mean==.\u00a0Binomial distributions are characterized by a fixed number of trials, each with two possible outcomes (success or failure), while normal distributions are continuous, symmetric, and have a bell-shaped curve.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#decision-tree","title":"Decision Tree","text":"<p>Decision trees are often used in marketing or biomedical industries as the tree-based structure is similar to sales or diagnosis use cases. Hence, when using decision tree as key component of the ensemble method, one could get random forest or gradient boosted decision tree models, etc. Fully grown decision tree model has its characters of being direct and easy-to-explain, hence it would be also important as the ensemble method section prerequisites. Overall, the formulation of decision tree involves 1) feature selection, 2) tree construction and 3) tree pruning. </p>"},{"location":"ml_fundamentals/ML_fundamentals/#structuring-a-decision-tree","title":"Structuring a decision tree","text":"<p>A decision tree starts at a node, called root, which breaks down into branches. Each branch then further splits into more branches, building a hierarchical network. The final branches with no more splits are referred to as leaf nodes.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#understanding-gini-index","title":"Understanding Gini Index","text":"<p>Note: A more clear explanation can be found in videos: - StatQuest: Decision and Classification Trees, Clearly Explained!!! - StatQuest: Decision Trees, Part 2 - Feature Selection and Missing Data - StatQuest: How to Prune Regression Trees, Clearly Explained!!! A Gini Index endeavors to quantify the disorder within these groups. A greater Gini Index score signifies more disorder. The formula of Gini Index can be represented as \\(G = 1-\\sum_{i=1}^n p_i^2\\) where \\(G\\) is the Gini index or coefficient, \\(p_i\\) is the proportion of individuals in the \\(i\\)th group, and the sum is taken over \\(n\\) groups. Gini index is used to describe the data purity, which has similar concept with information entropy.  \\(\\(\\text{Gini}(D) = 1 - \\sum_{k=1}^n(\\frac{C_k}{D})^2\\)\\) \\(\\(\\text{Gini}(D|A) = \\sum_{i=1}^n\\frac{|D_i|}{|D|}\\text{Gini}(D_i)\\)\\) Now let's use an example to better understand how to compute Gini index:</p> Loves Popcorn Loves Soda Age like movie A Y Y 7 N B Y N 12 N C N Y 18 Y D N Y 35 Y E Y Y 38 Y F Y N 50 N G N N 83 N Loves Popcorn Loves Soda <p>All the three leaves except for the fourth one are called impure leaves, where the fourth one is called a pure leaf node. As both leaf nodes from <code>loves Popcorn</code> are impure but there is only one node from <code>Loves Soda</code> being impure, it means that the <code>Loves Soda</code> does a better job predicting who will and will not the movie. </p> \\[\\text{Gini Impurity for a leaf} = 1 - (\\text{the probability of \"Yes\"}) ^ 2 - (\\text{the probability of \"No\"}) ^ 2\\] \\[\\text{Gini Impurity (Loves Movie | Loves Popcorn)} = 1 - (\\frac{1}{1+3})^2 - (\\frac{3}{1+3})^2 = 0.375\\] \\[\\text{Gini Impurity (Loves Movie | Hates Popcorn)} = 1 - (\\frac{2}{1+2})^2 - (\\frac{1}{1+2})^2 = 0.444\\] \\[\\text{Total Gini Impurity} = \\text{weighted avg of Gini for the leaves} = (\\frac{1+3}{1+3+2+1})\\cdot(0.375)+\\frac{3}{4+3}(0.444)\\]"},{"location":"ml_fundamentals/ML_fundamentals/#implementation-of-decision-tree-splits","title":"Implementation of decision tree splits","text":"<pre><code>groups = [\n    \\[\\['Red'], ['Blue'], ['Red'\\]\\],\n    \\[\\['Blue'], ['Red'], ['Blue'], ['Blue'\\]\\],\n]\nclasses = ['Red', 'Blue']\n\nn_instances = float(sum([len(group) for group in groups]))\n\ndef gini_index(groups, classes):\n    n_instances = float(sum([len(group) for group in groups]))\n    gini = 0.0\n    for group in groups:\n        size = len(group)\n        if size == 0:\n            continue\n        score = 0.0\n        for class_val in classes:\n            p = [row[-1] for row in group].count(class_val) / size\n            score += p * p gini # summed probabilities, 1 - score = gini impurity\n        gini += (1.0 - score) * (size / n_instances)\n    return gini\n\ndef test_split(index, value, dataset):\n    left, right = list(), list()\n    for row in dataset:\n        if row[index] &lt; value:\n            left.append(row)\n        else:\n            right.append(row)\n    return left, right\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#information-gain","title":"Information Gain","text":""},{"location":"ml_fundamentals/ML_fundamentals/#max-information-gain","title":"Max Information Gain","text":"<p>For a sample set D, there are K categories, the empirical entropy for this set D can be expressed as \\(H(D) = -\\sum_{k=1}^K \\frac{|C_k|}{D}\\log_2\\frac{C_k}{D}\\).</p>"},{"location":"ml_fundamentals/ML_fundamentals/#unsupervised-learnings","title":"Unsupervised Learnings","text":"<p>We may encounter problems such that providing the machine a tons of feature data and looking for the machine to learn the pattern or structure from the data, for example the video platforms would like to categorize the users from their activities for different recommendation strategies, or looking for relationship between whether the video playing smooth or not vs their relationship with user unsubscribe. These problems are called \"unsupervised learnings\", which does not like the supervised learnings where we expect to see outputs or predictions. The unsupervised learning inputs does not contain label information, instead it needs to dig into the internal data relationship from the algorithm model. There are two main categories of the unsupervised learnings: data clustering or feature variable correlation (using correlation analysis for relationships between variables). </p>"},{"location":"ml_fundamentals/ML_fundamentals/#k-nearest-neighbors-k-nn-algorithm","title":"K-Nearest Neighbors (k-NN) Algorithm","text":"<p>The kNN algorithm works on a basic principle: a data point is likely to be in the same category as the data points it is closest to. Note that choosing 'k' significantly impacts our model. A low 'k' might capture more noise in the data, whereas a high 'k' is computationally expensive.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#euclidean-distance-calculation","title":"Euclidean Distance Calculation","text":"<p>In k-NN, classification is determined by weighing the distance between data points. Euclidean distance is a frequently used metric that calculates the shortest straight-line distance \\(\\sqrt{(x_1-x_2)^2 + (y_1 - y_2)^2}\\) between two data points \\((x_1, y_1)\\) and \\((x_2, y_2)\\) in a Euclidean space. </p> <pre><code>import math\n\n# The 'euclidean_distance' function computes the Euclidean distance between two points\ndef euclidean_distance(point1, point2):\n    squares = [(p - q) ** 2 for p, q in zip(point1, point2)] # Calculate squared distance for each dimension\n    return math.sqrt(sum(squares)) # Return the square root of the sum of squares\n\n# Test it\npoint1 = (1, 2) # The coordinates of the first point\npoint2 = (4, 6) # The coordinates of the second point\nprint(euclidean_distance(point1, point2)) # 5.0\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#actual-knn-algorithm","title":"Actual KNN Algorithm","text":"<pre><code>from collections import Counter\nimport numpy as np\n\ndef k_nearest_neighbors(data, query, k, distance_fn):\n\u00a0 \u00a0 neighbor_distances_and_indices = []\n\u00a0 \u00a0 # Compute distance from each training data point\n\u00a0 \u00a0 for idx, label in enumerate(data):\n\u00a0 \u00a0 \u00a0 \u00a0 distance = euclidean_distance(label[0], query)\n\u00a0 \u00a0 neighbor_distances_and_indices.append((distance, idx))\n\u00a0 \u00a0 # Sort array by distance\n\u00a0 \u00a0 sorted_neighbor_distances_and_indices = sorted(neighbor_distances_and_indices)\n\u00a0 \u00a0 # Select k closest data points\n\u00a0 \u00a0 k_nearest_distances_and_indices = sorted_neighbor_distances_and_indices[:k]\n\u00a0 \u00a0 # Obtain class labels for those k data points\n\u00a0 \u00a0 k_nearest_labels = [data[i][1] for distance, i in k_nearest_distances_and_indices]\n\u00a0 \u00a0 # Majority vote\n\u00a0 \u00a0 most_common = Counter(k_nearest_labels).most_common(1)\n\u00a0 \u00a0 return most_common[0][0] # Return the label of the class that receives the majority vote\n\ndef euclidean_distance(point1, point2):\n\u00a0 \u00a0 distance = sum((p - q) ** 2 for p, q in zip(point1, point2))\n\u00a0 \u00a0 return np.sqrt(distance)\n\u00a0 \u00a0 \ndef mannhattan_distance(point1, point2):\n\u00a0 \u00a0 return np.sum(np.abs(p - q) for p, q in zip(point1, point2))\n\ndata = [\n\u00a0 \u00a0 ((2, 3), 0),\n\u00a0 \u00a0 ((5, 4), 0),\n\u00a0 \u00a0 ((9, 6), 1),\n\u00a0 \u00a0 ((4, 7), 0),\n\u00a0 \u00a0 ((8, 1), 1),\n\u00a0 \u00a0 ((7, 2), 1)\n]\nquery = (7,6)\nk=2\n\nclass_label = k_nearest_neighbors(data, query, k, distance_fn)\nprint(class_label)\n</code></pre>"},{"location":"ml_fundamentals/ML_fundamentals/#k-means-clustering","title":"K-means Clustering","text":"<p>Algorithms such as SVM, logistic regression, decision trees are more for the categorization, i.e. based on the known labelled samples, classifiers are training so that it could apply the same logic on unlabeled samples. Unlike the classification problems, clustering is directly categorize the samples without any previously known labelling. </p> <p>Classification belongs to supervised learning whereas clustering is a type of unsupervised learning algorithm. K-means clustering, as one type of the most basic and fundamental clustering algorithm, has the main idea of iteratively finding the way of cutting the space into K clusters, so that the loss function is the lowest. The loss function can be defined as the sum of squared error distance of each sample from their clustered centers: \\(\\(J(c,\\mu) = \\sum_{i=1}^M ||x_i - \\mu_{c_i}||^2\\)\\) where \\(x_i\\) represents the samples, \\(c_i\\) represents the cluster that \\(x_i\\) belongs to, \\(mu_{c_i}\\) corresponds to the center of the cluster that \\(x_i\\)'s located in and \\(M\\) is the total number of samples.</p>"},{"location":"ml_fundamentals/ML_fundamentals/#k-means-clustering-algorithm-in-steps","title":"K-means clustering algorithm in steps","text":"<p>The goal of K-means clustering is to categorize the dataset of interest into K-clusters, and also provides the cluster center corresponding to each data points: 1. data engineering and cleaning: normalization and outlier removal. 2. randomly pick K-cluster centers, labelled as \\(\\mu_1^{(0)}, \\mu_2^{(0)}, ..., \\mu_K^{(0)}\\)  3. define the loss function to be \\(J(c,\\mu) = \\min_{\\mu} \\min_{c} \\sum_{i=1}^M ||x_i - \\mu_{c_i}||^2\\)  4. iterate through the process below by t times, where t denotes the number of iterations:     1. for every sample \\(x_i\\), categorize it to the cluster that has shortest distance \\(\\(c_i^{(t)} \\leftarrow {\\arg\\min}_k ||x_i - \\mu_k^{(t)}||^2\\)\\)     2. for every cluster k, recalculate the center: \\(\\(\\mu_k^{(t+1)}\\leftarrow {\\arg\\min}_\\mu \\sum_{i:c_i^{(t)}=k} ||x_i - \\mu||^2\\)\\) <pre><code># k-Means algorithm\ndef k_means(data, centers, k):\n    while True:\n        clusters = [[] for _ in range(k)] \n\n        # Assign data points to the closest center\n        for point in data:\n            distances = [distance(point, center) for center in centers]\n            index = distances.index(min(distances)) \n            clusters[index].append(point)\n\n        # Update centers to be the mean of points in a cluster\n        new_centers = []\n        for cluster in clusters:\n            center = (sum([point[0] for point in cluster])/len(cluster), \n                      sum([point[1] for point in cluster])/len(cluster)) \n            new_centers.append(center)\n\n        # Break loop if centers don't change significantly\n        if max([distance(new, old) for new, old in zip(new_centers, centers)]) &lt; 0.0001:\n            break\n        else:\n            centers = new_centers\n    return clusters, centers\n</code></pre></p> <ol> <li> <p>need to work on the definition of this and learn more about information theory\u00a0\u21a9</p> </li> <li> <p>Please read through the recommendation system based on matrix vectorization to get a better idea on how recommenders are built based on SVD and matrices\u00a0\u21a9</p> </li> </ol>"},{"location":"ml_fundamentals/classical_algorithms/decision_trees/","title":"Decision Tree","text":"<p>Decision trees are often used in marketing or biomedical industries as the tree-based structure is similar to sales or diagnosis use cases. Hence, when using decision tree as key component of the ensemble method, one could get random forest or gradient boosted decision tree models, etc. Fully grown decision tree model has its characters of being direct and easy-to-explain, hence it would be also important as the ensemble method section prerequisites. Overall, the formulation of decision tree involves 1) feature selection, 2) tree construction and 3) tree pruning.</p>"},{"location":"ml_fundamentals/classical_algorithms/decision_trees/#structuring-a-decision-tree","title":"Structuring a Decision Tree","text":"<p>A decision tree starts at a node, called root, which breaks down into branches. Each branch then further splits into more branches, building a hierarchical network. The final branches with no more splits are referred to as leaf nodes.</p>"},{"location":"ml_fundamentals/classical_algorithms/decision_trees/#understanding-gini-index","title":"Understanding Gini Index","text":"<p>Note: A more clear explanation can be found in videos: - StatQuest: Decision and Classification Trees, Clearly Explained!!! - StatQuest: Decision Trees, Part 2 - Feature Selection and Missing Data - StatQuest: How to Prune Regression Trees, Clearly Explained!!!</p> <p>A Gini Index endeavors to quantify the disorder within these groups. A greater Gini Index score signifies more disorder. The formula of Gini Index can be represented as \\(G = 1-\\sum_{i=1}^n p_i^2\\) where \\(G\\) is the Gini index or coefficient, \\(p_i\\) is the proportion of individuals in the \\(i\\)th group, and the sum is taken over \\(n\\) groups. Gini index is used to describe the data purity, which has similar concept with information entropy.</p> \\[\\text{Gini}(D) = 1 - \\sum_{k=1}^n(\\frac{C_k}{D})^2\\] \\[\\text{Gini}(D|A) = \\sum_{i=1}^n\\frac{|D_i|}{|D|}\\text{Gini}(D_i)\\] <p>Now let's use an example to better understand how to compute Gini index:</p> Loves Popcorn Loves Soda Age like movie A Y Y 7 N B Y N 12 N C N Y 18 Y D N Y 35 Y E Y Y 38 Y F Y N 50 N G N N 83 N Loves Popcorn Loves Soda <p>All the three leaves except for the fourth one are called impure leaves, where the fourth one is called a pure leaf node. As both leaf nodes from <code>loves Popcorn</code> are impure but there is only one node from <code>Loves Soda</code> being impure, it means that the <code>Loves Soda</code> does a better job predicting who will and will not the movie.</p> \\[\\text{Gini Impurity for a leaf} = 1 - (\\text{the probability of \"Yes\"}) ^ 2 - (\\text{the probability of \"No\"}) ^ 2\\] \\[\\text{Gini Impurity (Loves Movie | Loves Popcorn)} = 1 - (\\frac{1}{1+3})^2 - (\\frac{3}{1+3})^2 = 0.375\\] \\[\\text{Gini Impurity (Loves Movie | Hates Popcorn)} = 1 - (\\frac{2}{1+2})^2 - (\\frac{1}{1+2})^2 = 0.444\\] \\[\\text{Total Gini Impurity} = \\text{weighted avg of Gini for the leaves} = (\\frac{1+3}{1+3+2+1})\\cdot(0.375)+\\frac{3}{4+3}(0.444)\\]"},{"location":"ml_fundamentals/classical_algorithms/decision_trees/#implementation-of-decision-tree-splits","title":"Implementation of Decision Tree Splits","text":"<pre><code>groups = [\n    \\[\\[['Red'], ['Blue'], ['Red']\\],\n    \\[\\[['Blue'], ['Red'], ['Blue'], ['Blue']\\],\n]\nclasses = ['Red', 'Blue']\n\nn_instances = float(sum([len(group) for group in groups]))\n\ndef gini_index(groups, classes):\n    n_instances = float(sum([len(group) for group in groups]))\n    gini = 0.0\n    for group in groups:\n        size = len(group)\n        if size == 0:\n            continue\n        score = 0.0\n        for class_val in classes:\n            p = [row[-1] for row in group].count(class_val) / size\n            score += p * p  # summed probabilities, 1 - score = gini impurity\n        gini += (1.0 - score) * (size / n_instances)\n    return gini\n\ndef test_split(index, value, dataset):\n    left, right = list(), list()\n    for row in dataset:\n        if row[index] &lt; value:\n            left.append(row)\n        else:\n            right.append(row)\n    return left, right\n</code></pre>"},{"location":"ml_fundamentals/classical_algorithms/decision_trees/#information-gain","title":"Information Gain","text":""},{"location":"ml_fundamentals/classical_algorithms/decision_trees/#max-information-gain","title":"Max Information Gain","text":"<p>For a sample set D, there are K categories, the empirical entropy for this set D can be expressed as \\(H(D) = -\\sum_{k=1}^K \\frac{|C_k|}{D}\\log_2\\frac{C_k}{D}\\).</p>"},{"location":"ml_fundamentals/classical_algorithms/decision_trees/#related-topics","title":"Related Topics","text":"<ul> <li>Linear Regression - Alternative regression algorithm</li> <li>Model Evaluation - Evaluating decision trees</li> <li>Feature Engineering - How decision trees handle different data types</li> </ul>"},{"location":"ml_fundamentals/classical_algorithms/linear_regression/","title":"Linear Regression","text":"<p>There are two central provinces in the world of regression: simple linear regression and multiple linear regression.</p>"},{"location":"ml_fundamentals/classical_algorithms/linear_regression/#formula-of-simple-linear-regression","title":"Formula of Simple Linear Regression","text":"<p>The formula of linear regression can be represented as \\(\\(y=c+m\\cdot x\\)\\)</p> <p>The formula revolves around minimizing residuals. Imagine residuals as the distance between the actual and predicted values of the dependent variable \\(y\\):</p> \\[m = \\frac{\\sum_{i=1}^N{(x_i-\\bar x)(y_i-\\bar y)}}{\\sum_{i=1}^N(x_i-\\bar x)^2}\\] <p>and the constant corresponds to \\(c=\\bar y - m \\cdot\\bar x\\).</p> <pre><code>import numpy as np\n\n# Step 1: Get the data set\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 5, 4, 5])\n\n# Step 2: Compute the mean of the X and y\nmean_x = np.mean(x)\nmean_y = np.mean(y)\n\n# Step 3: Calculate the coefficients\nm = np.sum((x - mean_x) * (y - mean_y)) / np.sum((x - mean_x) ** 2)\nc = mean_y - m * mean_x\n\n# Voila! We have our model\nprint(f\"Model: y = {c} + {m}*x\")  # Output: Model: y= 2.2 + 0.6*x\n</code></pre>"},{"location":"ml_fundamentals/classical_algorithms/linear_regression/#formula-of-multiple-linear-regression","title":"Formula of Multiple Linear Regression","text":"<p>For simple linear regression formula, we have \\(y=\\beta_0 + \\beta_1x\\), for multiple linear regression, we add multiple independent variables \\(x_1, x_2, ... , x_m\\). Suppose we had n data points, each with m features, then X would be like:</p> \\[\\mathbf{X}=\\begin{bmatrix}   1 &amp; x_{1,1} &amp; x_{1,2} &amp; ... &amp; x_{1,m} \\\\   1 &amp; x_{2,1} &amp; x_{2,2} &amp; ... &amp; x_{2,m} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_{n,1} &amp; x_{n,2} &amp; ... &amp; x_{n,m} \\\\ \\end{bmatrix} \\in \\mathbb{R^{n\\times (m+1)}}, \\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} \\in \\mathbb{R^{n\\times 1}}, \\mathbf{\\beta} = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_m \\end{bmatrix} \\in  \\mathbb{R^{(m+1)\\times 1}}\\] <p>Each row represents the m features for a single data point. The first column with \\(\\mathbf{1}\\)s are the bias / intercept of each equation. The normal equation would be of form</p> \\[\\beta = (X^T X)^{-1}X^Ty\\] <p>The predicted \\(\\hat y\\) values can be represented as</p> \\[\\hat y = (1 \\cdot \\beta_0)+(\\beta_1 \\cdot x_1) + (\\beta_2 \\cdot x_2) + \\dots + (\\beta_m \\cdot x_m)\\] <p>To calculate all the predictions at once, we take the dot product of \\(X\\) and \\(\\beta\\):</p> \\[\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} = X\\cdot \\beta =\\begin{bmatrix}   1 &amp; x_{1,1} &amp; x_{1,2} &amp; ... &amp; x_{1,m} \\\\   1 &amp; x_{2,1} &amp; x_{2,2} &amp; ... &amp; x_{2,m} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_{n,1} &amp; x_{n,2} &amp; ... &amp; x_{n,m} \\\\ \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_m \\end{bmatrix}\\]"},{"location":"ml_fundamentals/classical_algorithms/linear_regression/#linear-regression-model-evaluation","title":"Linear Regression Model Evaluation","text":""},{"location":"ml_fundamentals/classical_algorithms/linear_regression/#coefficient-of-determination-r2-score","title":"Coefficient of Determination (\\(R^2\\) Score)","text":"\\[R^2=1-\\frac{SS_\\text{residuals}}{SS_\\text{total}} = 1 - \\frac{\\sum_{i=1}^n(y_i - \\hat y_i)^2}{\\sum_{i=1}^n(y_i - \\bar y_i)^2}\\] <p>Where \\(SS_\\text{residuals}\\) denotes the residual sum of squares for predictions and \\(SS_\\text{total}\\) denotes the total sum of squares from actual values. A higher R-squared value / closer to 1 indicates a good model fit.</p> <pre><code>import numpy as np\n# given data\nhousing_data = np.array(\\[\\[[1800, 3], [2400, 4], [1416, 2], [3000, 5]\\])\nprices = np.array([350000, 475000, 230000, 640000])\n\n# adding 1s to our matrix\n# ones = np.ones(shape=(len(housing_data), 1))\n# X = np.append(ones, housing_data, axis=1)\nX = np.c_[np.ones((len(housing_data),1)),X] # add bias parameter to X\n\n# calculating coefficients\ncoefficients = np.linalg.inv(X.T @ X) @ X.T @ prices\n\n# predicting prices\npredicted_prices = X @ coefficients\n\n# calculating residuals\nresiduals = prices - predicted_prices\n\n# calculating total sum of squares\nsst = np.sum((prices - np.mean(prices)) ** 2)\n\n# calculating residual sum of squares\nssr = np.sum(residuals ** 2)\n\n# calculating R^2\nr2 = 1 - (ssr/sst)\n\nprint(\"Coefficients:\", coefficients)\nprint(\"Predicted prices:\", predicted_prices)\nprint(\"R^2:\", r2)\n</code></pre>"},{"location":"ml_fundamentals/classical_algorithms/linear_regression/#gradient-descent","title":"Gradient Descent","text":"<p>Gradient descent is an iterative optimization algorithm for minimizing a function, usually a loss function, quantifying the disparity between predicted and actual results. The goal of gradient descent is to find the parameters that minimize the value of the loss function.</p> <p>Gradient descent derives its name from its working mechanism: taking descents along the gradient. It operates in several iterative steps as follows:</p> <ol> <li>Choose random values for initial parameters.</li> <li>Calculate the cost (the difference between actual and predicted value).</li> <li>Compute the gradient (the steepest slope of the function around that point).</li> <li>Update the parameters using the gradient.</li> <li>Repeat steps 2 to 4 until we reach an acceptable error rate or exhaust the maximum iterations.</li> </ol> <p>A vital component of gradient descent is the learning rate, which determines the size of the descent towards the optimum solution.</p> <p>The first step is to calculate the cost function, which takes the form of \\(\\(J(X, y, \\theta) = \\frac{1}{m}\\sum_{i=1}^m(X\\cdot \\theta - y_i)^2\\)\\) where J is the cost, X is the data, y is the actual values and \\(\\theta\\) is the parameters, \\(m\\) is the length of \\(y\\). It is calculating the mean square error.</p> <pre><code>import numpy as np\n\ndef cost(X, y, theta):\n    m = len(y)\n    predictions = X @ theta\n    cost = (1/m) * np.sum((predictions - y) ** 2)\n    return cost\n</code></pre> <p>The second step is to compute the gradient descent function, which will be updated in the iterative loop:</p> \\[\\theta:=\\theta-\\alpha\\frac{1}{m}X^T\\cdot(X\\cdot \\theta - y)\\] <p>Here \\(\\alpha\\) is the learning rate, which determines the size of steps in the descent and \\(X^T\\) is the transpose of data, which should have been multiplied by 2 but as we take the derivative of the mean squared error we could also consider it to be included as part of the learning rate \\(\\alpha\\).</p> <pre><code>def gradient_descent(X, y, theta, alpha, threshold=0.01):\n    m = len(y)\n    cost_history = []\n    prev_cost = float('inf')\n    iterations = 0\n    while True:\n        prediction = X.dot(theta)\n        theta = theta - (alpha / m) * X.T.dot(prediction - y)\n        cost = (1/(2*m)) * np.sum((prediction - y) ** 2)\n        cost_history.append(cost)\n        if abs(prev_cost - cost) &lt; threshold:\n            break\n        prev_cost = cost\n        iterations += 1\n    return theta, cost_history, iterations\n</code></pre>"},{"location":"ml_fundamentals/classical_algorithms/linear_regression/#related-topics","title":"Related Topics","text":"<ul> <li>Decision Trees - Alternative regression algorithm</li> <li>Model Evaluation - Evaluating regression models</li> <li>Regularization - Regularizing linear regression</li> </ul>"},{"location":"ml_fundamentals/classical_algorithms/logistic_regression/","title":"Logistic Regression","text":"<p>Logistic regression is the most widely used and most fundamental model that one could use in the ML industry. One should always understand the deduction of logistic regression and application of it, as it is used in medical diagnosis, credit evaluation, email junk categorization, etc.</p>"},{"location":"ml_fundamentals/classical_algorithms/logistic_regression/#formulation-behind-logistic-regression","title":"Formulation behind Logistic Regression","text":"<p>Logistic Regression calculates a raw model output, then transforms it using the sigmoid function, mapping it to a range between 0 and 1, thus making it a probability. The sigmoid function can be defined as \\(S(x) = \\frac{1}{1+e^{-x}}\\). This can thus be implemented as:</p> <pre><code>def sigmoid(z):\n    return 1 / (1+np.exp(-z))\n</code></pre> <p>The mathematical form of logistic regression can be expressed as follows: \\(\\(P(Y=1|x) = \\frac{1}{1+e^{-(\\beta_0+\\beta_1x)}}\\)\\) where \\(P(Y=1|x)\\) is the probability of event \\(Y=1\\) given \\(x\\), \\(\\beta_0\\) and \\(\\beta_1\\) are parameters of the model, \\(x\\) is the input variable and \\(\\beta_0+\\beta_1x\\) is the linear combination of parameters and features.</p> <p>Log-Likelihood in Logistic Regression plays a similar role to the Least Squares method in Linear Regression. A maximum likelihood estimation method estimates parameters that maximize the likelihood of making the observations we collected. In Logistic Regression, we seek to maximize the log-likelihood.</p> <p>The cost function for a single training instance in logistic regression can be expressed as \\(-[y\\log{(\\hat p)+(1-y)\\log{(1-\\hat p)}}]\\) where \\(\\hat p\\) denotes the predicted probability.</p> <pre><code>def cost_function(h, y): # h = sigmoid(z) where z = X @ theta\n    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n\ndef logistic_regression(X, y, num_iterations, learning_rate): \n    # Add intercept to X \n    intercept = np.ones((X.shape[0], 1)) \n    X = np.concatenate((intercept, X), axis=1) \n\n    # Weights initialization \n    theta = np.zeros(X.shape[1]) \n    for i in range(num_iterations): \n        z = np.dot(X, theta) \n        h = sigmoid(z) \n        gradient = np.dot(X.T, (h - y)) / y.size \n        theta -= learning_rate * gradient \n\n        z = np.dot(X, theta) \n        h = sigmoid(z) \n        loss = cost_function(h, y) \n\n        if i % 10000 == 0:\n            print(f'Loss: {loss}\\t') \n\n    return theta\n\ndef predict_prob(X, theta):\n    # Add intercept to X\n    intercept = np.ones((X.shape[0], 1))\n    X = np.concatenate((intercept, X), axis=1)\n    return sigmoid(np.dot(X, theta))\n\ndef predict(X, theta, threshold=0.5):\n    return predict_prob(X, theta) &gt;= threshold\n</code></pre>"},{"location":"ml_fundamentals/classical_algorithms/logistic_regression/#differences-between-logistic-and-linear-regression","title":"Differences Between Logistic and Linear Regression","text":""},{"location":"ml_fundamentals/classical_algorithms/logistic_regression/#key-differences","title":"Key Differences","text":"<ul> <li> <p>logistic regression is used for categorization whereas linear regression is used for regression problems. This is the most significant difference between the two. In logistic regression, when given x and hyperparameter \\(\\theta\\), we could get the expectation value of the \\(y\\) values to predict the categorization of the values. On the other hand, in linear regression, one is solving \\(y' = \\theta^Tx\\), which is the approximate of the real relationship of \\(y = \\theta^Tx+\\epsilon\\) where \\(\\epsilon\\) corresponds to the system error.</p> </li> <li> <p>The actual logistic regression equation can be formulated via \\(\\log{\\frac{p}{1-p}}=\\theta^Tx\\), where \\(p=P(y=1|x)\\), corresponding to given x the probability of y being positive. Thus the most important difference between logistic regression and linear regression would be that the logistic regression \\(y\\)s are discretized whereas the linear regression \\(y\\)s are continuous. When \\(x\\) and \\(\\theta\\) are given, logistic regression can also be seen as generalized linear models where \\(y\\) follows the binary distribution, whereas when using least-squares for linear regression we view \\(y\\) follows the normal distribution.</p> </li> </ul>"},{"location":"ml_fundamentals/classical_algorithms/logistic_regression/#similarities","title":"Similarities","text":"<ul> <li>They both used maximum likelihood estimation for modeling the training data.</li> <li>They both could use gradient descent for getting the hyperparameters, and it is also a common strategy that all the supervised learning methods use.</li> </ul>"},{"location":"ml_fundamentals/classical_algorithms/logistic_regression/#general-logic-behind-regression","title":"General Logic Behind Regression","text":"<pre><code>Inputs: X (N\u00d7d), y (N,), model \u2208 {\"linear\",\"logistic\"}\nHyperparams: learning_rate (lr), lambda (L2), max_iters, tol, patience\nPrep:\n  Xb = concat([ones(N,1), X])        # add bias column\n  w = zeros(d+1)                     # includes bias at index 0\n  mask = [0, 1, 1, ..., 1]           # no L2 on bias\n\nFor t in 1..max_iters:\n  z = Xb @ w\n  if model == \"linear\":\n      pred = z\n      loss_data = (1/(2N)) * sum((pred - y)^2)\n  else:  # logistic\n      pred = sigmoid(z)              # clip to [eps, 1-eps] for stability\n      loss_data = -(1/N) * sum(y*log(pred) + (1-y)*log(1-pred))\n\n  loss = loss_data + lambda * sum((w*mask)^2)\n  grad = (1/N) * (Xb.T @ (pred - y)) + 2*lambda*(w*mask)\n  w = w - learning_rate * grad\n  if norm(grad) &lt; tol or early_stopping_on_val(loss): break\n\nReturn w\n</code></pre>"},{"location":"ml_fundamentals/classical_algorithms/logistic_regression/#binomial-vs-normal-distribution","title":"Binomial vs Normal Distribution","text":"<p>The main difference between a binomial distribution and a normal distribution lies in the type of data they describe: binomial distributions deal with discrete data from a fixed number of trials, while normal distributions describe continuous data that tends to cluster around a mean. Binomial distributions are characterized by a fixed number of trials, each with two possible outcomes (success or failure), while normal distributions are continuous, symmetric, and have a bell-shaped curve.</p>"},{"location":"ml_fundamentals/classical_algorithms/logistic_regression/#related-topics","title":"Related Topics","text":"<ul> <li>Linear Regression - Understanding the differences and similarities</li> <li>Decision Trees - Alternative classification algorithm</li> <li>Model Evaluation - Evaluating classification performance</li> <li>Regularization - Regularizing logistic regression</li> </ul>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/","title":"Categorical Feature Encoding","text":""},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#understanding-categorical-features","title":"Understanding Categorical Features","text":"<p>Categorical features include data like male/female, blood type (A,B,AB,O), and other variables that can only select values from a finite set of choices. Categorical features are originally input as strings.</p> <p>Important Note: While decision trees and some other models can directly take in strings, for logistic regression or SVM models, categorical features need to be translated to numerical form to work properly.</p>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#encoding-methods","title":"Encoding Methods","text":""},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#1-ordinal-encoding","title":"1. Ordinal Encoding","text":"<p>Use Case: Treats data that has ordinal sequence (e.g., high &gt; middle &gt; low)</p> <p>Method: Assigns numerical IDs that retain the high-to-low relationship</p> <p>Example: - High \u2192 3 - Middle \u2192 2 - Low \u2192 1</p> <p>Characteristics: - Preserves ordinal relationships - Simple and interpretable - Assumes meaningful order exists</p> <pre><code>from sklearn.preprocessing import OrdinalEncoder\n\n# Example data\ncategories = \\[\\[['high'], ['low'], ['middle'], ['high'], ['low']\\]\n\n# Create encoder\nencoder = OrdinalEncoder(categories=\\[\\[['low', 'middle', 'high']\\]\\])\n\n# Fit and transform\nencoded = encoder.fit_transform(categories)\nprint(encoded)  # \\[\\[[2], [0], [1], [2], [0]\\]\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#2-one-hot-encoding","title":"2. One-Hot Encoding","text":"<p>Use Case: Treats features that do not have ordinal relationships (e.g., blood type)</p> <p>Method: Creates binary vectors for each category</p> <p>Example for Blood Type: - Type A \u2192 [1, 0, 0, 0] - Type B \u2192 [0, 1, 0, 0] - Type AB \u2192 [0, 0, 1, 0] - Type O \u2192 [0, 0, 0, 1]</p> <p>Characteristics: - No ordinal relationship assumed - Creates sparse vectors - Increases dimensionality significantly</p> <p>Challenges: 1. High-dimensional features can be difficult in:    - K-nearest neighbors: Distance between high-dimensional vectors is hard to measure    - Logistic regression: Parameters increase with higher dimensions, causing overfitting    - Clustering: Only some dimensions may be helpful</p> <ol> <li>Sparse vectors for saving space</li> </ol> <pre><code>import pandas as pd\n\n# Example data\ndata = pd.DataFrame({'blood_type': ['A', 'B', 'AB', 'O', 'A']})\n\n# One-hot encoding\none_hot = pd.get_dummies(data, columns=['blood_type'])\nprint(one_hot)\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#3-binary-encoding","title":"3. Binary Encoding","text":"<p>Use Case: Alternative to one-hot encoding for space efficiency</p> <p>Method: Uses binary representation to do a hash mapping on the original category ID</p> <p>Characteristics: - Saves space compared to one-hot encoding - Usually fewer dimensions - Maintains some category information</p> <pre><code>import category_encoders as ce\n\n# Example data\ndata = pd.DataFrame({'category': ['A', 'B', 'C', 'D', 'A']})\n\n# Binary encoding\nencoder = ce.BinaryEncoder(cols=['category'])\nbinary_encoded = encoder.fit_transform(data)\nprint(binary_encoded)\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#advanced-encoding-techniques","title":"Advanced Encoding Techniques","text":""},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#target-encoding-mean-encoding","title":"Target Encoding (Mean Encoding)","text":"<p>Method: Replaces categories with the mean of the target variable for that category</p> <p>Advantages: - Captures relationship with target - Reduces dimensionality - Handles high-cardinality features</p> <p>Disadvantages: - Risk of overfitting - Requires careful cross-validation</p> <pre><code>from category_encoders import TargetEncoder\n\n# Example with target variable\nX = pd.DataFrame({'category': ['A', 'B', 'A', 'C', 'B']})\ny = pd.Series([1, 0, 1, 0, 1])\n\n# Target encoding\nencoder = TargetEncoder(cols=['category'])\nencoded = encoder.fit_transform(X, y)\nprint(encoded)\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#hash-encoding","title":"Hash Encoding","text":"<p>Method: Uses hash functions to map categories to a fixed number of features</p> <p>Advantages: - Handles high-cardinality features - Fixed output dimensionality - Memory efficient</p> <p>Disadvantages: - Potential hash collisions - Less interpretable</p>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#best-practices","title":"Best Practices","text":""},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#when-to-use-each-method","title":"When to Use Each Method:","text":"<ol> <li>Ordinal Encoding:</li> <li>Clear ordinal relationship exists</li> <li>Categories have meaningful order</li> <li> <p>Tree-based models</p> </li> <li> <p>One-Hot Encoding:</p> </li> <li>No ordinal relationship</li> <li>Small number of categories (&lt; 10)</li> <li> <p>Linear models</p> </li> <li> <p>Binary Encoding:</p> </li> <li>Medium number of categories (10-100)</li> <li>Memory constraints</li> <li> <p>Want to reduce dimensionality</p> </li> <li> <p>Target Encoding:</p> </li> <li>High-cardinality features</li> <li>Clear relationship with target</li> <li>Proper cross-validation setup</li> </ol>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#implementation-guidelines","title":"Implementation Guidelines:","text":"<ol> <li>Handle missing values before encoding</li> <li>Fit encoders on training data only</li> <li>Apply same encoding to test data</li> <li>Consider feature interactions after encoding</li> <li>Monitor for overfitting with high-cardinality features</li> </ol>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#common-pitfalls","title":"Common Pitfalls:","text":"<ul> <li>Data leakage: Fitting encoders on test data</li> <li>Overfitting: Using target encoding without proper validation</li> <li>Dimensionality explosion: One-hot encoding high-cardinality features</li> <li>Losing information: Using ordinal encoding for non-ordinal data</li> </ul>"},{"location":"ml_fundamentals/feature_engineering/categorical_encoding/#related-topics","title":"Related Topics","text":"<ul> <li>Data Types &amp; Normalization - Understanding different data types</li> <li>Feature Crosses - Combining encoded features</li> <li>Model Evaluation - How encoding affects model performance</li> </ul>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/","title":"Data Types &amp; Normalization","text":""},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#data-types-in-machine-learning","title":"Data Types in Machine Learning","text":""},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#structured-vs-unstructured-data","title":"Structured vs Unstructured Data","text":"<p>Machine learning deals with two main types of data:</p>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#structured-tabular-data","title":"Structured / Tabular Data","text":"<ul> <li>Can be viewed as a data table from a relational database</li> <li>Every column has a clear definition</li> <li>Includes numerical and categorical data types</li> <li>Examples: CSV files, database tables, spreadsheets</li> </ul>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#unstructured-data","title":"Unstructured Data","text":"<ul> <li>Includes text, image, audio, video data</li> <li>Information cannot be easily represented as numerical values</li> <li>No clear categorical definition</li> <li>Size of data is not identical</li> <li>Examples: documents, images, audio recordings</li> </ul>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#feature-normalization","title":"Feature Normalization","text":""},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#why-normalize-numerical-features","title":"Why Normalize Numerical Features?","text":"<p>In order to eliminate the magnitude impact between features, we should always normalize the features that we use. This means uniformly normalizing all features to a similar range, which helps compare between different metrics.</p>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#types-of-normalization","title":"Types of Normalization","text":""},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#1-min-max-scaling","title":"1. Min-Max Scaling","text":"<p>Linearly changes the original data so that it can be projected to [0, 1] range. This is an equal ratio transformation of the original data:</p> \\[X_{\\text{norm}} = \\frac{X-X_{\\text{min}}}{X_{\\text{max}-X_{\\text{min}}}}\\] <p>Characteristics: - Scales data to a fixed range [0, 1] - Preserves zero entries in sparse data - Sensitive to outliers</p>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#2-z-score-normalization-standardization","title":"2. Z-Score Normalization (Standardization)","text":"<p>Projects the original data to a mean of 0 and variance = 1 distribution. If the original feature has mean \\(\\mu\\) and variance \\(\\sigma\\), the normalization equation is:</p> \\[Z = \\frac{x-\\mu}{\\sigma}\\] <p>Characteristics: - Centers data around mean = 0 - Scales to standard deviation = 1 - Less sensitive to outliers than min-max scaling - Assumes data follows normal distribution</p>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#when-to-use-normalization","title":"When to Use Normalization","text":""},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#sgd-based-models-require-normalization","title":"SGD-Based Models (Require Normalization)","text":"<ul> <li>Linear regression</li> <li>Logistic regression</li> <li>Support vector machines</li> <li>Neural networks</li> </ul> <p>Example: When two numerical features, \\(x_1\\) of range [0,10] and \\(x_2\\) of range [0,3], are not normalized, the  gradient descent would not be as efficient as when normalization is applied.</p>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#tree-based-models-dont-require-normalization","title":"Tree-Based Models (Don't Require Normalization)","text":"<ul> <li>Decision trees</li> <li>Random forests</li> <li>Gradient boosting</li> </ul> <p>Reason: Tree models split based on data and information gain ratio, which is not impacted by whether features have been normalized.</p>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#implementation-example","title":"Implementation Example","text":"<pre><code>import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\n# Sample data\ndata = np.array(\\[\\[[1, 2, 3], [4, 5, 6], [7, 8, 9]\\])\n\n# Min-Max Scaling\nminmax_scaler = MinMaxScaler()\nminmax_scaled = minmax_scaler.fit_transform(data)\n\n# Z-Score Normalization\nstandard_scaler = StandardScaler()\nstandard_scaled = standard_scaler.fit_transform(data)\n\nprint(\"Original data:\")\nprint(data)\nprint(\"\\nMin-Max scaled:\")\nprint(minmax_scaled)\nprint(\"\\nZ-Score normalized:\")\nprint(standard_scaled)\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#best-practices","title":"Best Practices","text":"<ol> <li>Fit scalers on training data only - Never fit on test data to avoid data leakage</li> <li>Apply same scaling to test data - Use the fitted scaler to transform test data</li> <li>Choose based on your model - Use standardization for linear models, min-max for neural networks</li> <li>Handle outliers - Consider robust scaling methods if outliers are present</li> <li>Preserve interpretability - Keep track of scaling parameters for inverse transformation</li> </ol>"},{"location":"ml_fundamentals/feature_engineering/data_types_and_normalization/#related-topics","title":"Related Topics","text":"<ul> <li>Categorical Encoding - How to handle categorical features</li> <li>Feature Crosses - Combining features for better performance</li> <li>Model Evaluation - How normalization affects model performance</li> </ul>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/","title":"Feature Crosses &amp; Dimensionality","text":""},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#what-are-feature-crosses","title":"What are Feature Crosses?","text":"<p>Feature crosses combine single features together via dot-product or inner-product to help represent nonlinear relationships. This is particularly useful when individual features don't capture complex interactions in the data.</p>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#high-dimensional-feature-crosses","title":"High-Dimensional Feature Crosses","text":""},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#the-problem","title":"The Problem","text":"<p>Using logistic regression as an example, when a dataset contains feature vector \\(X=(x_1, x_2, ..., x_k)\\), the model would have:</p> \\[Y = \\text{sigmoid}(\\sum_i \\sum_j w_{ij} \\langle x_i, x_j \\rangle)\\] <p>Where \\(w_{ij}\\) is of dimension \\(n_{x_i} \\cdot n_{x_j}\\). When \\(n_{x_i} \\times n_{x_j}\\) is huge (especially in use cases like website customers and number of goods), this creates an extremely high-dimensional problem.</p>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#the-solution-dimensionality-reduction","title":"The Solution: Dimensionality Reduction","text":"<p>One way to get around this is to use a k-dimensional low-dimension vector (k &lt;&lt; m, k &lt;&lt; n).</p> <p>Now, \\(w_{ij} = x_i' \\cdot x_j'\\) and the number of parameters to tune becomes \\(m \\times k + n \\times k\\).</p> <p>This can also be viewed as matrix factorization, which has been widely used in recommendation systems.</p>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#matrix-factorization-example","title":"Matrix Factorization Example","text":"<pre><code>import numpy as np\n\n# Original high-dimensional features\nn_users = 1000\nn_items = 5000\nk = 50  # Low-dimensional representation\n\n# Create low-dimensional embeddings\nuser_embeddings = np.random.randn(n_users, k)\nitem_embeddings = np.random.randn(n_items, k)\n\n# Instead of n_users * n_items parameters,\n# we now have n_users * k + n_items * k parameters\ntotal_params = n_users * k + n_items * k\nprint(f\"Parameters reduced from {n_users * n_items:,} to {total_params:,}\")\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#feature-cross-selection","title":"Feature Cross Selection","text":""},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#the-challenge","title":"The Challenge","text":"<p>In reality, we face a variety of high-dimensional features. A single feature cross of all different pairs would induce: 1. Too many parameters 2. Overfitting issues</p>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#effective-feature-combination-selection","title":"Effective Feature Combination Selection","text":"<p>We introduce feature cross selection based on decision tree models. Taking CTR (Click-Through Rate) prediction as an example:</p> <p>Input features: age, gender, user type (free vs paid), searched item type (skincare vs foods)</p> <p>Decision tree approach: 1. Make a decision tree from the original input and their labels 2. View the feature crosses from the tree 3. Extract meaningful feature combinations</p> <p>Example feature crosses from tree: 1. age + gender 2. age + searched item type 3. paid user + search item type 4. paid user + age</p>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#gradient-boosting-decision-trees-gbdt","title":"Gradient Boosting Decision Trees (GBDT)","text":"<p>How to best construct the decision trees?</p> <p>One can use Gradient Boosting Decision Trees (GBDT). The idea behind this is that before constructing a decision tree, we first calculate the error from the true value and iteratively construct the tree from the error.</p> <pre><code>from sklearn.ensemble import GradientBoostingRegressor\nimport pandas as pd\n\n# Example implementation\ndef extract_feature_crosses(X, y, n_estimators=100):\n    \"\"\"\n    Extract feature crosses using GBDT\n    \"\"\"\n    gbdt = GradientBoostingRegressor(n_estimators=n_estimators, max_depth=3)\n    gbdt.fit(X, y)\n\n    # Extract feature importance\n    feature_importance = gbdt.feature_importances_\n\n    # Get feature crosses from tree structure\n    feature_crosses = []\n    for tree in gbdt.estimators_:\n        # Extract decision paths and identify feature combinations\n        # This is a simplified version - actual implementation would be more complex\n        pass\n\n    return feature_crosses\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#implementation-strategies","title":"Implementation Strategies","text":""},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#1-manual-feature-engineering","title":"1. Manual Feature Engineering","text":"<pre><code>import pandas as pd\n\n# Create feature crosses manually\ndef create_feature_crosses(df):\n    # Age + Gender cross\n    df['age_gender'] = df['age'].astype(str) + '_' + df['gender']\n\n    # User type + Item type cross\n    df['user_item_cross'] = df['user_type'] + '_' + df['item_type']\n\n    return df\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#2-polynomial-features","title":"2. Polynomial Features","text":"<pre><code>from sklearn.preprocessing import PolynomialFeatures\n\n# Create polynomial features (degree 2)\npoly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\nX_poly = poly.fit_transform(X)\n\nprint(f\"Original features: {X.shape[1]}\")\nprint(f\"Polynomial features: {X_poly.shape[1]}\")\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#3-factorization-machines","title":"3. Factorization Machines","text":"<pre><code># Using a library like fastFM or similar\nfrom fastFM import als\n\n# Factorization Machine for feature interactions\nfm = als.FMRegression(n_iter=1000, init_stdev=0.1, rank=8, l2_reg_w=0.1, l2_reg_V=0.1)\nfm.fit(X_train, y_train)\n</code></pre>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#best-practices","title":"Best Practices","text":""},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#when-to-use-feature-crosses","title":"When to Use Feature Crosses:","text":"<ol> <li>Domain knowledge suggests interactions exist</li> <li>Linear models need to capture nonlinear relationships</li> <li>High-cardinality categorical features</li> <li>Recommendation systems and collaborative filtering</li> </ol>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#implementation-guidelines","title":"Implementation Guidelines:","text":"<ol> <li>Start with domain knowledge - Don't cross everything</li> <li>Use tree-based methods to identify important interactions</li> <li>Monitor for overfitting - Cross-validation is crucial</li> <li>Consider computational cost - High-dimensional crosses are expensive</li> <li>Use regularization - L1/L2 regularization helps with sparse crosses</li> </ol>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#common-pitfalls","title":"Common Pitfalls:","text":"<ul> <li>Curse of dimensionality - Too many crosses lead to sparse data</li> <li>Overfitting - Complex crosses without enough data</li> <li>Computational expense - High-dimensional crosses are slow</li> <li>Loss of interpretability - Complex crosses are hard to explain</li> </ul>"},{"location":"ml_fundamentals/feature_engineering/feature_crosses/#related-topics","title":"Related Topics","text":"<ul> <li>Data Types &amp; Normalization - Preparing features for crosses</li> <li>Categorical Encoding - Encoding categorical features for crosses</li> <li>Model Evaluation - Evaluating models with feature crosses</li> <li>Regularization - Regularizing high-dimensional feature crosses</li> </ul>"},{"location":"ml_fundamentals/model_evaluation/evaluation_methods/","title":"Model Evaluation Methods","text":""},{"location":"ml_fundamentals/model_evaluation/evaluation_methods/#overview","title":"Overview","text":"<p>In ML algorithm design, we usually split the samples into training and test data set, where the training set is used to training the model and the test set is used to evaluate the model. In sample split and model evaluation process, we could use different sampling or evaluation methods.</p>"},{"location":"ml_fundamentals/model_evaluation/evaluation_methods/#main-evaluation-methods","title":"Main Evaluation Methods","text":""},{"location":"ml_fundamentals/model_evaluation/evaluation_methods/#holdout-evaluation","title":"Holdout Evaluation","text":"<p>Holdout evaluation is the easiest way as it randomly split the original sample set into training and evaluation. For example, for a clickthrough rate prediction algorithm, we split the samples into 70 - 30%. We use the 70% data for model training and the 30% for evaluation, including ROC curve, accuracy calculation and recall rate metric evaluation.</p> <p>Significant downside: The calculated final evaluation metric is highly correlated with the original data split. In order to eliminate this randomness, researchers started to use the \"cross validation\" idea.</p>"},{"location":"ml_fundamentals/model_evaluation/evaluation_methods/#cross-validation","title":"Cross-Validation","text":"<p>k-fold cross validation would always split the data set into k different sets that are of same counts. The method goes through all the k sample sets and always use the current subset as the evaluation set whereas the other ones are training set. Usually we use k = 10.</p>"},{"location":"ml_fundamentals/model_evaluation/evaluation_methods/#bootstrap","title":"Bootstrap","text":"<ul> <li>Make a fake test set by randomly picking the same number of rows from your real test set with replacement (so rows can repeat and some are left out).</li> <li>Suppose the test set has n rows.</li> <li>Pick n indices at random WITH replacement from <code>0..n-1</code>. (Duplicates allowed; some rows won't be picked.)</li> <li>Those picked rows form one fake test set.</li> <li>On that fake set, compute your metric (accuracy, F1, AUC, RMSE whatever you care about).</li> <li>Repeat steps 1-2 a lot (like 1,000 times).</li> <li>Now you have 1,000 metric values.</li> <li>The average is your central estimate.</li> <li>The middle 95% range (ignore the lowest 2.5% and highest 2.5%) is your 95% confidence interval.</li> </ul> <p>As \\(n\\) gets large, about 36.8% of items are not in the set (never selected) and 63.2% appear at least once. This is the source of the bootstrap terminology.</p>"},{"location":"ml_fundamentals/model_evaluation/evaluation_methods/#related-topics","title":"Related Topics","text":"<ul> <li>Metrics &amp; Validation - Understanding evaluation metrics</li> <li>Hyperparameter Tuning - Using evaluation methods for tuning</li> <li>Feature Engineering - How evaluation affects feature selection</li> </ul>"},{"location":"ml_fundamentals/model_evaluation/hyperparameter_tuning/","title":"Hyperparameter Tuning","text":"<p>For a lot of algorithm engineers, hyperparameter tuning can be really of headache, as there is no other way other than empirically tune the parameters to a reasonable range, while it is really important for the algorithm to be effective.</p>"},{"location":"ml_fundamentals/model_evaluation/hyperparameter_tuning/#common-ways-of-hyperparameter-tuning","title":"Common Ways of Hyperparameter Tuning","text":""},{"location":"ml_fundamentals/model_evaluation/hyperparameter_tuning/#grid-search","title":"Grid Search","text":"<p>Exhaustive on a small, low-dimensional space. Deterministic but expensive; scales poorly. In reality, it tend to be used as a bigger search space and larger step size to find the possible range of optimal results, then to shrink the search space and find more accurate optimal solution.</p>"},{"location":"ml_fundamentals/model_evaluation/hyperparameter_tuning/#random-search","title":"Random Search","text":"<p>Sample hyperparams at random (often log-uniform for learning rates). Much better than grid when only a few dims matter but cannot guarantee for a optimal solution.</p>"},{"location":"ml_fundamentals/model_evaluation/hyperparameter_tuning/#bayesian-optimization","title":"Bayesian Optimization","text":"<p>Model config -&gt; score to pick promising next trials. Unlike random/grid search do not learn from past trials, BO uses what you have learned so far to place the next (expensive) trial where it is most likely to pay off.</p>"},{"location":"ml_fundamentals/model_evaluation/hyperparameter_tuning/#related-topics","title":"Related Topics","text":"<ul> <li>Evaluation Methods - Using evaluation methods for tuning</li> <li>Metrics &amp; Validation - Using metrics to guide tuning</li> <li>Regularization - Tuning regularization parameters</li> </ul>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/","title":"Evaluation Metrics and Their Limitations","text":"<p>When doing model evaluation, the classification / sort / regression problems seems to always use different metrics for evaluation.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#accuracy-and-its-limitations","title":"Accuracy and Its Limitations","text":"<p>The accuracy only measures the number of correct labels divided by the number of total labels. This can potentially lead to a issue when the number of labels are limited in the dataset. When negative samples composed 99% of the data, if every label is a negative one, we still get 99% accuracy. So, if we use more effective mean accuracy that quantifies the mean accuracy under each category, it would be a better metrics to work with.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#precision-recall-and-their-balance","title":"Precision &amp; Recall and Their Balance","text":""},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#concept-of-precision-recall","title":"Concept of Precision &amp; Recall","text":"<p>Now we need to introduce the concept of precision and recall.</p> <p>Precision cares about the correctness of positive predictions, whereas recall cares about coverage of actual positives. Precision and recall trade off via the decision threshold. In a binary classification problem:</p> \\[\\text{Precision} = \\frac{N_{\\text{true positive}}}{N_{\\text{true positive}} + N_{\\text{false positive}}} = \\frac{N_{\\text{true positive}}}{N_{\\text{positive predictions}}}\\] \\[\\text{Recall} = \\frac{N_{\\text{true positive}}}{N_{\\text{true positive}} + N_{\\text{false negative}}} = \\frac{N_{\\text{true positive}}}{N_{\\text{actual positives}}}\\] <p>The F1 score is their harmonic mean:</p> \\[\\text{F1} = \\frac{2(\\text{Precision})(\\text{Recall})}{\\text{Precision} + \\text{Recall}} = \\frac{2N_{\\text{true positive}}}{2N_{\\text{true positive}}+N_{\\text{false positive}}+N_{\\text{false negative}}}\\] <p>This value ranges from 0 to 1 and penalizes imbalance, thus when either precision or recall is low, F1 drops sharply. F1 should be used when false positives and false negatives matter about equally, especially with imbalanced classes.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#confusion-matrix-implementation","title":"Confusion Matrix Implementation","text":"<pre><code>import numpy as np\n\ntrue_labels = np.array([0, 0, 1, 1, 0, 1, 0, 1, 1, 1])\npredicted_labels = np.array([0, 1, 0, 1, 0, 1, 1, 1, 1, 0])\n\nTP = np.sum((predicted_labels == 1) &amp; (true_labels == 1))\nTN = np.sum((predicted_labels == 0) &amp; (true_labels == 0))\nFP = np.sum((predicted_labels == 1) &amp; (true_labels == 0))\nFN = np.sum((predicted_labels == 0) &amp; (true_labels == 1))\n\nprint(\"Confusion Matrix:\\n TP: \", TP, \"\\tFP: \", FP, \"\\n FN: \", FN, \"\\tTN: \", TN)\n\n'''Output:\nConfusion Matrix:\n TP:  4     FP:  2 \n FN:  2     TN:  2\n'''\n</code></pre>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#precision-recall-in-ranking-retrieval-variants","title":"Precision &amp; Recall in Ranking / Retrieval Variants","text":"<pre><code>def precision_at_k(ground_truth_set, ranked_list, k):\n    return len(set(ranked_list[:k]) &amp; ground_truth_set) / k\n</code></pre> <pre><code># when there are more than one query / user / example that we would like to test on our predictions, we use the weighted average of the precision_at_k.\ndef mean_precision_at_k(ground_truth_sets, ranked_lists, k):\n    # ground_truth_sets and ranked_lists are aligned lists\n    return sum(precision_at_k(g, r, k) for g, r in zip(ground_truth_sets, ranked_lists)) / len(ground_truth_sets)\n</code></pre> <ul> <li>Precision@k for one case \\(q\\) (one list).</li> <li>Mean Precision@k average of those values over all cases \\(q \\in Q\\).</li> </ul> <p>Example: when dealing with video vague search functionality, it seems that the search ranking model can return the top 5 precision pretty high, however, the user in reality still cannot find the videos they want, especially those unpopular ones. Where does this problem coming from?</p> <p>Root cause analysis: Coming back to the example above, the top 5 precision being really high, meaning that the model can get the true positive results on a pretty good level with a certain set of positive predictions; however, when it comes down to cases where users would like to find not so popular videos, the precision of ranks can be rather no so useful as the user is looking for not so well-defined labels, hence the good precision of popular videos would not be helpful for this case as model is not providing all the relevant videos to the user and this is a problem of not so good recall rate. Let's say for the top 5 results, the precision@5 to be 100%, meaning that the correctness of the positive results is pretty higher, however, the recall@5 can still be 5%, meaning that only predicted 5 true positives although there are 100 actual positives involved. When doing model evaluation, it means that we should be focusing on both precision and recall, and also using different top N values for observations.</p> <p>Hence, in general, when people evaluate the goodness of a sort algorithm, they also look at the P-R curve, where in this curve, the x-axis corresponds to recall rate whereas the y-axis corresponds to precision rate.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#use-of-p-r-curve-for-model-evaluation-and-threshold-choice","title":"Use of P-R Curve for Model Evaluation and Threshold Choice","text":"<p>Each data point on the curve corresponds to a precision-recall combination at a certain threshold for True samples of choice, for example 0.95 / 0.9, etc. The closer to the origin (0,0) point, the bigger the threshold is.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#how-to-pick-the-threshold-in-practice","title":"How to Pick the Threshold in Practice","text":"<ul> <li>Capacity-constrained: If reviewers can handle 300 cases/day, pick the smallest threshold that yields \u2248300 flags/day; report the resulting (Precision, Recall).</li> <li>Recall target: If policy demands \u226595% recall, choose the lowest threshold achieving that, then report precision (and expected review load).</li> <li>Cost-based: Minimize \\(\\text{Cost}_{\\text{false positives}}\\cdot{\\text{False Positives}}+\\text{Cost}_{\\text{false negatives}}\\cdot{\\text{False Negatives}}\\) over thresholds.</li> </ul> <p>Also report AUPRC to compare models independent of a single threshold (higher is better, especially with class imbalance).</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#root-mean-squared-errors-rmse","title":"Root-Mean Squared Errors (RMSE)","text":"\\[ RMSE = \\sqrt{\\frac{\\sum_{i=1}^{n}{(y_i - \\hat y_i)^2}}{n}} \\] <p>Root-mean squared error has long been used as the metric for evaluating the regression model.</p> <p>Example: as a streaming company, one would say that prediction of traffic for each series can be really important when it comes down to ads bidding and user expansion. One would like to use a regression model to predict the traffic trend of a certain series, but whatever regression model that one uses, the RMSE metric ends up being really high. But, in reality, the model 95% of the time predict error is less than 1%, with really good prediction results. What might be the reason of this extraordinarily good results?</p> <p>Root cause analysis: From what the example, says there are two possible ways for the RMSE to be ineffective: 1) n being really small hence at this moment, the calculated error cannot be measurable anymore, 2) all the errors between actual value and predicted value are over- / under-predicting that the summation at the end being really high, however, in reality it is not the case and 3) one outlier being really off when comparing with other data points, it is contaminating the RMSE to be really big. Coming back to the question, as 95% of the time to model has really good prediction error hence it means the other 5% of the time the model can be really off with big outliers and it could happen when a series with small traffic / newly come-out / newly accoladed could produce this big error.</p> <p>How to solve: 1) When we think these outliers are noises, then we need to filter them out at the early stage when doing data cleaning, 2) If we do not think they are noises, then we need to further improve the prediction capability of our algorithm so that we could somehow model the formation of these outliers. and 3) We could also use a better metric for the model evaluation. There are indeed better evaluation metrics that are of better robustness than RMSE, for example, Mean Absolute Percentage Error (MAPE):</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#mean-absolute-percentage-error","title":"Mean Absolute Percentage Error","text":"\\[MAPE = \\sum_{i=1}^n{|\\frac{(y_i - \\hat y_i)}{y_i}|\\cdot\\frac{100}{n}}\\] <p>When comparing with RMSE, MAPE normalizes the error rate of each data point to mitigate the outlier impact from the absolute error.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#roc-curves","title":"ROC Curves","text":"<p>Binary classifiers are the mostly used and applied classifier in the ML industry. There are a lot of different metrics that one could use for evaluate the binary classifiers, including precision, recall, F1 score and P-R curve. But these metrics are only reflecting one aspect of the model. Hence, ROC curves can be of really good use.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#what-is-a-roc-curve","title":"What is a ROC Curve","text":"<p>ROC curves are called receiver Operating Characteristic Curves, which established from the military field and are often used in the medical industry as well. This curve's x-axis is the false positive rate, whereas the y-axis is the true-positive rate.</p> \\[\\text{False Positive Rate} = \\frac{\\text{False Positive}}{\\text{Negative}}$$ $$\\text{True Positive Rate} = \\frac{\\text{True Positive}}{\\text{Positive}}\\] <p>Example: There are 10 patients, where in there are 3 positive cancer patients, and the rest are negative patients. The hospital decides to do diagnosis on these customers and figured that 2 are true positive cancer patients. In this case:</p> \\[\\text{False Positive Rate} = \\frac{\\text{False Positive}}{\\text{Negative}} = \\frac{1}{7}$$ $$\\text{True Positive Rate} = \\frac{\\text{True Positive}}{\\text{Positive}}=\\frac{2}{3}\\]"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#how-to-draw-a-roc-curve","title":"How to Draw a ROC Curve","text":"<ul> <li>What is needed</li> <li>True labels \\(y \\in \\{0,1\\}\\)</li> <li>A score for the positive class per item (probability or decision score).</li> </ul> Sample Number True Label Model Output Probability as Positive 1 Positive 0.9 2 Positive 0.8 3 Negative 0.7 <p>From this example, we could then plot out the true positive rate (TPR) as the x-axis and false positive rate (FPR) as the y-axis for the curve, hence getting the ROC curve. There is a more direct way to plot the ROC curve as well:</p> <ul> <li>Getting the number of Positive &amp; Negative samples, i.e. assuming number of positive samples to be P and negative to be N.</li> <li>Getting the x-axis labels to be the count of negative samples, and y-axis labels to be the count of positive samples, then use the model output probability to do sorting of the samples</li> <li>Now draw the ROC curve from origin, whenever seeing a positive sample to draw a vertical line segment of +1 increment on y-axis, whenever seeing a negative sample then we draw a horizontal line segment along the x-axis until we reach the final sample with curve ending at (1,1).</li> </ul> <pre><code>from matplotlib import pyplot as plt\nfrom numpy import random\n\ntruth_labels = [1 if random.rand() &gt; 0.6 else 0 for _ in range(500)]\n# we generate some random predictions that would normally be obtained from the model\n# If a predicted probability is higher than the threshold, it is considered to be a positive outcome \npredicted_probs = [max(0, min(1, random.normal(loc=label, scale=0.3))) for label in truth_labels]\n\ndef roc_curve(truth_labels, predicted_probs):\n    thresholds = [0.1 * i for i in range(11)]\n    tprs, fprs = [], []\n    for threshold in thresholds:\n        tp = fp = tn = fn = 0  # initialize confusion matrix counts\n        # for each prediction\n        for i in range(len(truth_labels)):\n            # calculate confusion matrix counts\n            if predicted_probs[i] &gt;= threshold:\n                if truth_labels[i] == 1:\n                    tp += 1\n                else:\n                    fp += 1\n            else:\n                if truth_labels[i] == 1:\n                    fn += 1\n                else:\n                    tn += 1\n        # track the TPR and FPR for this threshold\n        tprs.append(tp / (tp + fn))  # True Positive Rate (TPR)\n        fprs.append(fp / (tn + fp))  # False Positive Rate (FPR)\n    return tprs, fprs\n\ntprs, fprs = roc_curve(truth_labels, predicted_probs)\nplt.plot(fprs, tprs, marker='.')\nplt.show()\n</code></pre>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#how-to-calculate-the-auc-area-under-curve","title":"How to Calculate the AUC (Area Under Curve)?","text":"<p>As simple as it could be, AUC is the area under the ROC curve, which can quantitatively reflect the model performance based on ROC curve. It is simple to calculate AUC along ROC x-axis. Due to that ROC curve tends to be above y=x, AUC values are usually between 0.5-1. The bigger the AUC is, the better the classifier is as the more likely that the classifier put the true positive samples at the front.</p> <pre><code>def compute_aucroc(tprs, fprs):\n    aucroc = 0\n    for i in range(1, len(tprs)):\n        aucroc += 0.5 * abs(fprs[i] - fprs[i - 1]) * (tprs[i] + tprs[i - 1])\n    return aucroc\n\naucroc = compute_aucroc(tprs, fprs)\nprint(f\"The AUC-ROC value is: {aucroc}\")  # The AUC-ROC value is: 0.9827272125066242\n</code></pre> <p>We have touched on the P-R curve for evaluating classification or sort algorithms. Comparing with P-R curve, there is one important character of ROC curve, which is that when positive / negative sample distribution change significant, the ROC curve shape could stay rather consistently whereas the P-R curve shape would be changing. This makes the ROC curve to mitigate the interference from diverse test sets and could more objectively evaluate the algorithm. In reality, when positive counts are much less than the negative counts, when switching dataset the data can be of big change, so a stable and robust evaluation would be important. Hence, usually ROC can be used in more variety of scenarios and could be utilized in sort / recommendation / ads.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#use-of-cosine-distance","title":"Use of Cosine Distance","text":"<p>How to evaluate the distance between samples can also define the optimization target and training method. In ML problems, we usually take the features to be of vector form, so when analyzing the two feature vector similarity, we could use cosine similarity. The cosine similarity can range from -1 to 1, where when two vectors are exactly the same, the cosine similarity becomes 1. Hence, when looking at distances, 1-cosine similarity becomes the cosine distance. Overall, the cosine distance is [0,2] and the same two vectors their cosine distance becomes 0.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#definition-of-euclidean-distance-cosine-distance","title":"Definition of Euclidean Distance &amp; Cosine Distance","text":"<p>Euclidean Distance For vectors \\(x,y\\in\\mathbb{R}^d\\):</p> \\[d_{\\text{Euc}}(x,y)=\\sqrt{\\sum_{i=1}^{d}(x_i-y_i)^2} \\in [0,\\infty)\\] <ul> <li>What it measures: straight-line (L2) distance in space.</li> <li>Sensitive to scale/magnitude: doubling a vector doubles distances.</li> <li>Squared form: sometimes use \\(\\|x-y\\|^2\\) (no square root) for speed/convexity.</li> </ul> <p>Cosine Distance Start with cosine similarity:</p> \\[\\text{cos\\_sim}(x,y)=\\frac{x\\cdot y}{\\|x\\|\\,\\|y\\|}\\in[-1,1]\\] <p>Cosine distance (common definition): \\(\\(d_{\\text{cos}}(x,y)=1-\\text{cos\\_sim}(x,y)\\in[0,2]\\)\\)</p> <ul> <li>What it measures: difference in direction (angle) only.</li> <li>Scale-invariant: multiplying a vector by a positive constant doesn't change it.</li> </ul> <p>Overall, on unit vectors, Euclidean and cosine distances are monotonic transforms. Also, on a unit circle, one would see: \\(\\(\\|A-B\\|=\\sqrt{2(1-cos(A,B))}\\)\\)</p> <ul> <li>When to use which</li> <li>Use Euclidean when magnitude matters (e.g., real spatial distances, continuous features with meaningful scales).</li> <li>Use Cosine when orientation matters more than length (e.g., text/image embeddings, TF-IDF vectors).</li> </ul>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#when-to-use-cosine-similarity-but-not-euclidean-distance","title":"When to Use Cosine Similarity but Not Euclidean Distance?","text":"<p>For two vectors A and B, when their cosine similarity are being defined as \\(cos(A,B)=\\frac{A\\cdot B}{\\|A\\|_2 \\|B\\|_2}\\), i.e. the cosine of angle between two vectors, we thus measure the angular distance between them, rather than the absolute magnitude, with the range being [-1,1]. When a pair of text being very different in length, but with similar content, if using Euclidean distance, one can think their distance being pretty big whereas when using cosine similarity, the angle between the two can be rather small, hence giving high similarity. In text, visual, video, image industries, when the objective has high dimensions, cosine can still retain its character of [-1,1] whereas the Euclidean distance number can be really big.</p> <p>Overall, Euclidean distance measures the absolute difference between numbers whereas the cosine distance measures the directional relative difference.</p> <p>Taking an example of measuring user behavior of watching two different TV series: - user A's watch vector = (0,1) - user B's watch vector = (1,0)</p> <p>It is obvious that the cosine distance between the two can be really big whereas their Euclidean distance is small.</p> <p>When measuring user A/B preference, we focus more on relative difference, hence we should be using the cosine distance whereas when we are analyzing user login frequency or activity, we should be using Euclidean distance instead as the cosine distance would think two users of vector (1,10) and (10,100) are more similar to each other.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#is-cosine-distance-a-strictly-defined-distance","title":"Is Cosine Distance a Strictly Defined Distance?","text":"<p>No, it is not strictly defined as it satisfies the Non-negativity &amp; identity (strictness), symmetry but does not satisfy the triangle inequality. A use case of this question is that when reading the word vector of <code>comedy</code> and <code>funny</code> and also <code>happy</code> and <code>funny</code>, their cosine distance is &lt; 0.3, whereas the distance between <code>comedy</code> and <code>happy</code> is 0.7.</p>"},{"location":"ml_fundamentals/model_evaluation/metrics_and_validation/#related-topics","title":"Related Topics","text":"<ul> <li>Evaluation Methods - How to apply these metrics</li> <li>Hyperparameter Tuning - Using metrics for model selection</li> <li>Feature Engineering - How metrics affect feature selection</li> </ul>"},{"location":"ml_fundamentals/regularization/early_stopping/","title":"Early Stopping","text":"<ul> <li>Early stopping watches validation loss/metric and halts training when it stops improving, and is a stopping rule driven by the validation metric's change, not a pre-fixed iteration count</li> <li>It reduces overfitting (lower variance) by not letting the model memorize noise; acts like implicit L2 regularization.</li> </ul> <p>Train while checking performance on a validation set. Whenever the validation score improves, remember those weights. If it doesn't improve for a while (patience), stop and roll back to the best checkpoint. This caps model complexity at the point where it generalized best, preventing the later epochs from fitting noise.</p>"},{"location":"ml_fundamentals/regularization/early_stopping/#related-topics","title":"Related Topics","text":"<ul> <li>Overfitting &amp; Underfitting - Why early stopping helps</li> <li>L1/L2 Regularization - Alternative regularization techniques</li> <li>Model Evaluation - Using validation for early stopping</li> </ul>"},{"location":"ml_fundamentals/regularization/l1_l2_regularization/","title":"L2 / L1 Regularization","text":""},{"location":"ml_fundamentals/regularization/l1_l2_regularization/#setup","title":"Setup","text":"<p>Model (no intercept for simplicity):</p> \\[\\hat y_i = w\\,x_i\\] <p>Data loss (sum of squared errors):</p> \\[\\sum_i (y_i - w x_i)^2\\] <p>L2-regularized loss (ridge):</p> \\[\\underbrace{\\sum_i (y_i - w x_i)^2}_{\\text{fit the data}} \\;+\\; \\underbrace{\\lambda\\, w^2}_{\\text{penalize big weights}}\\] <ul> <li>\\(\\lambda&gt;0\\) controls the strength of the penalty (larger \\(\\lambda\\) stronger shrinkage).</li> <li>In practice, we usually don't penalize the bias/intercept.</li> </ul>"},{"location":"ml_fundamentals/regularization/l1_l2_regularization/#how-l2-penalizes-the-parameter","title":"How L2 Penalizes the Parameter","text":"<p>Take derivative w.r.t. \\(w\\) and set to 0:</p> \\[\\frac{\\partial}{\\partial w}\\Big[\\sum_i (y_i - w x_i)^2 + \\lambda w^2\\Big] = -2\\sum_i x_i(y_i - w x_i) + 2\\lambda w = 0\\] <p>Rearrange:</p> \\[w\\big(\\sum_i x_i^2 + \\lambda\\big) = \\sum_i x_i y_i \\quad\\Rightarrow\\quad \\boxed{\\,w_{\\text{ridge}} = \\dfrac{\\sum_i x_i y_i}{\\sum_i x_i^2 + \\lambda}\\,}\\] <p>Compare to unregularized OLS:</p> \\[w_{\\text{OLS}} = \\dfrac{\\sum_i x_i y_i}{\\sum_i x_i^2}\\] <p>L2 adds \\(\\lambda\\) to the denominator and shrinks \\(w\\) toward 0.</p>"},{"location":"ml_fundamentals/regularization/l1_l2_regularization/#why-l2-decrease-variance-and-increase-bias","title":"Why L2 Decrease Variance and Increase Bias?","text":"<p>L2 regularization constrains how large the parameters can get. Constraining parameters makes the fitted function smoother/less wiggly, so predictions don't swing wildly when the training sample changes\u2014this cuts variance. The tradeoff is that the constrained model can't perfectly adapt to the true signal, so estimates are pulled toward zero (or toward simpler shapes), which introduces bias.</p>"},{"location":"ml_fundamentals/regularization/l1_l2_regularization/#tiny-numeric-example","title":"Tiny Numeric Example","text":"<p>Data: \\(x=[0,1,2,3]\\), \\(y=[0,1,2,60]\\) (last point is an outlier) - \\(\\sum x_i^2 = 14, \\sum x_i y_i = 185\\)</p> <p>Weights: - OLS (no L2): \\(185/14 \\approx 13.214\\) - L2, \\(\\lambda=10\\): \\(185/(14+10) = 185/24 \\approx 7.708185\\) - L2, \\(\\lambda=100\\): \\(185/(14+100) = 185/114 \\approx 1.623\\)</p> <p>As \\(\\lambda\\) grows, \\(w\\) is pulled toward 0, limiting the impact of the outlier.</p>"},{"location":"ml_fundamentals/regularization/l1_l2_regularization/#gradient-descent-view-weight-decay","title":"Gradient-Descent View (Weight Decay)","text":"<p>With learning rate \\(\\eta\\):</p> \\[w_{\\text{new}} = w_{\\text{old}} - \\eta\\Big(\\underbrace{-2\\sum_i x_i(y_i - w_{\\text{old}} x_i)}_{\\text{data gradient}} \\;+\\; \\underbrace{2\\lambda w_{\\text{old}}}_{\\text{L2 shrink}}\\Big)\\] <p>The \\(+2\\lambda w\\) term is the shrinkage that steadily decays weights.</p>"},{"location":"ml_fundamentals/regularization/l1_l2_regularization/#multi-feature-form-for-reference","title":"Multi-Feature Form (for reference)","text":"<p>For features \\(X\\in \\mathbb{R}^{n\\times d}\\), target \\(\\mathbf{y}\\):</p> \\[\\mathbf{w}_{\\text{ridge}} = (X^\\top X + \\lambda I)^{-1} X^\\top \\mathbf{y}\\]"},{"location":"ml_fundamentals/regularization/l1_l2_regularization/#copy-paste-python","title":"Copy-Paste Python","text":"<pre><code>import numpy as np\n\nx = np.array([0,1,2,3], dtype=float)\ny = np.array([0,1,2,60], dtype=float)\n\nSxx = np.sum(x**2)\nSxy = np.sum(x*y)\n\ndef ridge_weight(lmbda):\n    return Sxy / (Sxx + lmbda)\n\nprint(\"w_OLS        =\", Sxy / Sxx)\nfor lmbda in [10, 100]:\n    print(f\"w_ridge\", ridge_weight(lmbda))\n</code></pre> <p>Notes - Standardize features before using L2/L1 (esp. linear/logistic). - Tune \\(\\lambda\\) via cross-validation. - Do not penalize the bias term.</p>"},{"location":"ml_fundamentals/regularization/l1_l2_regularization/#related-topics","title":"Related Topics","text":"<ul> <li>Overfitting &amp; Underfitting - Why regularization helps</li> <li>Early Stopping - Alternative regularization technique</li> <li>Model Evaluation - Tuning regularization parameters</li> </ul>"},{"location":"ml_fundamentals/regularization/overfitting_underfitting/","title":"Overfitting &amp; Underfitting","text":"<p>This section tells how one could efficiently recognize overfit and underfit scenarios and do model improvements based on what has been identified.</p>"},{"location":"ml_fundamentals/regularization/overfitting_underfitting/#what-is-overfit-and-what-is-underfit","title":"What is Overfit and What is Underfit?","text":"<ul> <li>Overfit means that a model can be overfitting on its training data whereas on the test and new data sets, it's performing worse.</li> <li>Underfit means that the model is performing poorly on both training and test data sets.</li> </ul>"},{"location":"ml_fundamentals/regularization/overfitting_underfitting/#ways-to-mitigate-overfit-and-underfit","title":"Ways to Mitigate Overfit and Underfit","text":""},{"location":"ml_fundamentals/regularization/overfitting_underfitting/#avoid-overfitting","title":"Avoid Overfitting","text":"<ul> <li>Data: obtaining more data is one primitive way of solving overfit problem as more data can help the model to learn more efficient features to mitigate the impact from noise. Using rotation or expansion for image or GAN for getting more new training data.</li> <li>Model: one could use less complicated / complex model to avoid overfitting. For example, in NN one could reduce the number of layers or neurons in each layer; or in decision tree, one could reduce the depth of the tree or cut the tree.</li> <li>Regularization: one could use L2 regularization in model parameters to constraint the model.</li> <li>Ensemble method: ensemble method is to integrate multiple models together to avoid a single model overfitting issue, such as bagging methods.</li> </ul>"},{"location":"ml_fundamentals/regularization/overfitting_underfitting/#avoid-underfitting","title":"Avoid Underfitting","text":"<ul> <li>Add more features: when there is not enough features or the features are not relevant with the sample labels, there would be a underfit. We could dig into contextual features / ID features / combination of features to obtain better results. In deep learning, factor decomposition / gradient-boosted decision tree / deep-crossing can all be used for get more features.</li> <li>Increase the complexity of model.</li> <li>Decrease regularization parameters.</li> </ul>"},{"location":"ml_fundamentals/regularization/overfitting_underfitting/#related-topics","title":"Related Topics","text":"<ul> <li>L1/L2 Regularization - Mathematical foundations of regularization</li> <li>Early Stopping - Training control techniques</li> <li>Model Evaluation - How to detect overfitting/underfitting</li> </ul>"},{"location":"ml_fundamentals/unsupervised_learning/k_means_clustering/","title":"K-means Clustering","text":"<p>Algorithms such as SVM, logistic regression, decision trees are more for the categorization, i.e. based on the known labelled samples, classifiers are training so that it could apply the same logic on unlabeled samples. Unlike the classification problems, clustering is directly categorize the samples without any previously known labelling.</p> <p>Classification belongs to supervised learning whereas clustering is a type of unsupervised learning algorithm. K-means clustering, as one type of the most basic and fundamental clustering algorithm, has the main idea of iteratively finding the way of cutting the space into K clusters, so that the loss function is the lowest. The loss function can be defined as the sum of squared error distance of each sample from their clustered centers:</p> \\[J(c,\\mu) = \\sum_{i=1}^M ||x_i - \\mu_{c_i}||^2\\] <p>where \\(x_i\\) represents the samples, \\(c_i\\) represents the cluster that \\(x_i\\) belongs to, \\(\\mu_{c_i}\\) corresponds to the center of the cluster that \\(x_i\\)'s located in and \\(M\\) is the total number of samples.</p>"},{"location":"ml_fundamentals/unsupervised_learning/k_means_clustering/#k-means-clustering-algorithm-in-steps","title":"K-means Clustering Algorithm in Steps","text":"<p>The goal of K-means clustering is to categorize the dataset of interest into K-clusters, and also provides the cluster center corresponding to each data points:</p> <ol> <li>Data engineering and cleaning: normalization and outlier removal.</li> <li>Randomly pick K-cluster centers, labelled as \\(\\mu_1^{(0)}, \\mu_2^{(0)}, ..., \\mu_K^{(0)}\\)</li> <li>Define the loss function to be \\(J(c,\\mu) = \\min_{\\mu} \\min_{c} \\sum_{i=1}^M ||x_i - \\mu_{c_i}||^2\\)</li> <li>Iterate through the process below by t times, where t denotes the number of iterations:</li> <li>for every sample \\(x_i\\), categorize it to the cluster that has shortest distance \\(\\(c_i^{(t)} \\leftarrow {\\arg\\min}_k ||x_i - \\mu_k^{(t)}||^2\\)\\)</li> <li>for every cluster k, recalculate the center: \\(\\(\\mu_k^{(t+1)}\\leftarrow {\\arg\\min}_\\mu \\sum_{i:c_i^{(t)}=k} ||x_i - \\mu||^2\\)\\)</li> </ol> <pre><code># k-Means algorithm\ndef k_means(data, centers, k):\n    while True:\n        clusters = [[] for _ in range(k)] \n\n        # Assign data points to the closest center\n        for point in data:\n            distances = [distance(point, center) for center in centers]\n            index = distances.index(min(distances)) \n            clusters[index].append(point)\n\n        # Update centers to be the mean of points in a cluster\n        new_centers = []\n        for cluster in clusters:\n            center = (sum([point[0] for point in cluster])/len(cluster), \n                      sum([point[1] for point in cluster])/len(cluster)) \n            new_centers.append(center)\n\n        # Break loop if centers don't change significantly\n        if max([distance(new, old) for new, old in zip(new_centers, centers)]) &lt; 0.0001:\n            break\n        else:\n            centers = new_centers\n    return clusters, centers\n</code></pre>"},{"location":"ml_fundamentals/unsupervised_learning/k_means_clustering/#related-topics","title":"Related Topics","text":"<ul> <li>K-Nearest Neighbors - Alternative unsupervised learning algorithm</li> <li>Model Evaluation - Evaluating clustering performance</li> <li>Feature Engineering - How normalization affects clustering</li> </ul>"},{"location":"ml_fundamentals/unsupervised_learning/k_nearest_neighbors/","title":"K-Nearest Neighbors (k-NN) Algorithm","text":"<p>The kNN algorithm works on a basic principle: a data point is likely to be in the same category as the data points it is closest to. Note that choosing 'k' significantly impacts our model. A low 'k' might capture more noise in the data, whereas a high 'k' is computationally expensive.</p>"},{"location":"ml_fundamentals/unsupervised_learning/k_nearest_neighbors/#euclidean-distance-calculation","title":"Euclidean Distance Calculation","text":"<p>In k-NN, classification is determined by weighing the distance between data points. Euclidean distance is a frequently used metric that calculates the shortest straight-line distance \\(\\sqrt{(x_1-x_2)^2 + (y_1 - y_2)^2}\\) between two data points \\((x_1, y_1)\\) and \\((x_2, y_2)\\) in a Euclidean space.</p> <pre><code>import math\n\n# The 'euclidean_distance' function computes the Euclidean distance between two points\ndef euclidean_distance(point1, point2):\n    squares = [(p - q) ** 2 for p, q in zip(point1, point2)] # Calculate squared distance for each dimension\n    return math.sqrt(sum(squares)) # Return the square root of the sum of squares\n\n# Test it\npoint1 = (1, 2) # The coordinates of the first point\npoint2 = (4, 6) # The coordinates of the second point\nprint(euclidean_distance(point1, point2)) # 5.0\n</code></pre>"},{"location":"ml_fundamentals/unsupervised_learning/k_nearest_neighbors/#actual-knn-algorithm","title":"Actual KNN Algorithm","text":"<pre><code>from collections import Counter\nimport numpy as np\n\ndef k_nearest_neighbors(data, query, k, distance_fn):\n    neighbor_distances_and_indices = []\n    # Compute distance from each training data point\n    for idx, label in enumerate(data):\n        distance = euclidean_distance(label[0], query)\n        neighbor_distances_and_indices.append((distance, idx))\n    # Sort array by distance\n    sorted_neighbor_distances_and_indices = sorted(neighbor_distances_and_indices)\n    # Select k closest data points\n    k_nearest_distances_and_indices = sorted_neighbor_distances_and_indices[:k]\n    # Obtain class labels for those k data points\n    k_nearest_labels = [data[i][1] for distance, i in k_nearest_distances_and_indices]\n    # Majority vote\n    most_common = Counter(k_nearest_labels).most_common(1)\n    return most_common[0][0] # Return the label of the class that receives the majority vote\n\ndef euclidean_distance(point1, point2):\n    distance = sum((p - q) ** 2 for p, q in zip(point1, point2))\n    return np.sqrt(distance)\n\ndef mannhattan_distance(point1, point2):\n    return np.sum(np.abs(p - q) for p, q in zip(point1, point2))\n\ndata = [\n    ((2, 3), 0),\n    ((5, 4), 0),\n    ((9, 6), 1),\n    ((4, 7), 0),\n    ((8, 1), 1),\n    ((7, 2), 1)\n]\nquery = (7,6)\nk=2\n\nclass_label = k_nearest_neighbors(data, query, k, distance_fn)\nprint(class_label)\n</code></pre>"},{"location":"ml_fundamentals/unsupervised_learning/k_nearest_neighbors/#related-topics","title":"Related Topics","text":"<ul> <li>K-Means Clustering - Alternative unsupervised learning algorithm</li> <li>Model Evaluation - Evaluating KNN performance</li> <li>Feature Engineering - How normalization affects KNN</li> </ul>"},{"location":"neural_networks_and_deep_learning/Neural_Networks_and_Deep_Learning_Overview/","title":"Neural_Networks_and_Deep_Learning_Overview","text":""},{"location":"neural_networks_and_deep_learning/Neural_Networks_and_Deep_Learning_Overview/#introduction","title":"Introduction","text":"<p>Neural networks approximate complex nonlinear functions by stacking layers of linear transformations and nonlinear activations. Backpropagation efficiently computes gradients for training, enabling deep learning breakthroughs.</p>"},{"location":"neural_networks_and_deep_learning/Neural_Networks_and_Deep_Learning_Overview/#knowledge-points","title":"Knowledge Points","text":"<ul> <li>Introduction to Perceptron Algorithm</li> <li>Structure of a feed-forward neural network</li> <li>Activation functions: ReLU, softmax</li> <li>Backpropagation algorithm</li> <li>Implementing a simple NN from scratch (e.g., MNIST/XOR)</li> <li>Deriving gradient of softmax + cross-entropy</li> </ul>"},{"location":"neural_networks_and_deep_learning/neural_networks_sections/Introduction_to_Perceptron_Algorithm/","title":"Introduction_to_Perceptron_Algorithm","text":"<pre><code>import numpy as np\n\nclass Perceptron(object):\n\u00a0 \u00a0 def __init__(self, no_of_inputs, max_iterations=100, learning_rate=0.01):\n\u00a0 \u00a0 \u00a0 \u00a0 self.weights = np.zeros(no_of_inputs + 1)\n\u00a0 \u00a0 \u00a0 \u00a0 self.max_iterations = max_iterations\n\u00a0 \u00a0 \u00a0 \u00a0 self.learning_rate = learning_rate\n\n\u00a0 \u00a0 def predict(self, inputs):\n\u00a0 \u00a0 \u00a0 \u00a0 summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n\u00a0 \u00a0 \u00a0 \u00a0 if summation &gt; 0:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 activation = 1\n\u00a0 \u00a0 \u00a0 \u00a0 else:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 activation = 0\n\u00a0 \u00a0 \u00a0 \u00a0 return activation\n\n\u00a0 \u00a0 def train(self, training_inputs, labels):\n\u00a0 \u00a0 \u00a0 \u00a0 for _ in range(self.max_iterations):\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 for inputs, label in zip(training_inputs, labels):\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 prediction = self.predict(inputs)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 self.weights[0] += self.learning_rate * (label - prediction)\n\n# AND dataset\ntraining_inputs = [\n\u00a0 \u00a0 np.array([0, 0]),\n\u00a0 \u00a0 np.array([0, 1]),\n\u00a0 \u00a0 np.array([1, 0]),\n\u00a0 \u00a0 np.array([1, 1])\n]\nlabels = np.array([0, 0, 0, 1])\nperceptron = Perceptron(2)\nperceptron.train(training_inputs, labels)\n\ninputs = np.array([1, 1]) \u00a0# Expected: 1\nprint(perceptron.predict(inputs))\n</code></pre>"},{"location":"probability_and_markov/Probability_and_Markov_Overview/","title":"Week1_Probability_and_Markov","text":""},{"location":"probability_and_markov/Probability_and_Markov_Overview/#title-probability-markov","title":"title: Probability &amp; Markov","text":""},{"location":"probability_and_markov/Probability_and_Markov_Overview/#probability-foundations-markov-assumption","title":"Probability Foundations &amp; Markov Assumption","text":""},{"location":"probability_and_markov/Probability_and_Markov_Overview/#introduction","title":"Introduction","text":"<p>Probability theory provides the core mathematical language for reasoning under uncertainty, while the Markov assumption simplifies sequential dependencies\u00e2\u20ac\u201dboth are fundamental for modern NLP and language modeling.</p> <p>Through this module you will refresh key probability concepts and see how the Markov assumption enables tractable modeling of text sequences.</p>"},{"location":"probability_and_markov/Probability_and_Markov_Overview/#knowledge-points","title":"Knowledge Points","text":"<ul> <li>Conditional Probability &amp; Bayes' Rule</li> <li>Naive Bayes</li> <li>Joint &amp; Marginal</li> <li>ML Fundamentals</li> <li>Markov Assumption: definition &amp; role in NLP</li> </ul>"},{"location":"probability_and_markov/probability_and_markov_sections/","title":"Index","text":"<p># Week 1 Overview</p> <p>Short overview of Probability \\&amp; Markov topics.</p> <p>- [[Week1P1-conditional_probability_and_bayes_rule|Bayes\u2019 Rule]]</p> <p>- [[Week1P2-naive_bayes_and_gaussian_naive_bayes|Naive Bayes]]</p> <p>- [[Week1P3-joint_and_marginal_distributions|Joint \\&amp; Marginal]]</p>"},{"location":"probability_and_markov/probability_and_markov_sections/conditional_probability_and_bayes_rule/","title":"Conditional Probability & Bayes Rule","text":"<p>Resources - StatQuest: Conditional Probability (YouTube) - StatQuest: Bayes' Rule - 3Blue1Brown: Bayes theorem, the geometry of changing beliefs</p> <p></p> Loves Candy Does not Love Candy Row Total Loves Soda 2\\(p=\\frac{2}{14}\\) 5\\(p=\\frac{5}{14}\\) 2+5=7\\(p=\\frac{7}{14}\\) Does not Loves Soda 4\\(p=\\frac{4}{14}\\) 3\\(p=\\frac{3}{14}\\) 4+3=7\\(p=\\frac{7}{14}\\) Column total 2+4=6\\(p=\\frac{6}{14}\\) 5+3=8\\(p=\\frac{8}{14}\\)"},{"location":"probability_and_markov/probability_and_markov_sections/conditional_probability_and_bayes_rule/#probabilities","title":"Probabilities","text":"<p>\\(p(\\text{loves candy and soda}) =\\frac{2}{14}=0.14\\) \\(p(\\text{does not love candy but love soda}) =\\frac{5}{14}=0.36\\)</p>"},{"location":"probability_and_markov/probability_and_markov_sections/conditional_probability_and_bayes_rule/#conditional-probabilities","title":"Conditional probabilities","text":"<ul> <li>probability of someone loving candy and soda given that we know they love soda: \\(p(\\text{loves candy and soda}\\vert\\text{loves soda}) =\\frac{2}{2+5}=0.29\\)</li> <li>probability of someone does not love candy, given that we know they love soda: \\(p(\\text{does not love candy but love soda}\\vert\\text{loves soda}) =\\frac{5}{2+5}=0.71\\) Dividing the numerator and denominator by the total number of people 14, the equation above becomes: \\(\\(p(\\text{does not love candy but love soda}\\vert\\text{loves soda}) =\\frac{\\frac{5}{14}}{\\frac{2+5}{14}}=\\frac{p(\\text{does not love candy but love soda})}{p(\\text{loves soda})}=0.71\\)\\) To generalize: \\(\\(p(\\text{something will happen}\\vert\\text{we know})=\\frac{p(\\text{something will happen})}{p(\\text{we know})}\\)\\)</li> </ul> <p>So the conditional probability is the probability that something will happen scaled by whatever knowledge we already have about the event</p>"},{"location":"probability_and_markov/probability_and_markov_sections/conditional_probability_and_bayes_rule/#bayes-theorem","title":"Bayes Theorem","text":"\\[p(\\text{something will happen}\\vert\\text{we know})=\\frac{p(\\text{something will happen})}{p(\\text{we know})}\\] <p>Taking the conditional probabilities from the section above, we can calculate: - probability of someone does not love candy, given that we know they love soda: \\(p(\\text{does not love candy but love soda}\\vert\\text{loves soda}) =\\frac{5}{2+5}=0.71\\) - probability of someone does not love candy but love soda, given that we know they does not love candy: \\(p(\\text{does not love candy but love soda}\\vert\\text{does not love candy}) =\\frac{5}{5+3}=0.63\\) In both cases above, we want to know the probability of the same event, meeting someone who does not love candy but loves soda. This means that the numerators are the same in both cases. However since we have different prior knowledge in each case, we scale the probabilities of the events differently. So ultimately we get different probabilities.</p> <p>Now, what if we do not know the probability of someone does not love candy but love soda, which is the numerator in the cases above, we can still multiply both sides of the top equation by \\(p(\\text{loves soda})\\) from the equation: \\(p(\\text{does not love candy but love soda})\\ = p(\\text{does not love candy but love soda}\\vert\\text{loves soda})p(\\text{loves soda})\\) So overall, what we have is: \\(\\(\\frac{p(\\text{no love c \\&amp; love s}\\vert\\text{love s})p(\\text{love s})}{p(\\text{love s})}=\\frac{p(\\text{no love c \\&amp; love s}\\vert\\text{no love c})p(\\text{no love c})}{p(\\text{love s})}\\)\\) leading to: \\(\\(p(\\text{no love c \\&amp; love s}\\vert\\text{love s})=\\frac{p(\\text{no love c \\&amp; love s}\\vert\\text{no love c})p(\\text{no love c})}{p(\\text{love s})}\\)\\)</p> <p>In general, the Bayes' theorem can be represented by event A and B in the following form: \\(\\(p(\\text{A\\&amp;B}\\vert\\text{B})=\\frac{p(\\text{A\\&amp;B}\\vert\\text{A})\\times p(\\text{A})}{p(\\text{B})}\\)\\) Or in the other way around: \\(\\(p(\\text{A\\&amp;B}\\vert\\text{A})=\\frac{p(\\text{A\\&amp;B}\\vert\\text{B})\\times p(\\text{B})}{p(\\text{A})}\\)\\) the conditional probability given that we know one thing about an event can be derived from knowing the other thing about the event.</p> <p>Bayes' Theorem is the basis for Bayesian Statistics, which is this equation, paired with a broader philosophy of how statistics should be calculated.</p>"},{"location":"probability_and_markov/probability_and_markov_sections/naive_bayes_and_gaussian_naive_bayes/","title":"Naive Bayes & Gaussian Naive Bayes","text":"<p>Resources - StatQuest: Conditional Probability (YouTube) - StatQuest: Bayes' Rule - 3Blue1Brown: Bayes theorem, the geometry of changing beliefs</p>"},{"location":"probability_and_markov/probability_and_markov_sections/naive_bayes_and_gaussian_naive_bayes/#implementing-naive-bayes-classifier-from-scratch-in-python","title":"Implementing Naive Bayes Classifier from Scratch in Python","text":"<p>We approach the implementation of the Naive Bayes Classifier by first calculating the prior probabilities of each class, and then the likelihood of each feature given a class.</p> <pre><code>import pandas as pd\n\ndef calculate_prior_probabilities(y):\n    # Calculate prior probabilities for each class\n    return y.value_counts(normalize=True)\n\ndef calculate_likelihoods(X, y, smoothing = False):\n    likelihoods = {}\n    for column in X.columns:\n        likelihoods[column] = {}\n        for class_ in y.unique():\n            # Filter feature column data for each class\n            class_data = X[y == class_][column]\n            counts = class_data.value_counts()\n            if not smoothing:\n                total_count = len(class_data)  # Total count of instances for current class\n                likelihoods[column][class_] = counts / total_count  # Direct likelihoods without smoothing\n            else:\n                total_count = len(class_data) + len(X[column].unique()) # total count with smoothing \n                likelihoods[column][class_] = (counts + 1) / total_count # add-1 smoothing\n    return likelihoods\n</code></pre> <p>Armed with these utility functions, we can implement the Naive Bayes Classifier function:</p> <pre><code>def naive_bayes_classifier(X_test, priors, likelihoods):\n    predictions = []\n    for _, data_point in X_test.iterrows():\n        class_probabilities = {}\n        for class_ in priors.index:\n            class_probabilities[class_] = priors[class_]\n            for feature in X_test.columns:\n                # Use .get to safely retrieve probability and get a default of 1/total to handle unseen values\n                feature_probs = likelihoods[feature][class_]\n                class_probabilities[class_] *= feature_probs.get(data_point[feature], 1 / (len(feature_probs) + 1))\n\n        # Predict class with maximum posterior probability\n        predictions.append(max(class_probabilities, key=class_probabilities.get))\n\n    return predictions\n</code></pre>"}]}