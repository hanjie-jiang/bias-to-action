
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://hanjie-jiang.github.io/ml-learning-notes/ml_fundamentals/model_evaluation/metrics_and_validation/">
      
      
        <link rel="prev" href="../evaluation_methods/">
      
      
        <link rel="next" href="../hyperparameter_tuning/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.17">
    
    
      
        <title>Metrics & Validation - Machine Learning Notes</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/styles/layout.css">
    
      <link rel="stylesheet" href="../../../assets/styles/hero.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#evaluation-metrics-and-their-limitations" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Machine Learning Notes" class="md-header__button md-logo" aria-label="Machine Learning Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Machine Learning Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Metrics & Validation
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Machine Learning Notes" class="md-nav__button md-logo" aria-label="Machine Learning Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Machine Learning Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Engineering and Data Structure
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Engineering and Data Structure
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engineering_and_data_structure/Engineering_and_Data_Structure_Questions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Frequently used
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Foundations
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Foundations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    ML Fundamentals
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            ML Fundamentals
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ML_Fundamentals_Overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Feature Engineering
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Feature Engineering
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../feature_engineering/data_types_and_normalization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data Types & Normalization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../feature_engineering/categorical_encoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Categorical Encoding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../feature_engineering/feature_crosses/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Feature Crosses
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Model Evaluation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            Model Evaluation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation_methods/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Evaluation Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Metrics & Validation
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Metrics & Validation
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#accuracy-and-its-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      Accuracy and Its Limitations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#precision-recall-and-their-balance" class="md-nav__link">
    <span class="md-ellipsis">
      Precision &amp; Recall and Their Balance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Precision &amp; Recall and Their Balance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#concept-of-precision-recall" class="md-nav__link">
    <span class="md-ellipsis">
      Concept of Precision &amp; Recall
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confusion-matrix-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Confusion Matrix Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision-recall-in-ranking-retrieval-variants" class="md-nav__link">
    <span class="md-ellipsis">
      Precision &amp; Recall in Ranking / Retrieval Variants
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#use-of-p-r-curve-for-model-evaluation-and-threshold-choice" class="md-nav__link">
    <span class="md-ellipsis">
      Use of P-R Curve for Model Evaluation and Threshold Choice
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-pick-the-threshold-in-practice" class="md-nav__link">
    <span class="md-ellipsis">
      How to Pick the Threshold in Practice
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#root-mean-squared-errors-rmse" class="md-nav__link">
    <span class="md-ellipsis">
      Root-Mean Squared Errors (RMSE)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mean-absolute-percentage-error" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Absolute Percentage Error
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#roc-curves" class="md-nav__link">
    <span class="md-ellipsis">
      ROC Curves
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ROC Curves">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-a-roc-curve" class="md-nav__link">
    <span class="md-ellipsis">
      What is a ROC Curve
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-draw-a-roc-curve" class="md-nav__link">
    <span class="md-ellipsis">
      How to Draw a ROC Curve
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-calculate-the-auc-area-under-curve" class="md-nav__link">
    <span class="md-ellipsis">
      How to Calculate the AUC (Area Under Curve)?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#use-of-cosine-distance" class="md-nav__link">
    <span class="md-ellipsis">
      Use of Cosine Distance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Use of Cosine Distance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#definition-of-euclidean-distance-cosine-distance" class="md-nav__link">
    <span class="md-ellipsis">
      Definition of Euclidean Distance &amp; Cosine Distance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-cosine-similarity-but-not-euclidean-distance" class="md-nav__link">
    <span class="md-ellipsis">
      When to Use Cosine Similarity but Not Euclidean Distance?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is-cosine-distance-a-strictly-defined-distance" class="md-nav__link">
    <span class="md-ellipsis">
      Is Cosine Distance a Strictly Defined Distance?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#related-topics" class="md-nav__link">
    <span class="md-ellipsis">
      Related Topics
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hyperparameter_tuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hyperparameter Tuning
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_4" >
        
          
          <label class="md-nav__link" for="__nav_3_1_4" id="__nav_3_1_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Regularization
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_4">
            <span class="md-nav__icon md-icon"></span>
            Regularization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../regularization/overfitting_underfitting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overfitting & Underfitting
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../regularization/l1_l2_regularization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L1/L2 Regularization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../regularization/early_stopping/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Early Stopping
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_5" >
        
          
          <label class="md-nav__link" for="__nav_3_1_5" id="__nav_3_1_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Classical Algorithms
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_5">
            <span class="md-nav__icon md-icon"></span>
            Classical Algorithms
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../classical_algorithms/linear_regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linear Regression
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../classical_algorithms/logistic_regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Logistic Regression
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../classical_algorithms/decision_trees/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Decision Trees
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_6" >
        
          
          <label class="md-nav__link" for="__nav_3_1_6" id="__nav_3_1_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Unsupervised Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_6">
            <span class="md-nav__icon md-icon"></span>
            Unsupervised Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unsupervised_learning/k_nearest_neighbors/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    K-Nearest Neighbors
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unsupervised_learning/k_means_clustering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    K-Means Clustering
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Probability & Markov
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Probability & Markov
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../probability_and_markov/Probability_and_Markov_Overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../probability_and_markov/probability_and_markov_sections/conditional_probability_and_bayes_rule/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bayes’ Rule
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../probability_and_markov/probability_and_markov_sections/naive_bayes_and_gaussian_naive_bayes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Naive Bayes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../probability_and_markov/probability_and_markov_sections/joint_and_marginal_distributions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Joint & Marginal
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linear_Algebra_for_ML/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linear Algebra
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language_model/Ngram_Language_Modeling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Language Model
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Neural Networks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../neural_networks_and_deep_learning/Neural_Networks_and_Deep_Learning_Overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../neural_networks_and_deep_learning/neural_networks_sections/Introduction_to_Perceptron_Algorithm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Perceptron Algorithm
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="evaluation-metrics-and-their-limitations">Evaluation Metrics and Their Limitations<a class="headerlink" href="#evaluation-metrics-and-their-limitations" title="Permanent link">&para;</a></h1>
<p>When doing model evaluation, the classification / sort / regression problems seems to always use different metrics for evaluation.</p>
<h2 id="accuracy-and-its-limitations">Accuracy and Its Limitations<a class="headerlink" href="#accuracy-and-its-limitations" title="Permanent link">&para;</a></h2>
<p>The accuracy only measures the number of correct labels divided by the number of total labels. This can potentially lead to a issue <strong>when the number of labels are limited in the dataset</strong>. When negative samples composed 99% of the data, if every label is a negative one, we still get 99% accuracy. So, if we use more effective mean accuracy that quantifies the mean accuracy under each category, it would be a better metrics to work with.</p>
<h2 id="precision-recall-and-their-balance">Precision &amp; Recall and Their Balance<a class="headerlink" href="#precision-recall-and-their-balance" title="Permanent link">&para;</a></h2>
<h3 id="concept-of-precision-recall">Concept of Precision &amp; Recall<a class="headerlink" href="#concept-of-precision-recall" title="Permanent link">&para;</a></h3>
<p>Now we need to introduce the concept of precision and recall.</p>
<p>Precision cares about the correctness of positive predictions, whereas recall cares about coverage of actual positives. <strong>Precision and recall trade off via the decision threshold.</strong> In a binary classification problem:</p>
<div class="arithmatex">\[\text{Precision} = \frac{N_{\text{true positive}}}{N_{\text{true positive}} + N_{\text{false positive}}} = \frac{N_{\text{true positive}}}{N_{\text{positive predictions}}}\]</div>
<div class="arithmatex">\[\text{Recall} = \frac{N_{\text{true positive}}}{N_{\text{true positive}} + N_{\text{false negative}}} = \frac{N_{\text{true positive}}}{N_{\text{actual positives}}}\]</div>
<p>The F1 score is their harmonic mean:</p>
<div class="arithmatex">\[\text{F1} = \frac{2(\text{Precision})(\text{Recall})}{\text{Precision} + \text{Recall}} = \frac{2N_{\text{true positive}}}{2N_{\text{true positive}}+N_{\text{false positive}}+N_{\text{false negative}}}\]</div>
<p>This value ranges from 0 to 1 and penalizes imbalance, thus when either precision or recall is low, F1 drops sharply. <strong>F1 should be used when false positives and false negatives matter about equally, especially with imbalanced classes.</strong></p>
<h3 id="confusion-matrix-implementation">Confusion Matrix Implementation<a class="headerlink" href="#confusion-matrix-implementation" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="n">TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predicted_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">true_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predicted_labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">true_labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predicted_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">true_labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predicted_labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">true_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:</span><span class="se">\n</span><span class="s2"> TP: &quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">FP: &quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> FN: &quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">TN: &quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;Output:</span>
<span class="sd">Confusion Matrix:</span>
<span class="sd"> TP:  4     FP:  2 </span>
<span class="sd"> FN:  2     TN:  2</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<h3 id="precision-recall-in-ranking-retrieval-variants">Precision &amp; Recall in Ranking / Retrieval Variants<a class="headerlink" href="#precision-recall-in-ranking-retrieval-variants" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">precision_at_k</span><span class="p">(</span><span class="n">ground_truth_set</span><span class="p">,</span> <span class="n">ranked_list</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">ranked_list</span><span class="p">[:</span><span class="n">k</span><span class="p">])</span> <span class="o">&amp;</span> <span class="n">ground_truth_set</span><span class="p">)</span> <span class="o">/</span> <span class="n">k</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># when there are more than one query / user / example that we would like to test on our predictions, we use the weighted average of the precision_at_k.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">mean_precision_at_k</span><span class="p">(</span><span class="n">ground_truth_sets</span><span class="p">,</span> <span class="n">ranked_lists</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="c1"># ground_truth_sets and ranked_lists are aligned lists</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">precision_at_k</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">g</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ground_truth_sets</span><span class="p">,</span> <span class="n">ranked_lists</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ground_truth_sets</span><span class="p">)</span>
</code></pre></div>
<ul>
<li><strong>Precision@k</strong> for <strong>one</strong> case <span class="arithmatex">\(q\)</span> (one list).</li>
<li><strong>Mean Precision@k</strong> average of those values over <strong>all</strong> cases <span class="arithmatex">\(q \in Q\)</span>.</li>
</ul>
<p><strong>Example</strong>: when dealing with video vague search functionality, it seems that the search ranking model can return the top 5 precision pretty high, however, the user in reality still cannot find the videos they want, especially those unpopular ones. Where does this problem coming from?</p>
<p><strong>Root cause analysis</strong>: Coming back to the example above, the top 5 precision being really high, meaning that the model can get the true positive results on a pretty good level with a certain set of positive predictions; however, when it comes down to cases where users would like to find not so popular videos, the precision of ranks can be rather no so useful as the user is looking for not so well-defined labels, hence the good precision of popular videos would not be helpful for this case as <strong>model is not providing all the relevant videos to the user and this is a problem of not so good recall rate.</strong> Let's say for the top 5 results, the precision@5 to be 100%, meaning that the correctness of the positive results is pretty higher, however, the recall@5 can still be 5%, meaning that only predicted 5 true positives although there are 100 actual positives involved. When doing model evaluation, it means that we should be focusing on both precision and recall, and also using different top N values for observations.</p>
<p>Hence, in general, when people evaluate the goodness of a sort algorithm, they also look at the P-R curve, where in this curve, the x-axis corresponds to recall rate whereas the y-axis corresponds to precision rate.</p>
<h3 id="use-of-p-r-curve-for-model-evaluation-and-threshold-choice">Use of P-R Curve for Model Evaluation and Threshold Choice<a class="headerlink" href="#use-of-p-r-curve-for-model-evaluation-and-threshold-choice" title="Permanent link">&para;</a></h3>
<p><img alt="p-r_curve" src="../resources/p-r_curve.png" /></p>
<p>Each data point on the curve corresponds to a precision-recall combination at a certain threshold for True samples of choice, for example 0.95 / 0.9, etc. The closer to the origin (0,0) point, the bigger the threshold is.</p>
<h3 id="how-to-pick-the-threshold-in-practice">How to Pick the Threshold in Practice<a class="headerlink" href="#how-to-pick-the-threshold-in-practice" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Capacity-constrained:</strong> If reviewers can handle 300 cases/day, pick the smallest threshold that yields ≈300 flags/day; report the resulting (Precision, Recall).</li>
<li><strong>Recall target:</strong> If policy demands <strong>≥95% recall</strong>, choose the lowest threshold achieving that, then report precision (and expected review load).</li>
<li><strong>Cost-based:</strong> Minimize <span class="arithmatex">\(\text{Cost}_{\text{false positives}}\cdot{\text{False Positives}}+\text{Cost}_{\text{false negatives}}\cdot{\text{False Negatives}}\)</span> over thresholds.</li>
</ul>
<p>Also report <strong>AUPRC</strong> to compare models independent of a single threshold (higher is better, especially with class imbalance).</p>
<h2 id="root-mean-squared-errors-rmse">Root-Mean Squared Errors (RMSE)<a class="headerlink" href="#root-mean-squared-errors-rmse" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[ RMSE = \sqrt{\frac{\sum_{i=1}^{n}{(y_i - \hat y_i)^2}}{n}} \]</div>
<p>Root-mean squared error has long been used as the metric for evaluating the regression model.</p>
<p><strong>Example</strong>: as a streaming company, one would say that prediction of traffic for each series can be really important when it comes down to ads bidding and user expansion. One would like to use a regression model to predict the traffic trend of a certain series, but whatever regression model that one uses, the RMSE metric ends up being really high. But, in reality, the model 95% of the time predict error is less than 1%, with really good prediction results. What might be the reason of this extraordinarily good results?</p>
<p><strong>Root cause analysis</strong>: From what the example, says there are two possible ways for the RMSE to be ineffective: 1) n being really small hence at this moment, the calculated error cannot be measurable anymore, 2) all the errors between actual value and predicted value are over- / under-predicting that the summation at the end being really high, however, in reality it is not the case and <strong>3) one outlier being really off when comparing with other data points, it is contaminating the RMSE to be really big.</strong> Coming back to the question, as 95% of the time to model has really good prediction error hence it means the other 5% of the time the model can be really off with big outliers and it could happen when a series with small traffic / newly come-out / newly accoladed could produce this big error.</p>
<p><strong>How to solve:</strong> 1) When we think these outliers are noises, then we need to filter them out at the early stage when doing data cleaning, 2) If we do not think they are noises, then we need to further improve the prediction capability of our algorithm so that we could somehow model the formation of these outliers. and 3) We could also use a better metric for the model evaluation. There are indeed better evaluation metrics that are of better robustness than RMSE, for example, Mean Absolute Percentage Error (MAPE):</p>
<h2 id="mean-absolute-percentage-error">Mean Absolute Percentage Error<a class="headerlink" href="#mean-absolute-percentage-error" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[MAPE = \sum_{i=1}^n{|\frac{(y_i - \hat y_i)}{y_i}|\cdot\frac{100}{n}}\]</div>
<p>When comparing with RMSE, MAPE normalizes the error rate of each data point to mitigate the outlier impact from the absolute error.</p>
<h2 id="roc-curves">ROC Curves<a class="headerlink" href="#roc-curves" title="Permanent link">&para;</a></h2>
<p>Binary classifiers are the mostly used and applied classifier in the ML industry. There are a lot of different metrics that one could use for evaluate the binary classifiers, including precision, recall, F1 score and P-R curve. But these metrics are only reflecting one aspect of the model. Hence, ROC curves can be of really good use.</p>
<h3 id="what-is-a-roc-curve">What is a ROC Curve<a class="headerlink" href="#what-is-a-roc-curve" title="Permanent link">&para;</a></h3>
<p>ROC curves are called receiver Operating Characteristic Curves, which established from the military field and are often used in the medical industry as well. This curve's x-axis is the false positive rate, whereas the y-axis is the true-positive rate.</p>
<div class="arithmatex">\[\text{False Positive Rate} = \frac{\text{False Positive}}{\text{Negative}}$$
$$\text{True Positive Rate} = \frac{\text{True Positive}}{\text{Positive}}\]</div>
<p><strong>Example</strong>: There are 10 patients, where in there are 3 positive cancer patients, and the rest are negative patients. The hospital decides to do diagnosis on these customers and figured that 2 are true positive cancer patients. In this case:</p>
<div class="arithmatex">\[\text{False Positive Rate} = \frac{\text{False Positive}}{\text{Negative}} = \frac{1}{7}$$
$$\text{True Positive Rate} = \frac{\text{True Positive}}{\text{Positive}}=\frac{2}{3}\]</div>
<h3 id="how-to-draw-a-roc-curve">How to Draw a ROC Curve<a class="headerlink" href="#how-to-draw-a-roc-curve" title="Permanent link">&para;</a></h3>
<ul>
<li>What is needed</li>
<li>True labels <span class="arithmatex">\(y \in \{0,1\}\)</span></li>
<li>A <strong>score</strong> for the positive class per item (probability or decision score).</li>
</ul>
<table>
<thead>
<tr>
<th>Sample Number</th>
<th>True Label</th>
<th>Model Output Probability as Positive</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Positive</td>
<td>0.9</td>
</tr>
<tr>
<td>2</td>
<td>Positive</td>
<td>0.8</td>
</tr>
<tr>
<td>3</td>
<td>Negative</td>
<td>0.7</td>
</tr>
</tbody>
</table>
<p>From this example, we could then plot out the true positive rate (TPR) as the x-axis and false positive rate (FPR) as the y-axis for the curve, hence getting the ROC curve. There is a more direct way to plot the ROC curve as well:</p>
<ul>
<li>Getting the number of Positive &amp; Negative samples, i.e. assuming number of positive samples to be P and negative to be N.</li>
<li>Getting the x-axis labels to be the count of negative samples, and y-axis labels to be the count of positive samples, then use the model output probability to do sorting of the samples</li>
<li>Now draw the ROC curve from origin, whenever seeing a positive sample to draw a vertical line segment of +1 increment on y-axis, whenever seeing a negative sample then we draw a horizontal line segment along the x-axis until we reach the final sample with curve ending at (1,1).</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="kn">import</span> <span class="n">random</span>

<span class="n">truth_labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.6</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">500</span><span class="p">)]</span>
<span class="c1"># we generate some random predictions that would normally be obtained from the model</span>
<span class="c1"># If a predicted probability is higher than the threshold, it is considered to be a positive outcome </span>
<span class="n">predicted_probs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)))</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">truth_labels</span><span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">roc_curve</span><span class="p">(</span><span class="n">truth_labels</span><span class="p">,</span> <span class="n">predicted_probs</span><span class="p">):</span>
    <span class="n">thresholds</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">11</span><span class="p">)]</span>
    <span class="n">tprs</span><span class="p">,</span> <span class="n">fprs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>
        <span class="n">tp</span> <span class="o">=</span> <span class="n">fp</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">=</span> <span class="n">fn</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># initialize confusion matrix counts</span>
        <span class="c1"># for each prediction</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">truth_labels</span><span class="p">)):</span>
            <span class="c1"># calculate confusion matrix counts</span>
            <span class="k">if</span> <span class="n">predicted_probs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">truth_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">tp</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">fp</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">truth_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">fn</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tn</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># track the TPR and FPR for this threshold</span>
        <span class="n">tprs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">))</span>  <span class="c1"># True Positive Rate (TPR)</span>
        <span class="n">fprs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">))</span>  <span class="c1"># False Positive Rate (FPR)</span>
    <span class="k">return</span> <span class="n">tprs</span><span class="p">,</span> <span class="n">fprs</span>

<span class="n">tprs</span><span class="p">,</span> <span class="n">fprs</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">truth_labels</span><span class="p">,</span> <span class="n">predicted_probs</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fprs</span><span class="p">,</span> <span class="n">tprs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<h3 id="how-to-calculate-the-auc-area-under-curve">How to Calculate the AUC (Area Under Curve)?<a class="headerlink" href="#how-to-calculate-the-auc-area-under-curve" title="Permanent link">&para;</a></h3>
<p>As simple as it could be, AUC is the area under the ROC curve, which can quantitatively reflect the model performance based on ROC curve. It is simple to calculate AUC along ROC x-axis. Due to that ROC curve tends to be above y=x, AUC values are usually between 0.5-1. The bigger the AUC is, the better the classifier is as the more likely that the classifier put the true positive samples at the front.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_aucroc</span><span class="p">(</span><span class="n">tprs</span><span class="p">,</span> <span class="n">fprs</span><span class="p">):</span>
    <span class="n">aucroc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tprs</span><span class="p">)):</span>
        <span class="n">aucroc</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">fprs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">fprs</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">tprs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">tprs</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">aucroc</span>

<span class="n">aucroc</span> <span class="o">=</span> <span class="n">compute_aucroc</span><span class="p">(</span><span class="n">tprs</span><span class="p">,</span> <span class="n">fprs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The AUC-ROC value is: </span><span class="si">{</span><span class="n">aucroc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># The AUC-ROC value is: 0.9827272125066242</span>
</code></pre></div>
<p>We have touched on the P-R curve for evaluating classification or sort algorithms. Comparing with P-R curve, there is one important character of ROC curve, which is that when positive / negative sample distribution change significant, the ROC curve shape could stay rather consistently whereas the P-R curve shape would be changing. This makes the ROC curve to mitigate the interference from diverse test sets and could more objectively evaluate the algorithm. In reality, when positive counts are much less than the negative counts, when switching dataset the data can be of big change, so a stable and robust evaluation would be important. Hence, usually ROC can be used in more variety of scenarios and could be utilized in sort / recommendation / ads.</p>
<h2 id="use-of-cosine-distance">Use of Cosine Distance<a class="headerlink" href="#use-of-cosine-distance" title="Permanent link">&para;</a></h2>
<p>How to evaluate the distance between samples can also define the optimization target and training method. In ML problems, we usually take the features to be of vector form, so when analyzing the two feature vector similarity, we could use cosine similarity. The cosine similarity can range from -1 to 1, where when two vectors are exactly the same, the cosine similarity becomes 1. Hence, when looking at distances, 1-cosine similarity becomes the cosine distance. Overall, the cosine distance is [0,2] and the same two vectors their cosine distance becomes 0.</p>
<h3 id="definition-of-euclidean-distance-cosine-distance">Definition of Euclidean Distance &amp; Cosine Distance<a class="headerlink" href="#definition-of-euclidean-distance-cosine-distance" title="Permanent link">&para;</a></h3>
<p><strong>Euclidean Distance</strong>
For vectors <span class="arithmatex">\(x,y\in\mathbb{R}^d\)</span>:</p>
<div class="arithmatex">\[d_{\text{Euc}}(x,y)=\sqrt{\sum_{i=1}^{d}(x_i-y_i)^2} \in [0,\infty)\]</div>
<ul>
<li><strong>What it measures:</strong> straight-line (L2) distance in space.</li>
<li><strong>Sensitive to scale/magnitude:</strong> doubling a vector doubles distances.</li>
<li><strong>Squared form:</strong> sometimes use <span class="arithmatex">\(\|x-y\|^2\)</span> (no square root) for speed/convexity.</li>
</ul>
<p><strong>Cosine Distance</strong>
Start with cosine <strong>similarity</strong>:</p>
<div class="arithmatex">\[\text{cos\_sim}(x,y)=\frac{x\cdot y}{\|x\|\,\|y\|}\in[-1,1]\]</div>
<p>Cosine <strong>distance</strong> (common definition):
<span class="arithmatex">\(<span class="arithmatex">\(d_{\text{cos}}(x,y)=1-\text{cos\_sim}(x,y)\in[0,2]\)</span>\)</span></p>
<ul>
<li><strong>What it measures:</strong> difference in <strong>direction</strong> (angle) only.</li>
<li><strong>Scale-invariant:</strong> multiplying a vector by a positive constant doesn't change it.</li>
</ul>
<p>Overall, on unit vectors, Euclidean and cosine distances are monotonic transforms.
Also, on a unit circle, one would see:
<span class="arithmatex">\(<span class="arithmatex">\(\|A-B\|=\sqrt{2(1-cos(A,B))}\)</span>\)</span></p>
<ul>
<li><strong>When to use which</strong></li>
<li>Use <strong>Euclidean</strong> when magnitude matters (e.g., real spatial distances, continuous features with meaningful scales).</li>
<li>Use <strong>Cosine</strong> when orientation matters more than length (e.g., text/image embeddings, TF-IDF vectors).</li>
</ul>
<h3 id="when-to-use-cosine-similarity-but-not-euclidean-distance">When to Use Cosine Similarity but Not Euclidean Distance?<a class="headerlink" href="#when-to-use-cosine-similarity-but-not-euclidean-distance" title="Permanent link">&para;</a></h3>
<p>For two vectors A and B, when their cosine similarity are being defined as <span class="arithmatex">\(cos(A,B)=\frac{A\cdot B}{\|A\|_2 \|B\|_2}\)</span>, i.e. the cosine of angle between two vectors, we thus measure the angular distance between them, rather than the absolute magnitude, with the range being [-1,1]. When a pair of text being very different in length, but with similar content, if using Euclidean distance, one can think their distance being pretty big whereas when using cosine similarity, the angle between the two can be rather small, hence giving high similarity. In text, visual, video, image industries, when the objective has high dimensions, cosine can still retain its character of [-1,1] whereas the Euclidean distance number can be really big.</p>
<p><strong>Overall, Euclidean distance measures the absolute difference between numbers whereas the cosine distance measures the directional relative difference.</strong></p>
<p>Taking an example of measuring user behavior of watching two different TV series:
- user A's watch vector = (0,1)
- user B's watch vector = (1,0)</p>
<p>It is obvious that the cosine distance between the two can be really big whereas their Euclidean distance is small.</p>
<p>When measuring user A/B preference, we focus more on relative difference, hence we should be using the cosine distance whereas when we are analyzing user login frequency or activity, we should be using Euclidean distance instead as the cosine distance would think two users of vector (1,10) and (10,100) are more similar to each other.</p>
<h3 id="is-cosine-distance-a-strictly-defined-distance">Is Cosine Distance a Strictly Defined Distance?<a class="headerlink" href="#is-cosine-distance-a-strictly-defined-distance" title="Permanent link">&para;</a></h3>
<p>No, it is not strictly defined as it satisfies the Non-negativity &amp; identity (strictness), symmetry but does not satisfy the triangle inequality. A use case of this question is that when reading the word vector of <code>comedy</code> and <code>funny</code> and also <code>happy</code> and <code>funny</code>, their cosine distance is &lt; 0.3, whereas the distance between <code>comedy</code> and <code>happy</code> is 0.7.</p>
<h2 id="related-topics">Related Topics<a class="headerlink" href="#related-topics" title="Permanent link">&para;</a></h2>
<ul>
<li><strong><a href="../evaluation_methods/">Evaluation Methods</a></strong> - How to apply these metrics</li>
<li><strong><a href="../hyperparameter_tuning/">Hyperparameter Tuning</a></strong> - Using metrics for model selection</li>
<li><strong><a href="../../feature_engineering/data_types_and_normalization/">Feature Engineering</a></strong> - How metrics affect feature selection</li>
</ul>







  
  






                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.sections", "navigation.top", "content.code.copy", "content.code.annotate", "content.action.edit", "content.tabs.link", "toc.integrate", "search.suggest", "search.highlight"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.92b07e13.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="../../../javascripts/floating-nav.js"></script>
      
        <script src="https://unpkg.com/mermaid@10/dist/mermaid.min.js"></script>
      
    
  </body>
</html>